<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Stan Zhou&#39;s Hexo Technical Blog</title>
  
  <subtitle>Innovation Evangelist</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://223.95.78.227/"/>
  <updated>2019-09-19T13:27:08.458Z</updated>
  <id>http://223.95.78.227/</id>
  
  <author>
    <name>Stan Zhou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>apache-cloudstack</title>
    <link href="http://223.95.78.227/2019/09/19/apache-cloudstack/"/>
    <id>http://223.95.78.227/2019/09/19/apache-cloudstack/</id>
    <published>2019-09-19T12:56:11.000Z</published>
    <updated>2019-09-19T13:27:08.458Z</updated>
    
    <content type="html"><![CDATA[<h1 id="What-is-Apache-CloudStack"><a href="#What-is-Apache-CloudStack" class="headerlink" title="What is Apache CloudStack"></a>What is Apache CloudStack</h1><ul><li>Top level Apache Software Foundation project for cloud computing</li><li>Cloud computing framework to deploy IaaS cloud- private, public or hybrid</li><li>Supports all popular hypervisors for virtualization</li><li>Written in Java. Provides APIs and web GUI for management and administration</li></ul><h2 id="Key-features"><a href="#Key-features" class="headerlink" title="Key features"></a>Key features</h2><ul><li>Rich management interface</li><li>Powerful API</li><li>Dynamic workload management</li><li>Secure, configurable and extensible architecture<br><img src="https://i.imgur.com/J7Jm1XC.png" alt="architecuture"></li></ul><h2 id="Key-components-terminology"><a href="#Key-components-terminology" class="headerlink" title="Key components/terminology"></a>Key components/terminology</h2><ul><li>Region<ul><li>Largest Organizational Unit with a CloudStack Deployment</li><li>Consists of one or more zones</li></ul></li><li>Zone<ul><li>Consists of one or more pods</li><li>Contains one or more primary storage servers</li><li>Consists of a secondary storage</li></ul></li><li>Pod<ul><li>Contains one or more clusters</li><li>Contains primary storage servers</li></ul></li><li>Cluster<ul><li>Consists of a group of identical hosts running a common hypervisor</li><li>Contins one or more primary storage servers</li></ul></li><li>Host<ul><li>Smallest orgnizational unit within a Cloustack deployment</li><li>Has hypervisor to manage the guest VMs</li><li>Provides the computing resources that run guest VMs.</li></ul></li><li>Primary storage<br>iSCSI NFS Ceph Gluster  Local FileSystem</li><li>Secondary storage<br>Templates  ISO images   Disk volume snapshots</li></ul><hr><p>Recap</p><ul><li>Cloud computing is more efficient than traditional IT infrastructure deployment and management</li><li>Cloud can be deployed in public, private and hybrid configurations</li><li>Cloud services can be provided as IaaS, PaaS or SaaS.</li><li>Apache CloudStack is an open source IaaS cloud platform</li><li>Apache CloudStack si very robust, extensible and open platform</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;What-is-Apache-CloudStack&quot;&gt;&lt;a href=&quot;#What-is-Apache-CloudStack&quot; class=&quot;headerlink&quot; title=&quot;What is Apache CloudStack&quot;&gt;&lt;/a&gt;What is Apa
      
    
    </summary>
    
    
      <category term="cloudstack" scheme="http://223.95.78.227/tags/cloudstack/"/>
    
  </entry>
  
  <entry>
    <title>networking</title>
    <link href="http://223.95.78.227/2019/09/12/networking/"/>
    <id>http://223.95.78.227/2019/09/12/networking/</id>
    <published>2019-09-12T08:37:21.000Z</published>
    <updated>2019-09-12T14:34:14.724Z</updated>
    
    <content type="html"><![CDATA[<h1 id="IP-subnetting"><a href="#IP-subnetting" class="headerlink" title="IP subnetting"></a>IP subnetting</h1><p><strong>Subnetting part 1</strong><br>IP address</p><ul><li>Subnet address </li><li>1st Host address </li><li>Last Host address </li><li>Broadcast address </li></ul><p>Two methods</p><ul><li>Method 1 - Binary Method</li><li>Method 2 - Quick Method</li></ul><p><img src="https://i.imgur.com/GFUUIuH.png" alt="Typical example"></p><ul><li><p>What IP address would router1 be configured with if it is to use the first ip address in the same subnet as PC1?</p></li><li><p>What broadcast address is use by PC1?</p></li><li><p>What ip address would Router1 be configured with if it is to use the last IP address in the same Subnet as PC1?</p></li><li><p>What subnet is PC1 part of?</p></li></ul><p><strong>Binary Rules</strong></p><p>Network/subnet address </p><ul><li>Fill the host portion of an address with binary 0’s </li></ul><p>Broadcast address </p><ul><li>Fill the host portion of an address with binary 1’s </li></ul><p>First Host</p><ul><li>Fill the host portion of an address with binary 0’s except for the last bit which is set to binary 1</li></ul><p>Last Host</p><ul><li>Fill the host portion of an address with binary 1’s except for the last bit which is set to binary 0</li></ul><p>3rd example<br>172.16.129.1/17</p><p>172.16.1|000 0001.0000 0001<br>subnet = 172.16.1000 0000.0000 0000=172.16.128.0<br>Broadcast= 172.16.1111 1111.1111 1111=172.16.255.255<br>1st host=172.16.128.1<br>last host=172.16.255.254</p><p><strong>Shortcut table</strong><br>128|64|32|16|8|4|2|1<br>128|192|224|240|248|252|254|255</p><p>Tip: the first line shows the decimal values for the binary numbers of an octet<br>10000000=128   00010000=16</p><p>Second row, subtract the value in the frist row from 256<br>256-128=128    256-32=224   256-64=192  256-1=255</p><p><strong>Binary odometer:(0-255)</strong><br>10.1.1.254+1=10.1.1.255<br>10.1.1.255+1=10.1.2.0<br>10.1.2.0+1=10.1.2.1<br>or in reverse:<br>10.1.2.0-1=10.1.1.255</p><p>Broadcast address = Next Network -1<br>First host = subnet +1<br>last host = broadcast -1<br>What subnet is this host on?<br>What is a last host?</p><p><strong>Subnetting part 2</strong><br>creat multiple subnets</p><p>Subnet this network into at least 10 subnets<br>Subnet this network into subnets each having 10 host</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;IP-subnetting&quot;&gt;&lt;a href=&quot;#IP-subnetting&quot; class=&quot;headerlink&quot; title=&quot;IP subnetting&quot;&gt;&lt;/a&gt;IP subnetting&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Subnetting part 1&lt;
      
    
    </summary>
    
    
      <category term="networking" scheme="http://223.95.78.227/tags/networking/"/>
    
  </entry>
  
  <entry>
    <title>pipeline</title>
    <link href="http://223.95.78.227/2019/09/09/pipeline/"/>
    <id>http://223.95.78.227/2019/09/09/pipeline/</id>
    <published>2019-09-09T05:08:50.136Z</published>
    <updated>2019-09-09T05:08:50.136Z</updated>
    
    <content type="html"><![CDATA[<p>Pipeline</p><p>Represents a part of:</p><ul><li>Software delivery</li><li>Quality assurance process</li></ul><p>Benefits:</p><ul><li>Operation grouping</li><li>Visibility</li><li>Feedback<br><strong>Automated deployment pipeline</strong><br>3 stages:<br>code change-&gt; Continuous Integration-&gt; Automated acceptance testing-&gt; Configuration management</li></ul><ol><li>Continuous Integration<br>The continuous integration phase provides the first feedback to the developers. It checks out the code from the repository, compiles it, runs unit tests and verifies the code quality. If any step fails the pipeline execution is stopped and the first thing the developer should do is fix the continuous integration build. The continuous integration pipeline is usually the starting point.</li></ol><ul><li>first feedback</li><li>checks code</li><li>starting point</li><li>simple to setup</li></ul><ol start="2"><li>Automated acceptance testing</li></ol><ul><li>Suites of tests</li><li>A quality gate</li><li>Pipeline execution is stopped if test fails</li><li>Prevents movement</li><li>Lot of confusion</li></ul><p><img src="https://i.imgur.com/KGWFQPx.png" alt="Agile testing matrix"></p><ol><li>Acceptance testing</li></ol><ul><li>Represent functional requirements</li><li>Wrtten in the form of stories or examples</li></ul><ol start="2"><li>Unit Testing</li></ol><ul><li>Provide the high-quality software</li><li>Minimize the number of bugs</li></ul><ol start="3"><li>Exploratory Testing</li></ol><ul><li>Manual black-box testing</li><li>Breaks or improves the system</li></ul><ol start="4"><li>Non-functional testing</li></ol><ul><li>Represent properties:<ul><li>Performance</li><li>Scalability</li><li>Security</li></ul></li></ul><ol start="3"><li>Configuration management</li></ol><ul><li>Replaces the manual operations</li><li>Responsible for tracking and controlling changes</li><li>Solution to the problems</li><li>Enable storing configuration files<br>Configuration management is a solution to the problems posed by manually deploying and configuring applications on the production. Configuration management tools enables storing configuration files in the version control system and tracking every change that was made on the production servers.</li></ul><p><strong>Technical and development prerequisites</strong></p><ul><li>Automated build, test, package, and deploy operations</li><li>Quick pipeline execution</li><li>Quick failure recovery</li><li>Zero-downtime deployment</li><li>Trunk-based deployment</li></ul><p><strong>Building the continuous delivery process</strong><br>Jenkins</p><ul><li>Popular automation server</li><li>Helps create automated sequence of scripts</li><li>Plugin-oriented</li></ul><p>Ansible<br>Helps with:</p><ul><li>Software provisioning</li><li>Configuration management</li><li>Application deployment</li></ul><p>Java</p><ul><li>Most popular programming language</li><li>Develop with the Spring framework</li><li>Gradle-build tool<br>Jenkins is by far the most popular automation server on the market. It helps to create continuous integration and continuous delivery pipelines and in general any other automated sequence of scripts. Highly plug-in oriented it has a greater community which constantly extends it with new features. Another one is Ansible. Ansible is an automation tool that helps with software provisioning configuration management and application deployment. Next comes Java. Java has been the most popular programming language for years, that is why it is being used for most code examples. Together with Java, most companies develop with the Spring framework so we used it to create a simple web service needed to explain some concepts. Gradle is used as a build tool. It is less popular than Maven however trending much faster.</li></ul><p><strong>Pipeline elements</strong></p><ul><li>Basic elements</li><li>Stage - Logical separation</li><li>Setp - Used to visualize process<br><img src="https://i.imgur.com/J7xJ8KG.png" alt="elements"></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">   agent any</span><br><span class="line">   stages &#123;</span><br><span class="line">      stage(&apos;First Stage&apos;) &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">              echo &apos;Step 1. Hello World&apos;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      stage(&apos;Second Stage&apos;) &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">              echo &apos;Step 2. Second time Hello&apos;</span><br><span class="line">              echo &apos;Step 3. Third time Hello&apos;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Define pipeline structure<br>A declarative pipeline is always specified inside the pipeline block and contains sections, directives and steps. </li></ul><p><strong>Sections</strong></p><ul><li>Keywords are:<ul><li>Stages</li><li>Step</li><li>Post<br>Sections define the pipeline structure and usually contain one or more directives or steps. They are defined with the key words, stages, step and post.</li></ul></li></ul><p>Stages defines a series of one or more stage directives.</p><p>Steps defines a series of one or more step instructions.<br>Steps are the most fundamental part of the pipeline they define the operations that are executed so they actually tell Jenkins what to do.</p><p>Defined using:</p><ul><li>sh: executes the shell command</li><li>custom</li><li>script</li></ul><p>Posts defines a series of one or more step instructions that are run at the end of the pipeline build.</p><p><strong>Directives</strong></p><ul><li>Expresses the configuration of a pipeline or its parts</li><li>Defined by:<ul><li>Agent: specifies where the execution takes place</li><li>Triggers: define automated ways to trigger the pipeline and can use cron to set the time based scheduling</li><li>Options: specified pipeline specific options</li><li>Environment: deinfes a set of key values used a s environment variables</li><li>Parameters: define a list of user input parameters</li><li>Stage: allows for logical grouping of steps </li><li>When: determines whether the stage should be executed depending on the given condition</li></ul></li></ul><h2 id="Commit-Pipeline"><a href="#Commit-Pipeline" class="headerlink" title="Commit Pipeline"></a>Commit Pipeline</h2><ul><li>Basic continuous integration process</li><li>Results in a report about the build</li><li>Runs after each change in the code</li><li>Consume a reasonable amount of resources</li><li>Starting point</li></ul><p>Since it runs after every change in the code, the build should take no more than five minutes and should consume a reasonable amount of resources. The commit phase is always the starting point of the continuous delivery process and it provides the most important feedback cycle in the development process.</p><p>In the commit phase a developer checks in the code to the repository.<br>The continuous integration server detects the change and the build starts.<br>The most fundamental commit pipeline contains three stages </p><ul><li>checkout</li><li>compile</li><li>unit test</li></ul><h2 id="Code-Quality-Stages"><a href="#Code-Quality-Stages" class="headerlink" title="Code Quality Stages"></a>Code Quality Stages</h2><p><strong>Extending continuous integration</strong></p><ul><li>The most widely used are: Code coverage and Static analysis</li></ul><p><strong>Code coverage</strong></p><ul><li>Scenario:<ul><li>Nobody writes unit tests</li><li>Passes all the builds</li></ul></li><li>Solution:<ul><li>Add coverage code tools</li></ul></li><li>Creates report</li><li>Make build fail<br><strong>Available tools</strong></li><li>JaCoCo</li><li>Clover</li><li>Cobertura<br><strong>Static Code Analysis</strong></li><li>Checks without execution</li><li>Checks number of rules</li><li>Rules apply to wide range of aspects</li><li>Popular tools are Checkstyle, FindBugs, and PMD</li></ul><p><strong>SonarQube</strong></p><ul><li>Quality management tool</li><li>An alternative</li><li>Aggregates different code analysis frameworks</li><li>Has own dashboards</li><li>User friendly web interface</li></ul><h2 id="Triggers-and-notifications"><a href="#Triggers-and-notifications" class="headerlink" title="Triggers and notifications"></a>Triggers and notifications</h2><p><strong>Triggers</strong></p><ul><li>Automatic action to start the build</li><li>Manay options to choose from</li><li>Three types:<ul><li>External</li><li>Polling SCM</li><li>Scheduled build<br><strong>External Trigger</strong></li></ul></li><li>Natural to understand</li><li>Starts the build after it’s called by the notifier</li></ul><p>GitHub -&gt; trigger-&gt; Jenkins</p><p><strong>Polling SCM</strong></p><ul><li>Periodically calls Github</li><li>Sound counter-intuitive<br>Polling SCM trigger is less intuitive.<br><img src="https://i.imgur.com/s6L2bbo.png" alt="Polling SCM figure"><br>Jenkins periodically calls GitHub and checks if there were any push to the repository. Then it starts the build.</li></ul><p><strong>Scheduled build</strong></p><ul><li>Jenkins runs the build periodically</li><li>No communication with any system</li><li>Implementation of scheduled build is same as polling SCM</li><li>Used for the commit pipeline</li></ul><p><strong>Notifications</strong></p><ul><li>Lot</li></ul><h2 id="Team-development-strategies"><a href="#Team-development-strategies" class="headerlink" title="Team development strategies"></a>Team development strategies</h2><p><strong>Development workflows</strong></p><ul><li>Put the code into the repostitory</li><li>Depends on many factors</li><li>Classify into three types:<ul><li><img src="https://i.imgur.com/WXIl9qU.png" alt="Trunk-based workflow"></li><li><img src="https://i.imgur.com/Oiury7J.png" alt="Branching workflow"></li><li><img src="https://i.imgur.com/5Uo3Ac9.png" alt="Forking workflow"><br><strong>Feature toggle</strong><br>Feature toggle is a technique that is an alternative to maintaining multiple source code branches such that the feature can be tested before it is completed and ready for use. It is used to disable the feature for users but enables it for developers while testing. Feature toggles are essentially variables used in conditional statements the simplest implementation of feature toggles are flags and the if statements.</li></ul></li></ul><h2 id="acceptance-testing"><a href="#acceptance-testing" class="headerlink" title="acceptance testing**"></a>acceptance testing**</h2><p>Acceptance testing is a test performed to determine if business requirements or contracts are met. </p><ul><li>Invovles black-box testing</li><li>Imply the acceptance of the software delivery</li><li>Also called UAT</li><li>Rely on manual steps</li><li>Reaonable to run them as programmed repeatable operations<br><strong>Artifact repository</strong><br>While the source control management stores the source code the artifact repository is dedicated for storing software binary artifacts, for example, compiled libraries or components later used to build a complete application.</li><li>Store binaries on a separate server due to:<ul><li>File size</li><li>Versions</li><li>Revision mapping</li><li>Packages</li><li>Access Control</li><li>Clients</li><li>Use cases<br><img src="https://i.imgur.com/5gDLWLc.png" alt="working"><br><strong>private docker registry</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p certs</span><br><span class="line"></span><br><span class="line">openssl req \\n  -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key \\n  -x509 -days 365 -out certs/domain.crt</span><br><span class="line"></span><br><span class="line">docker run -d -p 5000:5000 --restart=always --name registry -v `pwd`/auth:/auth -e &quot;REGISTRY_AUTH=htpasswd&quot; -e &quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm&quot; -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/passwords -v `pwd`/certs:/certs -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key registry:2</span><br><span class="line"></span><br><span class="line">docker tag ubuntu_with_python stanosaka/ubuntu_with_python:1</span><br><span class="line">docker push stanosaka/ubuntu_with_python:1</span><br></pre></td></tr></table></figure></li></ul></li></ul><p><strong>Acceptance test in pipeline</strong><br><img src="https://i.imgur.com/06nJoTO.png" alt="process"></p><ol><li>The developer pushes a code change to Github.</li><li>Jenkins detects the change, triggers the build and checks out the current code.</li><li>Jenkins executes the commit phase and builds the Docker image</li><li>Jenkins pushes the image to Docker Registry</li><li>Jenkins runs the Docker container in the staging environment</li></ol><p><strong>Configuration management</strong></p><ul><li>Process of controlling configuration changes</li><li>Used to refer to the software and the hardware</li></ul><p>Application Configuration| Infrastructre Configuration<br>Decides how the system works| Server infrastructure and environment configuration<br>Expressed in the form of flags| Takes care of the deployment process<br><img src="https://i.imgur.com/L4k4cb0.png" alt="working"><br><strong>Traits</strong></p><ul><li>Automation</li><li>Version Control</li><li>Incremental changes</li><li>Server provisioning</li><li>Security</li><li>Simplicity</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Pipeline&lt;/p&gt;
&lt;p&gt;Represents a part of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software delivery&lt;/li&gt;
&lt;li&gt;Quality assurance process&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Benefits:&lt;/p&gt;
&lt;ul&gt;

      
    
    </summary>
    
    
      <category term="pipeline" scheme="http://223.95.78.227/tags/pipeline/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes-on-the-cloud</title>
    <link href="http://223.95.78.227/2019/08/31/kubernetes-on-the-cloud/"/>
    <id>http://223.95.78.227/2019/08/31/kubernetes-on-the-cloud/</id>
    <published>2019-08-31T03:47:20.688Z</published>
    <updated>2019-08-31T03:47:20.688Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes-on-the-GKE"><a href="#Kubernetes-on-the-GKE" class="headerlink" title="Kubernetes on the GKE"></a>Kubernetes on the GKE</h1><p><strong>use cloud shell</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#setup zone</span><br><span class="line">gcloud config set compute/zone australia-southeast1-a</span><br><span class="line">#setup region</span><br><span class="line">gcloud config set compute/region australia-southeast1</span><br><span class="line"># create a single node cluster</span><br><span class="line">gcloud container clusters create my-first-cluster --num-nodes 1</span><br><span class="line"># see the list of clusters</span><br><span class="line">gcloud compute instances list</span><br><span class="line"># deploy a wordpress Docker container to our single node cluster</span><br><span class="line"># --image=tutum/wordpress: An out-fo-the-box image which includes everything you need</span><br><span class="line"># to run this site-including a MySQL database</span><br><span class="line">kubectl run wordpress --image=tutum/wordpress --port=80</span><br><span class="line"># see the status of pods running</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ kubectl get pods</span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">wordpress-7fff795d48-kzbfr   1/1     Running   0          5m36s</span><br></pre></td></tr></table></figure></p><p>By default a pod is accessible to only other internal machines in the cluster<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#kubectl expose pod: Exposed the pod a a service so it can be accessed externally</span><br><span class="line">#--type=LoadBalancer: Creates an external IP that this pod can use to accept traffic</span><br><span class="line">kubectl expose pod wordpress-7fff795d48-kzbfr --name=wordpress --type=LoadBalancer</span><br><span class="line"># check </span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ kubectl describe svc wordpress</span><br><span class="line">Name:                     wordpress</span><br><span class="line">Namespace:                default</span><br><span class="line">Labels:                   pod-template-hash=7fff795d48</span><br><span class="line">                          run=wordpress</span><br><span class="line">Annotations:              &lt;none&gt;</span><br><span class="line">Selector:                 pod-template-hash=7fff795d48,run=wordpress</span><br><span class="line">Type:                     LoadBalancer</span><br><span class="line">IP:                       10.27.245.246</span><br><span class="line">LoadBalancer Ingress:     35.189.22.57</span><br><span class="line">Port:                     &lt;unset&gt;  80/TCP</span><br><span class="line">TargetPort:               80/TCP</span><br><span class="line">NodePort:                 &lt;unset&gt;  31344/TCP</span><br><span class="line">Endpoints:                10.24.0.11:80</span><br><span class="line">Session Affinity:         None</span><br><span class="line">External Traffic Policy:  Cluster</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason                Age    From                Message</span><br><span class="line">  ----    ------                ----   ----                -------</span><br><span class="line">  Normal  EnsuringLoadBalancer  2m17s  service-controller  Ensuring load balancer</span><br><span class="line">  Normal  EnsuredLoadBalancer   81s    service-controller  Ensured load balancer</span><br></pre></td></tr></table></figure></p><p><strong>How Kubernetes Works</strong><br>Kubernetes: Orchestration technology- convert isolated containers running on different hardware into a cluster</p><p>Pod: Atomic unit of deployment in Kubernetes.</p><ul><li>Consists of 1 or more tightly coupled containers.</li><li>Pod runs on node, which is controlled by master.</li><li>Kubernetes only knows about pods</li><li>Cannot start container without a pod</li><li>Pod =&gt; Sandbox for 1 or more cntainers</li></ul><p><img src="https://i.imgur.com/m8uoP3H.png" alt="pods"><br>Kubernetes::Hadoop</p><ul><li>Docker Container Engine -&gt; Java Runtime</li><li>Docker containers -&gt; Jars</li><li>Kubernetes -&gt; Hadoop</li></ul><p><strong>Kubernetes for Orchestration</strong></p><ul><li>Fault-tolerance: Pod/Nod failures</li><li>Auto-scaling: More clients? More demand</li><li>Rollback: Advanced deployment options</li><li>Auto-healing: Crashed containers restart</li><li>Load-balancing: Distribute client requests</li><li>Isolation: Sandboxes so that containers don’t interfere</li></ul><p><strong>kubectl</strong><br><img src="https://i.imgur.com/GryAqTK.png" alt="kubectl"><br>Telling k8s what the desire state is.</p><p><strong>What does the k8s master do?</strong><br>Kubernetes Master</p><ul><li>One or more nodes designated as master</li><li>Several k8s processes run on master</li><li>Multi-master for high-availability</li></ul><p><strong>kube-apiserver</strong></p><ul><li>Communicates with user</li><li>RESTful API end-points</li><li>Manifest yaml files are accepted by apiserver<br><img src="https://i.imgur.com/GA0zKFs.png" alt="apiserver"><br><strong>etcd</strong><br>Cluster Store for Metadata</li><li>Metadata about spec and status of cluster</li><li>etcd is consistent and highly available key-value store</li><li>source-of-truth for cluster state<br><img src="https://i.imgur.com/kQQe478.png" alt="etcd"></li></ul><p><strong>kube-scheduler</strong></p><ul><li>Handle pod creation and management</li><li>Kube-scheduler match/assign nodes to pods</li><li>Complex-affinities, taints, tolerations,…<br><img src="https://i.imgur.com/erz1Rpw.png" alt="scheduler"></li></ul><p><strong>controller-manager</strong></p><ul><li>Different master processes</li><li>Actual state <-> Desired State</li><li>cloud-controller-manager</li><li>kube-controller-manager</li><li>Node controller</li><li>Replication controller</li><li>Route controller</li><li>Volume controller<br><img src="https://i.imgur.com/iQpH2WD.png" alt="controller"></li></ul><p><strong>Control Plane</strong></p><ul><li>Apiserver</li><li>etc</li><li>scheduler</li><li>controller-manager<ul><li>cloud-controller-manager</li><li>kube-controller-manager<br><img src="https://i.imgur.com/ql9VYxt.png" alt="control plane"></li></ul></li></ul><p><strong>What runs on each node of a cluster?</strong><br>Kubernetes Node (Minion)</p><ul><li>Kubelet<ul><li>Agent running on this node</li><li>Listen to k8s master</li><li>Port 10255</li></ul></li><li>Kube-proxy<ul><li>Needed because pod IP addresses are ephemeral</li><li>Networking- will make sense when we discuss Service objects</li></ul></li><li>Container engine<ul><li>Works with kubelet</li><li>Pulling images</li><li>Start/stop</li><li>Could be Docker or rkt<br><img src="https://i.imgur.com/lXOojJr.png" alt="Minion"><br><img src="https://i.imgur.com/dft7Zwy.png" alt="Pod Creation Request"></li></ul></li></ul><p><strong>What are Pods?</strong><br><img src="https://i.imgur.com/5qt1aB6.png" alt="pod creation yaml"><br>Multi-Container Pods</p><ul><li>Share access to memory space</li><li>Connect to each other using localhost</li><li>Share access to the same volumes (storage abstraction)</li><li>Same parameters such as configMaps</li><li>Tight coupling is dangerous</li><li>Once crashes, all crash</li></ul><p><strong>Use cases for multi-container Pod</strong></p><ul><li>Main container, “sidecar” supporting containers<br><img src="https://i.imgur.com/ollFuAy.png" alt="main container"></li><li>Proxies, Bridges, Adapters<br><img src="https://i.imgur.com/kan5QHv.png" alt="Proxies"></li></ul><p><strong>Anti-Patterns for multi-container pods</strong></p><ul><li>Avoid packing three-tier web app into 1 pod</li><li>Do not pack multiple similar containers  in the same pod for scaling</li><li>Use Deployments or ReplicaSet instead</li><li>Micro0services: Simple, independent components</li></ul><p><strong>Pods limitations</strong></p><ul><li>No auto-healing or scaling</li><li>Pod crashes? Must be handled at higher level<ul><li>ReplicaSet,Deployment,Service</li></ul></li><li>Ephemeral: Ip address are ephemeral<br><strong>Higer level k8s objects</strong></li><li>ReplicaSet, ReplicationController: Scaling and healing</li><li>Deployment: Versioning and rollback</li><li>Service: Static (non-ephemeral) IP and networking</li><li>Volume: Non-ephemeral storage<h2 id="How-do-master-nodes-communicate"><a href="#How-do-master-nodes-communicate" class="headerlink" title="How do master nodes communicate?"></a>How do master nodes communicate?</h2><strong>Cluster to master</strong></li><li>All cluster -&gt; master communication only with apiserver</li><li>HTTPS (443)</li><li>Relatively secure<br><strong>Master to cluster</strong></li><li>apiserver-&gt;kubelet<ul><li>Certicate not verified by default</li><li>Vulnerable to man-in-the-middle attacks</li><li>Don’t run on public network</li><li>To harden<ul><li>set -kubelet-certificate-authority</li><li>use SSH tunelling</li></ul></li></ul></li><li>apiserver-&gt;nodes/pods/services<ul><li>Not safe</li><li>Plain HTTP</li><li>Neither authenticated for encrypted</li><li>On public clouds, SSH tunnelling provided by cloud provider e.g. GCP<h2 id="Where-can-we-run-Kubernetes"><a href="#Where-can-we-run-Kubernetes" class="headerlink" title="Where can we run Kubernetes?"></a>Where can we run Kubernetes?</h2>Public Cloud: </li></ul></li><li>aws(kops)</li><li>azure </li><li>gcp(kubectl)<ul><li>GKE:Google Kubernetes Engine</li><li>Infra on GCE Virtual machines</li><li>GCE: Google Compute Engine (IaaS)<br>Bootstrap(kubeadm): On-prem, private cloud<br>Playgrounds:PWK(Browser-based,time-limited sessions), Minikube(Windows or Mac, Sets up VM on your machine)</li></ul></li></ul><h2 id="Can-K8s-be-used-in-a-hybird-multi-cloud-world"><a href="#Can-K8s-be-used-in-a-hybird-multi-cloud-world" class="headerlink" title="Can K8s be used in a hybird, multi-cloud world?"></a>Can K8s be used in a hybird, multi-cloud world?</h2><p>Hybrid=On-prem+Public Cloud</p><ul><li>On-premise: vare metal or VMs</li><li>Legacy infra, large on-prem datacenters</li><li>Medium-term importance</li></ul><p>Multi-Cloud</p><ul><li>More than 1 public cloud provider</li><li>Strategic reasons, vendor lock-in (Amazon buying Whole Foods)</li></ul><h2 id="Interacting-with-K8s"><a href="#Interacting-with-K8s" class="headerlink" title="Interacting with K8s"></a>Interacting with K8s</h2><p><strong>How do we work with k8s</strong></p><ul><li>kubectl<ul><li>Most common command line utility</li><li>Make POST requests to apiserver of control plane</li></ul></li><li>kubeadm<ul><li>Bootstrap cluster when not on cloud Kubernetes service</li><li>To create cluster out of individual infra nodes</li></ul></li><li>kubefed<ul><li>Administer federated clusters</li><li>Federated cluster-&gt; group of multiple clusters (multi-cloud,hybrid)</li></ul></li><li>kubelet</li><li>kube-proxy</li></ul><p><strong>Objects</strong></p><ul><li>K8s objects are persistent entities</li><li>Everything is an object…</li><li>Pod,ReplicaSet, Deployment, Node … all are objects</li><li>Send object specification (usually in .yaml or .json)</li></ul><p><strong>Three object management methods</strong></p><ul><li>Imperative commands<ul><li>No .yaml or config files</li><li>kubectl run …</li><li>kubectl expose …</li><li>kubectl autosacle …<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl run ningx --image nginx</span><br><span class="line">kubectl create deployment nginx --image nginx</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>No config file</p><p>Imperative: intent is in command</p><p>Pro:</p><ul><li>Simple<br>Cons:</li><li>No audit trail or review mechanism</li><li>Can’t reuse or use in template</li></ul><ul><li>Imperative object configuration<ul><li>kubectl + yaml or config files used</li><li>kubectl create -f config.yaml</li><li>kubectl replace -f config.yaml</li><li>kubectl delete -f config.yaml</li></ul></li></ul><p>Config file required<br>Still Imperative: intent is in command</p><p>Pros:</p><ul><li>Still simple</li><li>Robust - files checked into repo</li><li>One file for multiple operations</li></ul><ul><li>Declarative object configuration<ul><li>Only .yaml or config files used</li><li>kubectl apply -f config.yaml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f configs/</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>Config files(s) are all that is required<br>Declarative not imperative</p><p>Pros:</p><ul><li>Most robust-review, repos, audit trails</li><li>K8S will automatically figure out intents</li><li><p>Can specify multiple files/directories recursively</p></li><li><p>Live object configuration: The live configuration values of an object, as observed by the Kubernetes cluster</p></li><li>Current object configuration files: The config file we are applying in the current command</li><li>List-applied object configuration file: The last config file what was applied to the object</li></ul><p><em>Don’t mix and match!</em><br><em>Declarative is preferred</em></p><p><strong>Merging Changes</strong></p><ul><li>Primitive fields<ul><li>String, init, boolean, images or replicas</li><li>Replace old state with Current object configuration file</li></ul></li><li>Map fields<ul><li>Merge old state with Current object configuration file</li></ul></li><li>List field<ul><li>Complex-varies by field</li></ul></li></ul><p><strong>The Pros and Cons of Declarative and Imperative object management</strong><br>Declarative</p><p>kubectl apply -f config.yaml</p><ul><li>Robust</li><li>Track in repos, review</li><li>Recursively apply to directories</li></ul><p>Imperative<br>kubectl run …<br>kubectl expose…<br>kubectl autosacle…</p><ul><li>Simple, intention is very clear</li><li>Preferred for deletion</li></ul><h2 id="Names-and-UIDs"><a href="#Names-and-UIDs" class="headerlink" title="Names and UIDs"></a>Names and UIDs</h2><p><strong>How are objects named?</strong></p><ul><li>Objects-persistent entities<ul><li>pods,replicasets,services,volumes,nodes,…</li><li>information maintained in etcd</li></ul></li><li>Identified using<ul><li>names: client-given</li><li>UIDs: system-generated<h2 id="Namespaces"><a href="#Namespaces" class="headerlink" title="Namespaces"></a>Namespaces</h2></li></ul></li><li>Divide physical cluster into multiple virtual clusters</li><li>Three pre-defined namespaces:<ul><li>default: if non specified</li><li>kube-system: for internal k8s objects</li><li>kub-public: auto-readable by all users</li></ul></li><li>Name scopes: names need to be unique only inside a namespace</li><li>Future version: namespace-&gt; common access control</li><li>Don’t use namespaces for versioning<ul><li>Just use labels instead</li></ul></li></ul><p><strong>Objects without namespaces</strong></p><ul><li>Nodes</li><li>PersistentVolumes</li><li>Namespace themselves</li></ul><h2 id="Labels"><a href="#Labels" class="headerlink" title="Labels"></a>Labels</h2><ul><li>key/value pairs attached to objects</li><li>metadata</li><li>need not be unique (same label to mutiple objects)</li><li>No sematics for k8s (meaningful only to humans)</li><li>Loose coupling via selectors</li><li>Can be added<ul><li>at creation time</li><li>after creation</li></ul></li><li>Multiple objects can have same label</li><li>Same label can’t repeat key though</li></ul><h2 id="Volumes"><a href="#Volumes" class="headerlink" title="Volumes"></a>Volumes</h2><ul><li>Permanence: Storage that lasts longer than lifetime of a pod<ul><li>a container inside pod (true for all volumes)</li><li>a pod (only true for persistent volumes)</li></ul></li><li>Shared State: multiple containers in a pod need to share state/files</li><li>Volumes: address both these needs</li><li>Volumes (in general): lifetime of abstraction=lifetime of pod<ul><li>Note that this is longer than lifetime of any container inside pod</li></ul></li><li>Persistent Volumes: lifetime of abstraction independent of pod lifetime<br><img src="https://i.imgur.com/0DJ10wq.png" alt="using volume"><br><strong>Types of Volumes</strong></li><li>awsElasticBlockStore</li><li>azureDisk</li><li>azureFile</li><li>gcePersistentDisk</li><li>Many non-cloud-specific volume types as well<br><strong>Important type of volumes</strong></li><li>configMap</li><li>emptyDir</li><li>gitRepo</li><li>secret</li><li>hostPath<h2 id="Lab-Volumes-and-the-exmptydir-volume"><a href="#Lab-Volumes-and-the-exmptydir-volume" class="headerlink" title="Lab: Volumes and the exmptydir volume"></a>Lab: Volumes and the exmptydir volume</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ cat pod-redis.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">   name: redis</span><br><span class="line">spec:</span><br><span class="line">   containers:</span><br><span class="line">   - name: redis</span><br><span class="line">     image: redis</span><br><span class="line">     volumeMounts:</span><br><span class="line">     - name: redis-storage</span><br><span class="line">       mountPath: /data/redis</span><br><span class="line">   volumes:</span><br><span class="line">   - name: redis-storage</span><br><span class="line">     emptyDir: &#123;&#125;</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ k get pod redis --watch        NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">redis   0/1     Pending   0          7m36s</span><br><span class="line">redis   0/1   Pending   0     7m36s</span><br><span class="line">redis   0/1   ContainerCreating   0     7m36s</span><br><span class="line">redis   1/1   Running   0     7m40s</span><br><span class="line">^Cstancloud9@cloudshell:~ (scenic-torch-250909)$ k exec -it redis -- /bin/bash</span><br><span class="line">root@redis:/data# cd /data/redis</span><br><span class="line">root@redis:/data/redis# echo Hello &gt; test-file</span><br><span class="line">root@redis:/data/redis# kill 1</span><br><span class="line">root@redis:/data/redis# command terminated with exit code 137</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ k get pod redis --watch</span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">redis   1/1     Running   1          18m</span><br><span class="line">^Cstancloud9@cloudshell:~ (scenic-torch-250909)$ k exec -it redis -- /bin/bash</span><br><span class="line">root@redis:/data# ls /data/redis</span><br><span class="line">test-file</span><br></pre></td></tr></table></figure></li></ul><h2 id="Persistent-Volumes"><a href="#Persistent-Volumes" class="headerlink" title="Persistent Volumes"></a>Persistent Volumes</h2><ul><li>Low-level objects, like nodes</li><li>Two types of provisioning:<ul><li>Static: administrator pre-creates the volumes</li><li>Dynamic: containers need to file a PersistentVolumeClaim<br><img src="https://i.imgur.com/Yk4bu0J.png" alt="Cloud specific persistent volumes"><br><img src="https://i.imgur.com/KnjqWkU.png" alt="persisten volumes"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">gcloud compute disks create my-disk-1 --zone australia-southeast1-a</span><br><span class="line">gcloud compute disks list</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ cat volum-sample.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pd</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: k8s.gcr.io/test-webserver</span><br><span class="line">    name: test-container</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test-pd</span><br><span class="line">      name: test-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    gcePersistentDisk:</span><br><span class="line">      pdName: my-disk-1</span><br><span class="line">      fsType: ext4</span><br><span class="line">k create -f volum-sample.yaml --validate=false</span><br><span class="line">pod/test-pd created</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ k get pod test-pd --watch</span><br><span class="line">NAME      READY   STATUS              RESTARTS   AGE</span><br><span class="line">test-pd   0/1     ContainerCreating   0          23s</span><br><span class="line">test-pd   1/1   Running   0     29s</span><br><span class="line">^Cstancloud9@cloudshell:~ (scenic-torch-250909)$ k describe pod test-pd</span><br><span class="line">Name:               test-pd</span><br><span class="line">Namespace:          default</span><br><span class="line">Priority:           0</span><br><span class="line">PriorityClassName:  &lt;none&gt;</span><br><span class="line">Node:               gke-my-first-cluster-default-pool-8ca613e9-w13m/10.152.0.2</span><br><span class="line">Start Time:         Sat, 31 Aug 2019 11:39:22 +1000</span><br><span class="line">Labels:             &lt;none&gt;</span><br><span class="line">Annotations:        kubernetes.io/limit-ranger: LimitRanger plugin set: cpu request for container test-container</span><br><span class="line">Status:             Running</span><br><span class="line">IP:                 10.24.0.22</span><br><span class="line">Containers:</span><br><span class="line">  test-container:</span><br><span class="line">    Container ID:   docker://8b08b4cd144d256a078fe3c7b4031844e2c3355d854a711ec454611c0edea30b</span><br><span class="line">    Image:          k8s.gcr.io/test-webserver</span><br><span class="line">    Image ID:       docker-pullable://k8s.gcr.io/test-webserver@sha256:f63e365c13646f231ec4a16791c6133ddd7b80fcd1947f41ab193968e02b0745</span><br><span class="line">    Port:           &lt;none&gt;</span><br><span class="line">    Host Port:      &lt;none&gt;</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Sat, 31 Aug 2019 11:39:50 +1000</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Requests:</span><br><span class="line">      cpu:        100m</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /test-pd from test-volume (rw)</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gw57h (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  Type              Status</span><br><span class="line">  Initialized       True</span><br><span class="line">  Ready             True</span><br><span class="line">  ContainersReady   True</span><br><span class="line">  PodScheduled      True</span><br><span class="line">Volumes:</span><br><span class="line">  test-volume:</span><br><span class="line">    Type:       GCEPersistentDisk (a Persistent Disk resource in Google Compute Engine)</span><br><span class="line">    PDName:     my-disk-1</span><br><span class="line">    FSType:     ext4</span><br><span class="line">    Partition:  0</span><br><span class="line">    ReadOnly:   false</span><br><span class="line">  default-token-gw57h:</span><br><span class="line">    Type:        Secret (a volume populated by a Secret)</span><br><span class="line">    SecretName:  default-token-gw57h</span><br><span class="line">    Optional:    false</span><br><span class="line">QoS Class:       Burstable</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute for 300s</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason                  Age    From                                                      Message</span><br><span class="line">  ----    ------                  ----   ----                                                      -------</span><br><span class="line">  Normal  Scheduled               2m15s  default-scheduler                                         Successfully assigned default/test-pd to gke-my-first-cluster-default-pool-8ca613e9-w13m</span><br><span class="line">  Normal  SuccessfulAttachVolume  2m9s   attachdetach-controller                                   AttachVolume.Attach succeeded for volume &quot;test-volume&quot;</span><br><span class="line">  Normal  Pulling                 109s   kubelet, gke-my-first-cluster-default-pool-8ca613e9-w13m  pulling image &quot;k8s.gcr.io/test-webserver&quot;</span><br><span class="line">  Normal  Pulled                  107s   kubelet, gke-my-first-cluster-default-pool-8ca613e9-w13m  Successfully pulled image &quot;k8s.gcr.io/test-webserver&quot;</span><br><span class="line">  Normal  Created                 107s   kubelet, gke-my-first-cluster-default-pool-8ca613e9-w13m  Created container</span><br><span class="line">  Normal  Started                 107s   kubelet, gke-my-first-cluster-default-pool-8ca613e9-w13m  Started container</span><br></pre></td></tr></table></figure></li></ul></li></ul><p><strong>What are some important types of volumes?</strong></p><ul><li><p>emptyDir</p><ul><li>Not persistent</li><li>Created when pod is created on node</li><li>Initially empty</li><li>Share space/state across containers in same pod</li><li>Containers acan mount at different times</li><li>When pod removed/crashes, data lost</li><li>When container carshes data remains</li><li>Usecases: Scratch space, checkpointing…<br><img src="https://i.imgur.com/GGAyCl0.png" alt="emptyDir"></li></ul></li><li><p>hostPath<br><img src="https://i.imgur.com/pzfvzAb.png" alt="hostPath"></p><ul><li>Mount file/directory from node filesystem into pod</li><li>Uncommon- pods should be independent of nodes</li><li>Makes pod-node coupling tight</li><li>Usecases: Access docker internals, running cAdvisor</li><li>Block devices or sockets on host</li></ul></li><li><p>gitRepo<br><img src="https://i.imgur.com/EPHpRzS.png" alt="gitRepo"></p></li><li><p>configMap<br><img src="https://i.imgur.com/GkC7kjP.png" alt="conigMap"></p><ul><li>configMap volume mounts data from ConfigMap object</li><li>configMap objects define key-value pairs</li><li>configMap objects inject paramters into pods</li><li>Two main usecases:<ul><li>Providing config information for apps running inside pods</li><li>Specifying config information for control plane (controllers)</li></ul></li></ul></li><li><p>secret</p><ul><li>Pass ensitive inforamtion to pods</li><li>First create secret so it is stored in control plane<ul><li>kubectl create secret</li></ul></li><li>Mount that secret as a volume so that it is available inside pod</li><li>Secret is stored in RAM storage (not written to persistent disk)<h2 id="Lab-use-of-secrets-pass-information-to-pods"><a href="#Lab-use-of-secrets-pass-information-to-pods" class="headerlink" title="Lab: use of secrets pass information to pods"></a>Lab: use of secrets pass information to pods</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ cat secrets.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: test-secret</span><br><span class="line">data:</span><br><span class="line">  username: bXktYMxw</span><br><span class="line">  password: Mzk1MjqkdmRnN0pi</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ cat secrets-pod.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: secret-test-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: test-container</span><br><span class="line">      image: nginx</span><br><span class="line">      volumeMounts:</span><br><span class="line">         # name must match the volume name below</span><br><span class="line">         - name: secret-volume</span><br><span class="line">           mountPath: /etc/secret-volume</span><br><span class="line">  # The secret data is exposed to Containers in the Pod through a Volume.</span><br><span class="line">  volumes:</span><br><span class="line">    - name: secret-volume</span><br><span class="line">      secret:</span><br><span class="line">        secretName: test-secret</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ k get pod secret-test-pod</span><br><span class="line">NAME              READY   STATUS    RESTARTS   AGE</span><br><span class="line">secret-test-pod   1/1     Running   0          19m</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ k exec -it secret-test-pod -- /bin/bash</span><br><span class="line">root@secret-test-pod:/# cd /etc/secret-volume/</span><br><span class="line">root@secret-test-pod:/etc/secret-volume# ls</span><br><span class="line">password  username</span><br></pre></td></tr></table></figure></li></ul></li></ul><h1 id="Debugging"><a href="#Debugging" class="headerlink" title="Debugging"></a>Debugging</h1><h2 id="Insufficient-cpu"><a href="#Insufficient-cpu" class="headerlink" title="Insufficient cpu"></a>Insufficient cpu</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ k get pod secret-test-pod</span><br><span class="line">NAME              READY   STATUS    RESTARTS   AGE</span><br><span class="line">secret-test-pod   0/1     Pending   0          51s</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ k describe pod secret-test-pod</span><br><span class="line">Name:               secret-test-pod</span><br><span class="line">Namespace:          default</span><br><span class="line">Priority:           0</span><br><span class="line">PriorityClassName:  &lt;none&gt;</span><br><span class="line">Node:               &lt;none&gt;</span><br><span class="line">Labels:             &lt;none&gt;</span><br><span class="line">Annotations:        kubernetes.io/limit-ranger: LimitRanger plugin set: cpu request for container test-container</span><br><span class="line">Status:             Pending</span><br><span class="line">IP:</span><br><span class="line">Containers:</span><br><span class="line">  test-container:</span><br><span class="line">    Image:      nginx</span><br><span class="line">    Port:       &lt;none&gt;</span><br><span class="line">    Host Port:  &lt;none&gt;</span><br><span class="line">    Requests:</span><br><span class="line">      cpu:        100m</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /etc/secret-volume from secret-volume (rw)</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gw57h (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  Type           Status</span><br><span class="line">  PodScheduled   False</span><br><span class="line">Volumes:</span><br><span class="line">  secret-volume:</span><br><span class="line">    Type:        Secret (a volume populated by a Secret)</span><br><span class="line">    SecretName:  test-secret</span><br><span class="line">    Optional:    false</span><br><span class="line">  default-token-gw57h:</span><br><span class="line">    Type:        Secret (a volume populated by a Secret)</span><br><span class="line">    SecretName:  default-token-gw57h</span><br><span class="line">    Optional:    false</span><br><span class="line">QoS Class:       Burstable</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute for 300s</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason            Age                  From               Message</span><br><span class="line">  ----     ------            ----                 ----               -------</span><br><span class="line">  Warning  FailedScheduling  11s (x8 over 4m25s)  default-scheduler  0/1 nodes are available: 1 Insufficient cpu.</span><br><span class="line"></span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ gcloud container clusters resize my-first-cluster --num-nodes=3 --zone australia-southeast1-a</span><br><span class="line">Pool [default-pool] for [my-first-cluster] will be resized to 3.</span><br><span class="line"></span><br><span class="line">Do you want to continue (Y/n)?  Y</span><br><span class="line"></span><br><span class="line">Resizing my-first-cluster...done.</span><br><span class="line">Updated [https://container.googleapis.com/v1/projects/scenic-torch-250909/zones/australia-southeast1-a/clusters/my-first-cluster].</span><br><span class="line">stancloud9@cloudshell:~ (scenic-torch-250909)$ k get pod secret-test-pod</span><br><span class="line">NAME              READY   STATUS    RESTARTS   AGE</span><br><span class="line">secret-test-pod   1/1     Running   0          19m</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Kubernetes-on-the-GKE&quot;&gt;&lt;a href=&quot;#Kubernetes-on-the-GKE&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes on the GKE&quot;&gt;&lt;/a&gt;Kubernetes on the GKE&lt;/
      
    
    </summary>
    
    
      <category term="k8s" scheme="http://223.95.78.227/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>effective devops with aws</title>
    <link href="http://223.95.78.227/2019/08/16/effective-devops-with-aws/"/>
    <id>http://223.95.78.227/2019/08/16/effective-devops-with-aws/</id>
    <published>2019-08-15T14:15:29.000Z</published>
    <updated>2019-08-21T09:47:54.738Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Code</strong></p><p><a href="https://github.com/stanosaka/ansible">source code ansible</a><br><a href="https://github.com/00root/helloworld">source code helloworld</a></p><h1 id="Continuous-Delivery"><a href="#Continuous-Delivery" class="headerlink" title="Continuous Delivery"></a>Continuous Delivery</h1><p><img src="https://i.imgur.com/QOYWSYb.png" alt="codepipline01"><br><img src="https://i.imgur.com/an0PPjD.png" alt="codepipline02"><br><img src="https://i.imgur.com/P7gdZBo.png" alt="Source"><br><img src="https://i.imgur.com/O6LNT3M.png" alt="Test"><br><img src="https://i.imgur.com/gD0EYZ7.png" alt="Deploy"><br><img src="https://i.imgur.com/uAnMDQk.png" alt="Approval"><br><img src="https://i.imgur.com/OoeILa2.png" alt="Production"><br><img src="https://i.imgur.com/Mz3RM0I.png" alt="Jenkins01"><br><img src="https://i.imgur.com/88C8zGu.png" alt="Jenkins02"><br><img src="https://i.imgur.com/7YXnt5L.png" alt="Jenkins03"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm config set registry http://registry.npmjs.org/ </span><br><span class="line">npm install</span><br><span class="line">./node_modules/mocha/bin/mocha</span><br></pre></td></tr></table></figure></p><p><strong>Creating the new cloudformation stack for production</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">aws cloudformation create-stack --capabilities CAPABILITY_IAM --stack-name helloworld-production --template-body file://nodeserver-cf.template --parameters ParameterKey=KeyPair,ParameterValue=EffectiveDevOpsAWS</span><br><span class="line">aws cloudformation wait stack-create-complete --stack-name helloworld-production</span><br><span class="line">arn=$(aws deploy get-deployment-group --application-name helloworld --deployment-group-name staging --query &apos;deploymentGroupInfo.serviceRoleArn&apos;)</span><br><span class="line">aws deploy create-deployment-group --application-name helloworld --ec2-tag-filters Key=aws:cloudformation:stack-name,Type=KEY_AND_VALUE,Value=helloworld-production --deployment-group-name production --service-role-arn $arn</span><br><span class="line">aws deploy create-deployment-group --application-name helloworld --ec2-tag-filters Key=aws:cloudformation:stack-name,Type=KEY_AND_VALUE,Value=helloworld-production --deployment-group-name production --service-role-arn arn:aws:iam::012152306932:role/CodeDeployRole</span><br><span class="line">aws deploy list-deployment-groups --application-name helloworld</span><br><span class="line">aws sns create-topic --name production-deploy-approval</span><br><span class="line">aws sns subscribe --topic-arn arn:aws:sns:ap-southeast-2:012152306932:production-deploy-approval --protocol email --notification-endpoint foobar@gmail.com</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/stanosaka/ansible&quot;&gt;source code ansible&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/00root
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>vagrant</title>
    <link href="http://223.95.78.227/2019/08/03/vagrant/"/>
    <id>http://223.95.78.227/2019/08/03/vagrant/</id>
    <published>2019-08-03T13:35:53.000Z</published>
    <updated>2019-08-05T05:20:28.770Z</updated>
    
    <content type="html"><![CDATA[<p>Vagrant can be used for automatically provisioning VMs, and even whole development environments.</p><p>On ubuntu host:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install vagrant</span><br><span class="line">$ vagrant --version</span><br><span class="line">$ mkdir Vagrant;cd Vagrant</span><br><span class="line">$ vagrant init</span><br><span class="line"># Every Vagrant development environment requires a box. You can search for</span><br><span class="line">  # boxes at https://vagrantcloud.com/search.</span><br><span class="line">  config.vm.box = &quot;base&quot;</span><br><span class="line">$ sed -i &apos;s#config.vm.box = &quot;base&quot;#config.vm.box = &quot;centos/7&quot;#g&apos; Vagrantfile</span><br><span class="line">$ vagrant up</span><br><span class="line">$ vagrant ssh</span><br><span class="line">$ vagrant destroy</span><br></pre></td></tr></table></figure></p><p><strong>Components</strong></p><ul><li>Providers:<ul><li>Backend of Vagrant</li><li>VirtualBox</li><li>VMware</li><li>Hyper-V</li><li>vCloud</li><li>AWS</li></ul></li><li>Boxes:<ul><li>Predefined images</li><li><a href="https://app.vagrantup.com/boxes/search">Public Vagrant box catalog</a></li></ul></li><li>Vagrantfile:<ul><li>A Ruby file</li><li>How many VMs</li><li>Configure VMs</li><li>Provision VMs</li><li>Committed to version control<br><img src="https://i.imgur.com/lb7muP9.png" alt="example of Vagrantfile"></li></ul></li><li>Provisioners:<ul><li>Automatically install software, alter configurations</li><li>Boxes may not be a complete use case for you</li><li>Multiple options</li><li>Shell Script</li><li>Ansible</li><li>Chef</li><li>Docker</li><li>Puppet<br><img src="https://i.imgur.com/U5cISEK.png" alt="workflow of vagrant"></li></ul></li></ul><p><strong>Operations</strong></p><ul><li>Adding a vagrant box:<ul><li>Syntax: vagrant box add <name> <url> <provider></li><li>Example: vagrant box add ubuntu/trusty32</li></ul></li><li>Listing and removing vagrant boxes:<ul><li>vagrant box list</li><li>vagrant box remove</li></ul></li><li>Creating a VM environment:<ul><li>Syntax: vagrant init <your box name></li><li>Example: vagrant init ubuntu/trusty32</li></ul></li><li>Starting a VM environment:<ul><li>vagrant up ubuntu/trusty32</li><li>vagrant up </li></ul></li><li>Connecting:<ul><li>vagrant ssh ubuntu/trusty32</li><li>vagrant ssh</li></ul></li><li>Stopping, restarting, and destroying<ul><li>vagrant halt</li><li>vagrant reload</li><li>vagrant destroy</li></ul></li></ul><p><strong>Provisioning of vagrant</strong></p><ul><li>Creating a VM and provisioning it with Apache installed and prot forwarding</li><li><p>Add theses lines in Vagrantfile:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8080</span><br><span class="line">config.vm.provision &apos;shell&apos;, path: &apos;provision.sh&apos;</span><br></pre></td></tr></table></figure></li><li><p>Create provision.sh file with these entries:</p><ul><li>sudo apt-get update</li><li>sudo apt-get install -y apache2</li></ul></li><li><p>Destroy and start the virtual machine:</p><ul><li>vagrant destroy</li><li>vagrant up</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Vagrant can be used for automatically provisioning VMs, and even whole development environments.&lt;/p&gt;
&lt;p&gt;On ubuntu host:&lt;br&gt;&lt;figure class=
      
    
    </summary>
    
    
      <category term="vagrant" scheme="http://223.95.78.227/tags/vagrant/"/>
    
      <category term="Hashicorp" scheme="http://223.95.78.227/tags/Hashicorp/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins Pipeline</title>
    <link href="http://223.95.78.227/2019/07/29/jenkins-blue-ocean/"/>
    <id>http://223.95.78.227/2019/07/29/jenkins-blue-ocean/</id>
    <published>2019-07-29T01:00:54.000Z</published>
    <updated>2019-09-17T10:46:54.853Z</updated>
    
    <content type="html"><![CDATA[<h1 id="An-Example-of-Declarative-Pipeline"><a href="#An-Example-of-Declarative-Pipeline" class="headerlink" title="An Example of Declarative Pipeline:"></a>An Example of Declarative Pipeline:</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">       node &#123;</span><br><span class="line">           label <span class="string">'master'</span></span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(<span class="string">'Build'</span>) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh <span class="string">'mvn clean verify -DskipITs=true'</span></span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage (<span class="string">'Static Code Analysis'</span>) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh <span class="string">'mvn clean verify sonar:sonar'</span></span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage (<span class="string">'Publish to Artifactory'</span>) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               script &#123;</span><br><span class="line">                   def server = Artifactory.server <span class="string">'Default Artifactory'</span></span><br><span class="line">                   def uploadSpec = <span class="string">""</span><span class="string">"&#123;</span></span><br><span class="line"><span class="string">                       "</span>files<span class="string">": [</span></span><br><span class="line"><span class="string">                           &#123;</span></span><br><span class="line"><span class="string">                               "</span>pattern<span class="string">": "</span>target/*.war<span class="string">",</span></span><br><span class="line"><span class="string">                               "</span>target<span class="string">": "</span>helloworld/<span class="variable">$&#123;BUILD_NUMBER&#125;</span>/<span class="string">",</span></span><br><span class="line"><span class="string">                               "</span>pattern<span class="string">": "</span>Unit-Tested=Yes<span class="string">",</span></span><br><span class="line"><span class="string">                           &#125;</span></span><br><span class="line"><span class="string">                        ]</span></span><br><span class="line"><span class="string">                    &#125;"</span><span class="string">""</span></span><br><span class="line">                    server.upload(uploadSpec)</span><br><span class="line">&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Jenkinsfile</strong><br>A Jenkinsfile is a file that contains Pipeline code.</p><h1 id="Shared-Library"><a href="#Shared-Library" class="headerlink" title="Shared Library"></a>Shared Library</h1><p>A Jenkins Shared Library is an external source control repository containing your complex Groovy code. It acts like a function that could be used on-demand inside your Declarative Pipeline.</p><p><em>A Groovy Script (example.groovy)Inside Jenkins Shared Library Repository:</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def greet(message) &#123;</span><br><span class="line">   echo &quot;Hello $&#123;message&#125;, welcome to Jenkins Blue Ocean.&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em>Jenkins Declarative Pipeline Utilizing the Shared Library:</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@Library(&apos;Example_shared_Library&apos;) _</span><br><span class="line"></span><br><span class="line">pipeline &#123;</span><br><span class="line">  agent none</span><br><span class="line">  stage (&apos;Example&apos;) &#123;</span><br><span class="line">     steps &#123;</span><br><span class="line">        script &#123;</span><br><span class="line">           example.greet &apos;Readers&apos;</span><br><span class="line">        &#125;</span><br><span class="line">     &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="Setting-up-Jenkins-Blue-Ocean"><a href="#Setting-up-Jenkins-Blue-Ocean" class="headerlink" title="Setting up Jenkins Blue Ocean"></a>Setting up Jenkins Blue Ocean</h1><h2 id="Setting-up-Blue-Ocean-using-docker"><a href="#Setting-up-Blue-Ocean-using-docker" class="headerlink" title="Setting up Blue Ocean using docker"></a>Setting up Blue Ocean using docker</h2><p><strong>Downloading the latest Jenkins Blue Ocean</strong></p><ol><li><p>docker pull jenkinsci/blueocean</p></li><li><p>To list the downloaded docker image: docker images</p></li></ol><p>Docker containers generate and use data. When a container gets deleted, its relevant data also gets lost.<br>To make the data persistent, we use docker volumes.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker volume create jenkins_home</span><br><span class="line">docker volume ls</span><br><span class="line">docker volume inspect jenkins_home <span class="comment">#get detailed info about docker volume</span></span><br></pre></td></tr></table></figure></p><h2 id="Run-Jenkins-blue-ocrean-behind-a-reverse-proxy"><a href="#Run-Jenkins-blue-ocrean-behind-a-reverse-proxy" class="headerlink" title="Run Jenkins blue ocrean behind a reverse proxy"></a>Run Jenkins blue ocrean behind a reverse proxy</h2><ol><li><p>Run a Jenkins container</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name jenkins -v jenkins_home:/var/jenkins_home jenkinsci/blueocean</span><br></pre></td></tr></table></figure></li><li><p>Download the docker image for Nginx</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nginx</span><br></pre></td></tr></table></figure></li><li><p>Spawn a Dockr container for Nginx. Also, link the nginx container to the jenkins container using the <em>–link</em> option.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name ngingx -p 80:80 --link jenkins nginx</span><br></pre></td></tr></table></figure></li><li><p>Get inside the Ningx container using the <em>docker exec</em> command</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it ningx /bin/bash</span><br></pre></td></tr></table></figure></li><li><p>Update the Ubuntu package lists<br><code>apt-get update</code></p></li><li>Install vim text editor<br><code>apt-get install vim</code></li><li><p>Take the backup of the default.conf file inside /etc/nginx/conf.d/</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp etc/ningx/conf.d/default.conf etc/nginx/conf.d/default.conf.backup</span><br></pre></td></tr></table></figure></li><li><p>Next, replace the content of the default.conf file with the following:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">upstream jenkins &#123;</span><br><span class="line">  server jenkins:8080;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">  listen 80;</span><br><span class="line">  server_name jenkins.example.com;</span><br><span class="line">  </span><br><span class="line">  location / &#123;</span><br><span class="line">     proxy_pass         http://jenkins;</span><br><span class="line">     proxy_set_header   Host <span class="variable">$host</span>;</span><br><span class="line">     proxy_set_header   X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">     proxy_set_header   X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">     proxy_set_header   X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Exit the Nginx container.<br><code>exit</code></p></li><li>Restart the Nginx container.<br><code>docker restart nginx</code></li><li>Run the following docker command to fetch the content of initialAdminPassword file.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it jenkins /bin/bash -c \ <span class="string">"cat /var/jenkins_home/secrets/initialAdminPassword"</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="Creating-Pipeline"><a href="#Creating-Pipeline" class="headerlink" title="Creating Pipeline"></a>Creating Pipeline</h1><p><strong>Prerequisites</strong>     </p><ol><li>fork <a href="https://github.com/Apress/beginning-jenkins-blue-ocean/tree/master/Ch03/example-maven-project">example maven project</a></li><li>pulling the docker image for jenkins agent<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nikhilpathania/jenkins_ssh_agent</span><br></pre></td></tr></table></figure></li></ol><p>The docker image is based on Ubuntu and comes with Git,Java JDK, Maven, and sshd installed.<br>The image also contains a user account named <em>jenkins</em>.</p><p><strong>Creating credentials for the docker image in Jenkins</strong><br>Add credentials inside Jenkins that allow it to interact with the docker image nikhilpathania/jenkins_ssh_agent</p><ol><li>Classic Jenkins dashboard -&gt; Credentials-&gt; System-&gt; Global credential (unrestricted).</li><li>Add Credentials</li><li>Options<ol><li>Kind: Username with password</li><li>Username: the username to interact with the docker image: jenkins</li><li>Password: the password to interact with the docker image: jenkins</li><li>ID: add a meaningful name to recognize these credentials.</li><li>Descritpion: Add a meaningful description for these credentials.<br><img src="https://i.imgur.com/pFaHQuZ.png" alt="configuring the credential"><br><strong>Installing the docker plugin</strong><br>To spawn on-demand docker containers serving as Jenkins agents, need to install the docker plugin<br><img src="https://i.imgur.com/nUi1uKk.png" alt="Installing the Docker Plugin for Jenkins">   </li></ol></li></ol><p><strong>Configuring the docker plugin</strong><br>Manage Jenkins-&gt; Configure System-&gt; Cloud-&gt; Add a new cloud-&gt; Docker</p><p>Options to configure:</p><ol><li>Docker Host URI: This is the URL used by Jenkins to talk to the docker host.</li></ol><hr><p><strong>ENABLING DOCKER REMOTE API (CRITICAL)</strong><br>The Docker remote API allows external applications to communicate with the Docker server using REST APIs . Jenkins (through the Docker Plugin) uses the docker remote API to communicate with a docker host.</p><p>To enable the Docker remote API on your Docker host, you’ll need to modify Docker’s configuration file. Depending on your OS version and the way you have installed Docker on your machine, you might need to choose the right configuration file to modify. Shown here are two methods that work on Ubuntu. Try them one by one.</p><p><strong>Modifying the docker.conf File</strong><br>Follow these steps to modify the docker.conf file :</p><ol><li>Log in to your docker server; make sure you have sudo privileges.</li></ol><ol start="2"><li>Execute the following command to edit the file docker.conf :</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /etc/init/docker.conf</span><br></pre></td></tr></table></figure><ol start="3"><li>Inside the docker.conf file, go to the line containing “DOCKER_OPTS=” .</li></ol><p>You’ll find “DOCKER_OPTS=” variable at multiple places inside the docker.conf file. Use the DOCKER_OPTS= that is available under the pre-start script or script section.</p><ol start="4"><li>Set the value of DOCKER_OPTS as shown here. Do not copy and paste; type it all in a single line.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DOCKER_OPTS=&apos;-H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock&apos;</span><br></pre></td></tr></table></figure></li></ol><p>The above setting binds the Docker server to the UNIX socket as well on TCP port 4243.</p><p>“0.0.0.0” makes Docker engine accept connections from anywhere. If you would like your Docker server to accept connections only from your Jenkins server, then replace “0.0.0.0” with your Jenkins Server IP.</p><ol start="5"><li>Restart the Docker server using the following command:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure></li></ol><ol start="6"><li>To check if the configuration has worked, execute the following command. It lists all the images currently present on your Docker server.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X GET http://&lt;Docker Server IP&gt;:4243/images/json</span><br></pre></td></tr></table></figure></li></ol><ol start="7"><li>If this command does not return a meaningful output, try the next method.</li></ol><p><strong>Modifying the docker.service File</strong><br>Follow these steps to modify the docker.service file :</p><ol><li>Execute the following command to edit the docker.service file.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /lib/systemd/system/docker.service</span><br></pre></td></tr></table></figure></li></ol><ol start="2"><li>Inside the docker.service file, go to the line containing ExecStart= and set its value as shown here. Do not copy and paste; type it all in a single line.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ExecStart=/usr/bin/dockerd -H fd:// -H tcp://0.0.0.0:4243</span><br></pre></td></tr></table></figure></li></ol><p>The above setting binds the docker server to the UNIX socket as well on TCP port 4243.</p><p>“0.0.0.0” makes the Docker engine accept connections from anywhere. If you would like your Docker server to accept connections only from your Jenkins server, then replace “0.0.0.0” with your Jenkins Server IP.</p><ol start="3"><li>Execute the following command to make the Docker demon notice the modified configuration:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br></pre></td></tr></table></figure></li></ol><ol start="4"><li>Restart the Docker server using the below command:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure></li></ol><ol start="5"><li>To check if the configuration has worked, execute the following command. It lists all the images currently present on your Docker server.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X GET http://&lt;Docker Server IP&gt;:4243/images/json</span><br></pre></td></tr></table></figure></li></ol><hr><ol start="2"><li>Server Credentials: If your docker host requireds a login, you need to add the credentials to Jenkins using the <strong>Add</strong> button. However, do nothing if you are using a docker host that’s running your Jenkins server container.</li><li>Test Connection: Click on this to test the communication between your Jenkins server and the docker host. You should see the docker version and the API version [4] if the connection is successful.</li><li>Enabled: A checkbox to enable/disable the current configuration.<br><img src="https://i.imgur.com/RKOm2V2.png" alt="Configuring the Docker host URI and testing the connection"></li></ol><p><strong>Add Docker Template</strong> button. Click on it to configure the docker image that Jenkins shoudl use to spawn container.<br><img src="https://i.imgur.com/6NOb5kY.png" alt="docker template figure"></p><ol><li>Labels: The label that you type in under the Labels field gets used inside your Pipeline to define agents for your stages. In this way, Jenkins knows that it has to use docker to spawn agents. </li><li>Enabled: This checkbox is used to enable/disable the current configuration. </li><li>Docker Image: Add the name of the docker image that should be used to spawn agents containers. </li><li>Remote File System Root: This is the directory inside the container that holds the workspace of the Pipeline that runs inside it. </li><li>Usage: We would like only to build pipelines that have the right agent label, in our case it is docker.</li><li>Connect method : Choose to Connect with SSH option to allow Jenkins to connect with the container using the SSH protocol.</li><li>SSH Key: Choose use configured SSH credentials from the options to use the SSH credentials as the preferred mode of authentication.</li><li>SSH Credentials: From the list of options choose the credentials that you have created earlier, in the section: Creating Credentials for the Docker Image in Jenkins.</li><li>Host Key Verification Strategy: Choose Non verifying Verification Strategy to keep things simple. However, this is not the recommended setting for a production Jenkins server.<h1 id="Using-the-pipeline-creation-wizard-configure-Jenkins-Blue-Ocean-with-various-types-of-source-code-repositories"><a href="#Using-the-pipeline-creation-wizard-configure-Jenkins-Blue-Ocean-with-various-types-of-source-code-repositories" class="headerlink" title="Using the pipeline creation wizard, configure Jenkins Blue Ocean with various types of source code repositories."></a>Using the pipeline creation wizard, configure Jenkins Blue Ocean with various types of source code repositories.</h1><h1 id="Using-the-Visual-Pipeline-Editor-to-design-Pipeline"><a href="#Using-the-Visual-Pipeline-Editor-to-design-Pipeline" class="headerlink" title="Using the Visual Pipeline Editor to design Pipeline."></a>Using the Visual Pipeline Editor to design Pipeline.</h1></li></ol><ul><li>Downloads the source code from the Github repository</li><li>Performs a build and some testing</li><li>Publishes the testing results under the Pipeline’s Test page</li><li>Uploads the built artifact to Henkins Blue Ocean</li></ul><p><strong>Assigning a global agent</strong><br>The pipeline that you are going to create should have two stages, and each stage is supposed to run inside a docker<br>container. You’ll define the agents for each stage sparately in the stage’s settings.<br>Therefore, let’s keep the Pipeline’s global agent setting to none.<br><img src="https://i.imgur.com/fBKsY4k.png" alt="Assigning a global agent"></p><p><strong>Creating a build &amp; test stage</strong><br>Type in the name <strong>Build &amp; Test</strong> for your stage.<br><img src="https://i.imgur.com/SOXKlCZ.png" alt="Naming your stage"></p><p><strong>Adding steps</strong><br>Let’s add some steps to our <strong>Build &amp; Test</strong> stage.<br><img src="https://i.imgur.com/FR5koOy.png" alt="Adding a new step"><br><strong>Adding a shell script setp</strong><br>Our source code is a Maven project, and we would like to build and test it using an mvn command, which eventually<br>gets executed inside a shell on the Jenkins agent.<br><img src="https://i.imgur.com/zdRO91W.png" alt="Adding a shell script step"><br>Paste the below code which is a maven command to build, test, and create a package out of your source code.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn -Dmaven.test,failure,ignore clean package</span><br></pre></td></tr></table></figure></p><p><strong>Adding a stash step to pass artifact between stages</strong><br>Add another step to stash the build package and the testing report generated by the maven command.<br>Look for the step <strong>Stash some files to be used later in the build</strong><br><img src="https://i.imgur.com/yguB0hB.png" alt="Adding a Stash step"></p><p>Add the name “build-test-artifacts” fro your stash using the Name<em> field, which is mandatory.<br>Add the following to the Included field: **/target/surefire-reports/TEST-</em>.xml,target/*.jar</p><p>With this configuration you are telling Jenkins to stash any .jar file (build package) from the target directory,<br>and the TEST-*.xml file(test report) from the <code>**/target/surefire-reports/</code> directory on the build agent.<br><img src="https://i.imgur.com/ZtwyY00.png" alt="configuring a Stash step"></p><p>piple line code so far:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent none</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(&apos;Build &amp; Test&apos;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &apos;mvn -Dmaven.test.failure.ignore clean package&apos;</span><br><span class="line">                stash(name: &apos;build-test-artifacts&apos;, \</span><br><span class="line">                includes: &apos;**/target/surefire-reports/TEST-*.xml,target/*.jar&apos;)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>Assigning an agent for the build &amp; test stage</strong><br>You’ll assign a build agent for your <strong>Build &amp; Test</strong> stage. The agent is going to be a docker container that will be spawn automatically by Jenkins. ONce the stage is complete, Jenkins will destroy the container.<br><img src="https://i.imgur.com/8QGv9eH.png" alt="assigning an agent to a stage"><br>With the following configuration, Jenkins looks for an agent with the label <strong>docker</strong>. Remember the section, wherein you configured the docker plugin in Jenkins. You specified the label <strong>docker</strong> while configure the <strong>Docker Agent<br>Template</strong>.</p><p><strong>Creating a report &amp; publish stage</strong><br>Add another stage named <strong>Report &amp; Publish</strong> that will publish the testing results on the <strong>Test</strong> page of the Pipeline and that will publish the build package on the <strong>Artifacts</strong> page of the pipeline.<br><img src="https://i.imgur.com/1wyyhNT.png" alt="Naming your stage"></p><p><strong>Adding an un-stash step</strong><br>Before we do anything in the <strong>Report &amp; Publish</strong> stage. it is first crucial to un-stash the files that were stashed<br>in the previous stage. So let’s add step to un-stash a stash from the previous stage.<br><img src="https://i.imgur.com/e0XDMmW.png" alt="Adding a restore files previously stashed step"><br>You’ll see a text field Name* where you should paste the name of your stash precisely as it was defined during its<br>creation.<br><img src="https://i.imgur.com/O5Do1D7.png" alt="Configuring the Restore files previously stashed step"></p><p><strong>Report testing results</strong><br>The stash contains a JUnit test results .xml file that you’ll publish on the pipeline’s Test page. For this, we need<br>to add a step named <strong>Archive Junit-formatted test results</strong></p><p>Use the TestResults<em> field to provide Jenkins with the path to your JUnit test result file. In our case, it is<br>`**/target/surefire-reports/TEST-</em>.xml`</p><p><img src="https://i.imgur.com/Skz6Yg7.png" alt="Configuring an Archive Junit-formatted test results step"></p><p><strong>Upload artifacts to blue ocean</strong><br>Add a step that will upload the build package to the Pipleine’s Artifacts page. From the un-stashed files, you also<br>have a .jar file that is the build package.</p><p>To upload it to the Pipeline Artifacts page, use the <strong>Archive the artifacts</strong> step.<br>Use the Artifacts<em> filed to provide Jenkins with the path to your build package file. In our case, it is target/</em>.jar.Also, tick the option OnlyIfSuccessful to upload the artifacts only if the Pipeline status is green or yellow.<br><img src="https://i.imgur.com/X1ogakY.png" alt="Configuring the Archive the Artifacts step"> </p><p><strong>Assigning an aget for the report &amp; publish stage</strong><br>you’ll assign a build agent for your Report &amp; Publish stage. The agent is going to be a docker container that will be spawn automatically by Jenkins. Once the stage is complete, Jenkins will destroy the container.</p><p><img src="https://i.imgur.com/zg4Jc5G.png" alt="Assigning an agent to a stage"></p><p>You are new done with creating the pipeline. To save the changes, click on the Save button.</p><p>When you click on the <strong>Save</strong> button, Jenkins in the back end converts your UI configurations into a Jenkinsfile that follows the Declarative Pipeline Syntax.</p><p><img src="https://i.imgur.com/2HYkBP5.png" alt="Committing your pipeline configurations changes"></p><p><strong>Run an artifactory server</strong><br>To spawn an Artifactory server with docker. Artifactory is a popular tool to manage and version control software build artifacts. </p><ol><li>Log in to your docker host</li><li>docker volume create –name artifactory_data</li><li>docker pull docker.bintray.io/jfrog/artifactory-oss:latest  # downloading the latest version of Artifactory community edition</li><li>docker run –name artifactory -d -v artifactory_data:/var/opt/jfrog/ -p 8081:8081 docker.bintray.io/jfrog/artifactory-oss:latest</li><li>access your Artifactory server: http://&lt;Docker_host_ip&gt;:8081/artifactory/webapp/#/home</li><li>using the admin credentials (username: admin, and password as password). Note the default example repository in Artifactory named example-repo-local.</li></ol><p><strong>Installing the artifactory plugin for jenkins</strong><br>Manage Jenkins-&gt; Manage Plugins-&gt; Artifactory</p><p><strong>Configuring the artifactory plugin in jenkins</strong><br><img src="https://i.imgur.com/2HYkBP5.png" alt="configuring the artifactory plugin"></p><p><strong>Creating a Publish to Artifactory Stage (Parallel Stage)</strong><br>Add a stage in parallel to existing <strong>Report &amp; Publish</strong> stage.<br><img src="https://i.imgur.com/HAq6sYq.png" alt="creating a new stage"><br><img src="https://i.imgur.com/vXUpngZ.png" alt="naming your stage"><br>Your new stage first downloads the stash files from the previous stage, and then it publishes the built artifacts to<br>the Artifactory server.</p><p><strong>Adding a scripted pipeline step</strong><br>does two things</p><ol><li>it fetches the stash files from the previous stage.</li><li>it runs a filespec that uploads the build package to the Artifactory server.<br><img src="https://i.imgur.com/9W9fTUQ.png" alt="add a scripted pipeline step"><br>Script to Un-Stash Built Artifacts and Upload Them to the Artifactory Server<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">unstash &apos;build-test-artifacts&apos;</span><br><span class="line">def server = Artifactory.server &apos;Artifactory&apos;</span><br><span class="line">def uploadSpec = &quot;&quot;&quot;&#123;</span><br><span class="line">  &quot;files&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;pattern&quot;: &quot;target/*.jar&quot;,</span><br><span class="line">      &quot;target&quot;: &quot;example-repo-local/$&#123;BRANCH_NAME&#125;/$&#123;BUILD_NUMBER&#125;/&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;&quot;&quot;&quot;</span><br><span class="line">server.upload(uploadSpec)</span><br></pre></td></tr></table></figure></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">███████╗██╗  ██╗██████╗ ██╗      █████╗ ██╗███╗   ██╗</span><br><span class="line">██╔════╝╚██╗██╔╝██╔══██╗██║     ██╔══██╗██║████╗  ██║</span><br><span class="line">█████╗   ╚███╔╝ ██████╔╝██║     ███████║██║██╔██╗ ██║</span><br><span class="line">██╔══╝   ██╔██╗ ██╔═══╝ ██║     ██╔══██║██║██║╚██╗██║</span><br><span class="line">███████╗██╔╝ ██╗██║     ███████╗██║  ██║██║██║ ╚████║</span><br><span class="line">╚══════╝╚═╝  ╚═╝╚═╝     ╚══════╝╚═╝  ╚═╝╚═╝╚═╝  ╚═══╝</span><br></pre></td></tr></table></figure><p>The code line unstash ‘build-test-artifacts’ downloads the previously stashed package. The rest of the code is a Filespec that uploads the target/*jar file, which is our built package file, to the Artifactory server on the repository example-repo-local.</p><p>Notice that the target path contains Jenkins Global variables, ${BRANCH_NAME} and ${BUILD_NUMBER}, representing the branch name and build number, respectively. Doing so uploads the built artifacts to a unique path on Artifactory every single time a pipeline runs.</p><p><strong>Assigning an Agent for the Publish to Artifactory Stage</strong><br>you’ll assign a build agent for your Publish to Artifactory stage. The agent is going to be the docker container that gets spawned automatically by Jenkins. Once the stage is complete, Jenkins destroys the container.<br><img src="https://i.imgur.com/l3VMpHu.png" alt="Assigning an agent to a stage"></p><p>Final pipeline code:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  agent none</span><br><span class="line">  stages &#123;</span><br><span class="line">    stage(&apos;Build &amp; Test&apos;) &#123;</span><br><span class="line">      agent &#123;</span><br><span class="line">        node &#123;</span><br><span class="line">          label &apos;docker&apos;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">      steps &#123;</span><br><span class="line">        sh &apos;mvn -Dmaven.test.failure.ignore clean package&apos;</span><br><span class="line">        stash(name: &apos;build-test-artifacts&apos;, includes: &apos;**/target/surefire-reports/TEST-*.xml,target/*.jar&apos;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(&apos;Report &amp; Publish&apos;) &#123;</span><br><span class="line">      parallel &#123;</span><br><span class="line">        stage(&apos;Report &amp; Publish&apos;) &#123;</span><br><span class="line">          agent &#123;</span><br><span class="line">            node &#123;</span><br><span class="line">              label &apos;docker&apos;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">          steps &#123;</span><br><span class="line">            unstash &apos;build-test-artifacts&apos;</span><br><span class="line">            junit &apos;**/target/surefire-reports/TEST-*.xml&apos;</span><br><span class="line">            archiveArtifacts(artifacts: &apos;target/*.jar&apos;, onlyIfSuccessful: true)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&apos;Publish to Artifactory&apos;) &#123;</span><br><span class="line">          agent &#123;</span><br><span class="line">            node &#123;</span><br><span class="line">              label &apos;docker&apos;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">          steps &#123;</span><br><span class="line">            script &#123;</span><br><span class="line">              unstash &apos;build-test-artifacts&apos;</span><br><span class="line"></span><br><span class="line">              def server = Artifactory.server &apos;Artifactory&apos;</span><br><span class="line">              def uploadSpec = &quot;&quot;&quot;&#123;</span><br><span class="line">                &quot;files&quot;: [</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;pattern&quot;: &quot;target/*.jar&quot;,</span><br><span class="line">                    &quot;target&quot;: &quot;example-repo-local/$&#123;BRANCH_NAME&#125;/$&#123;BUILD_NUMBER&#125;/&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                ]</span><br><span class="line">              &#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">              server.upload(uploadSpec)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><img src="https://i.imgur.com/id9vL50.png" alt="Committing your pipeline configurations changes"><br><img src="https://i.imgur.com/Ec4LinF.png" alt="build artifact uploaded to Artifactory"></p><p><strong>Running a pipeline for a pull requrest</strong><br>Jenkins Blue Ocean can detect pull requests on your Github repositories and run a pipeline with it for you. The<br>pipeline run result (fail/pass/canceled) gets reported back to your source code repository.</p><p>The person who is reponsible for accepting the pull request can then decide based on the pipeline run result whether<br>he should merge the new changes into the destination branch or not.<br><img src="https://i.imgur.com/kUvGGZM.jpg" alt="pull request"></p><h2 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h2><p>pull requests not showing<br>fix by: <img src="https://i.imgur.com/63ETSbk.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;An-Example-of-Declarative-Pipeline&quot;&gt;&lt;a href=&quot;#An-Example-of-Declarative-Pipeline&quot; class=&quot;headerlink&quot; title=&quot;An Example of Declarativ
      
    
    </summary>
    
    
      <category term="Jenkins" scheme="http://223.95.78.227/tags/Jenkins/"/>
    
      <category term="Devops" scheme="http://223.95.78.227/tags/Devops/"/>
    
      <category term="CD/CI" scheme="http://223.95.78.227/tags/CD-CI/"/>
    
      <category term="Pipeline" scheme="http://223.95.78.227/tags/Pipeline/"/>
    
      <category term="Blue Ocean" scheme="http://223.95.78.227/tags/Blue-Ocean/"/>
    
  </entry>
  
  <entry>
    <title>LinuxSystemAdmin</title>
    <link href="http://223.95.78.227/2019/07/23/LinuxSystemAdmin/"/>
    <id>http://223.95.78.227/2019/07/23/LinuxSystemAdmin/</id>
    <published>2019-07-22T23:00:22.000Z</published>
    <updated>2019-09-19T06:48:35.263Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TCP-IP-networking"><a href="#TCP-IP-networking" class="headerlink" title="TCP/IP networking"></a>TCP/IP networking</h1><h2 id="Troubleshoot-networking"><a href="#Troubleshoot-networking" class="headerlink" title="Troubleshoot networking"></a>Troubleshoot networking</h2><p><strong>Tools for troubleshooting the network</strong></p><ul><li><em>ping</em> - ICMP echo requests<br><img src="https://i.imgur.com/RcrCjea.jpg" alt="ping -I eth1 192.168.10.12"></li><li><em>traceroute</em> and <em>tracepath</em> - Trace the path taken to a given host</li><li><em>netcat</em> - Arbitrary TCP and UDP network communication<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">stan@stan-virtual-machine:~$ ifconfig</span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 00:0c:29:a2:c2:5d  </span><br><span class="line">          inet addr:192.168.199.107  Bcast:192.168.199.255  Mask:255.255.255.0</span><br><span class="line">          inet6 addr: fe80::20c:29ff:fea2:c25d/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:109798 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:34545 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:53893408 (53.8 MB)  TX bytes:15357635 (15.3 MB)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          inet6 addr: ::1/128 Scope:Host</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:5917 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:5917 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:1699426 (1.6 MB)  TX bytes:1699426 (1.6 MB)</span><br><span class="line"></span><br><span class="line">stan@stan-virtual-machine:~$ nc -l 8000</span><br><span class="line">nc -v -z 192.168.199.107 8000</span><br><span class="line">Connection to 192.168.199.107 8000 port [tcp/*] succeeded!</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://i.imgur.com/60o3bav.png" alt="nc"></p><ul><li><em>tcpdump</em> and <em>wireshark</em> - Packet captures for network analysis<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"> nc -l 8000 &amp;</span><br><span class="line">[1] 20393</span><br><span class="line">➜  ~ sudo tcpdump -i enp2s0 port 8000</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on enp2s0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">Hi</span><br><span class="line">[1]  + 20393 done       nc -l 8000</span><br><span class="line">09:52:41.674092 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [S], seq 3581133462, win 29200, options [mss 1460,sackOK,TS val 12349350 ecr 0,nop,wscale 7], length 0</span><br><span class="line">09:52:41.674180 IP stan-OptiPlex-380.lan.8000 &gt; stan-virtual-machine.lan.57089: Flags [S.], seq 2419171515, ack 3581133463, win 28960, options [mss 1460,sackOK,TS val 2113949133 ecr 12349350,nop,wscale 7], length 0</span><br><span class="line">09:52:41.674412 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [.], ack 1, win 229, options [nop,nop,TS val 12349351 ecr 2113949133], length 0</span><br><span class="line">09:52:41.674518 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [P.], seq 1:4, ack 1, win 229, options [nop,nop,TS val 12349351 ecr 2113949133], length 3</span><br><span class="line">09:52:41.674541 IP stan-OptiPlex-380.lan.8000 &gt; stan-virtual-machine.lan.57089: Flags [.], ack 4, win 227, options [nop,nop,TS val 2113949133 ecr 12349351], length 0</span><br><span class="line">09:52:41.674582 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [F.], seq 4, ack 1, win 229, options [nop,nop,TS val 12349351 ecr 2113949133], length 0</span><br><span class="line">09:52:41.674718 IP stan-OptiPlex-380.lan.8000 &gt; stan-virtual-machine.lan.57089: Flags [F.], seq 1, ack 5, win 227, options [nop,nop,TS val 2113949133 ecr 12349351], length 0</span><br><span class="line">^C</span><br><span class="line">7 packets captured</span><br><span class="line">8 packets received by filter</span><br><span class="line">1 packet dropped by kernel</span><br><span class="line"></span><br><span class="line">stan@stan-virtual-machine:~$ echo Hi| nc 192.168.199.178 8000</span><br><span class="line">tcpdump -i eth1 port 8000 and not port 22 and not icmp</span><br><span class="line">tcpdump -i eth1 not udp 53</span><br><span class="line">tcpdump -nX -i eth1 port 8000</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://i.imgur.com/D7Vewu7.jpg" alt="tcpdump"><br><img src="https://i.imgur.com/4WIQHtZ.png" alt="tcp three-way handshake"></p><h2 id="Backup-and-streaming"><a href="#Backup-and-streaming" class="headerlink" title="Backup and streaming"></a>Backup and streaming</h2><p><strong>What to expect from a backup tool?</strong></p><ul><li>Any backup solution should -roughly- provide the following:</li><li>Full and incrementail backups</li><li>File permissions and ownership preservation</li><li>The ability to be automated</li></ul><p><strong>Introducing rsync</strong></p><ul><li>Rsync is native Linux tool that can be deployed from the official repositories</li><li>It supports incremental and full backups- It transfers files over SSH</li><li>It can be automated via cron jobs to run in unattended mode.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type rsync</span><br><span class="line">rsync -zvr simple-php-website/ ~/backup/</span><br><span class="line">sudo rsync -azv simple-php-website/ ~/backup/ # backup with file created time stampe and ownership</span><br></pre></td></tr></table></figure></li></ul><p><strong>using rsync over the network</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rsync -azv simple-php-website/ pi@rpi-01:~/backup/</span><br><span class="line">rsync -azv  pi@rpi-01:~/backup/ simple-php-website</span><br></pre></td></tr></table></figure></p><p><strong>advanced ssh options with rsync</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">ssh-copy-id pi@rpi-01 </span><br><span class="line">rsync -avz -e &quot;ssh -p 2222&quot; simple-php-website/ pi@rpi-01:~/backup/ # specify the ssh port</span><br><span class="line">rsync -azv --existing simple-php-website/ pi@rpi-01:~/backup/ ## only sync the file existing in destnation</span><br><span class="line">rsync -avzi simple-php-website/ pi@rpi-01:~/backup/ # i show what has been changed in source and destnation</span><br><span class="line">dd if=/dev/zero of=data.bin bs=102400 count=10240</span><br><span class="line">rsync -azv --progress simple-php-website/ pi@rpi-01:~/backup/ #show the transfers info</span><br><span class="line">rsync -azv --include &apos;*.php&apos; --exclude &apos;*.jpg&apos; simple-php-website/ pi@rpi-01:~/backup/</span><br><span class="line"></span><br><span class="line">```  </span><br><span class="line">## Performance Analysis</span><br><span class="line">**How to improve performance?**</span><br><span class="line">- The following are general guidelines for achieving a higher performance level on a typical Linux box:</span><br><span class="line">  - Make sure that you have enough memory to serve the running applications</span><br><span class="line">  - Use softwre or hardware load balancing systems. They not only provide faster responses from network applications, but they also provide redundancy should one of the servers go down undexpectedly.</span><br><span class="line">  - Review the application specific documentation and configuration files. Some settings may dramatically boost application performance like turning on caching in webservers or unning multiple instances of a network application.</span><br><span class="line">  - Avoid storage I/O bottlnecks by installing faster disks like SSD&apos;s, which do not depend on mechanically moving parts to offer much higher read/write speed than their old counterparts.</span><br><span class="line">  - Use technologies like RAID to distribute I/O evenly on disks (like striping). However, not all applications/databases benefit from striping and RAID and sometimes this my lead to negative results. Application and database vendor and/or documentation should be consulted before moving to RAID.</span><br><span class="line">  - Keep an eye on the network bandwidth and errors to ensure that the bandwidth is not saturated and that the error rate is at the minimum</span><br><span class="line">**Possible causes of bottlenecks**</span><br><span class="line">- Hardware-wise, performance is affected mainly by one or more of the following system components: CPU, memory, and disk and network I/O.</span><br><span class="line">- Processes running on the system must access the above components. They compete to have, for example a CPU cycle or an I/O from the disk to read to write data. If the component is busy, the process will have to wait for its trun to be served. This wait time means that the sytem will run slower and implies that are have a performance issue.</span><br><span class="line">**Check your resources**</span><br><span class="line">- Before addressing a performance degradation problem, you must first check your assets to have an estimate of the upper bound for system&apos;s general performance level</span><br><span class="line">- The following files provide hardware information:</span><br><span class="line">  - /proc/cpuinfo: take note of the vendor ID, cpu family, model and model name. Each processor core will have a stanza of its own. Useful information can be extracted from the CPU flags like ht which means that the CPU is using the hyper threading technology.</span><br><span class="line">  - /proc/meminfo: details on total, used, and free memeory</span><br><span class="line">  - /proc/diskstats: disk devices statistics</span><br><span class="line">- Another useful command for this purpose if dmidecode. This will print a lot of hardware information about the machine like the mothermoard type, BIOS version, installed memory amont many other information.</span><br><span class="line">**Using vmstat to measure CPU utilization**</span><br><span class="line">- When meansuring CPU performance, you may want to determine the overall CPU utilization to know whether or not the overall clock speed is the problem, load averages may also aid you in this. In addition, you may want to check perprocess CPU consumption to know which process really hogging the CPU</span><br><span class="line">- Running vmstat gives you the information you need. It takes the number of seconds and the number of reports as the first and second arguments to determine the number of seconds for which the tool will calculate the averages. The first line of output represents the averages since the systems boot time. The subsequent line present the average per n seconds.</span><br><span class="line">- The right most column is for CPU readings. Us, sy,id, and wa represent the user, system, idle time, and wait time for CPU.</span><br><span class="line">- A high us means that the system is busy doing computational tasks, while a high **sy** time means the system is making a lot of system calls and/or making a lot of I/O requests. A system-typically-should be using no more than 50% in user time, no more than 50% in system time, and have a non-zero idle time.</span><br><span class="line">- The **cs** is short for context switches per interval. That is how many times the kernel switched the running process per interval. The **in** is short for interrupts, it shows the number of interrupts per interval. A high **cs** or **in** rate may be an indication to a malunctioning hardware device.</span><br><span class="line"></span><br><span class="line">**CPU load average and per-process**</span><br><span class="line">- Using the **uptime** command, it essentially provides the total time spent since the system was booted, but it also offers a CPU load average for the same period.</span><br><span class="line">- The load average consists of three vlues that represent 5,10, and 15 minutes averages.</span><br><span class="line">- A load average that stays the same on a &quot;good performance&quot; and on a &quot;performance degraded&quot; one is an indication that you have to look elsewhere,perhaps at the network bandwidth, disk I/O, or the intalled memroy.</span><br><span class="line">- Other commands that offer real time view of the CPU per-process load is **ps -aux** and **top**. You may find a single process using more than 50% of the available CPU time. Using **nice** to decrease the execution prioroty of this process may help boost performance.</span><br><span class="line"></span><br><span class="line">**Memeory management**</span><br><span class="line">- When an application requests memeory to operate, the kernel offers this memeory in the form of &quot;pages&quot;. In linux, a page size is 4KiB.</span><br><span class="line">- The kernel serves those pages from physical storage hardware (either RAM or SWAP space on the disk).</span><br><span class="line">- The kernel shuffles pages between the SWAP space together with RAM. Memroy that is not accessed for a specific period of time is moved into SWAP space (paged) to free more space for rather more frequently accessed memory.</span><br><span class="line">- As more and more processes demand memroy, the kernel tries to fulfil the reqeusts by paging in and out memory pages from and to the SWAP space. And because the disk is the slowest coponent of the system, as the paging rate increates, performance is degraded as processes will have to wait longer before they can have their requested memory and things start to get slower.</span><br><span class="line">- Fainlly, if the system runs out of both physical memory and SWAP space, the kernel resorts to more drastic measures: it kills the least important process with an out-of-memory killer function, a situation that should be avoided at all costs by anticipating the need to install more memroy early enough.</span><br><span class="line"></span><br><span class="line">**Using vmstat to measure memory utilization**</span><br><span class="line">- **vmstat** is used the same way it was used to measure CPU utilization.</span><br><span class="line">- The swap in (si) and swap out (so) columns in the SWAP area of the output are of the most importance here. Pages that are read from disk into memory are &quot;swapped in&quot; while those which are ejected by the kernel into the disk are &quot;swapped out&quot;. A high rate of si and so may be an indication that the system is using SWAP sapce extensively and that it might need more physical memeory to be installed.</span><br><span class="line">- Such a decision should not be reached by the **si** and **so** rates alone as the system normally does page in and page out operations. Only if is accompanied by slow system response and user complaints.</span><br></pre></td></tr></table></figure></p><p>iostat -dx 5 5<br><code>`</code><br><strong>A slow system quick diagnosis and remedy</strong></p><ul><li>If you find that the system is suddenly running slower than before and users start complaining, you can examine the resources discussed in this section for bottlenecks.</li><li><p>For example, running <strong>ps -auxww</strong> will show you the CPU utilization per process. If you find that a single process is using more than 50% of the CPU ofr a long time, this might be an indication of fault in the process itself. Also check the load average with uptime to determine whether or not the CPU is contended.</p></li><li><p>Check the paging activity with vmstat. If there are a lot of page-outs this means the physical memeory is overloaded. Additionalyy, if there is a lot of disk activity without paging this means the a process is extensively using the disk for read and write requests. If this is not the normal behavior (e.g. a database), the process activity should be further examined.</p></li><li>It is difficult to know exactly which process is using the disk I/O the most, but using kill -STOP to temporarily suspend the susceptiable process can narrow down the possibilities.</li><li>If a process is identified as resource intensive, a number of actions can be taken: if it is CPU intensive you can use the renice command to descrease its priority. You can also ask the user to run it later. I the process is hogging the disk and/or then network, renice will not solve the problem, but you can tune the process itself to optimize its behavior (for example web servers).</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TCP-IP-networking&quot;&gt;&lt;a href=&quot;#TCP-IP-networking&quot; class=&quot;headerlink&quot; title=&quot;TCP/IP networking&quot;&gt;&lt;/a&gt;TCP/IP networking&lt;/h1&gt;&lt;h2 id=&quot;Troub
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://223.95.78.227/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>programming4sysadmins</title>
    <link href="http://223.95.78.227/2019/07/19/programming4sysadmins/"/>
    <id>http://223.95.78.227/2019/07/19/programming4sysadmins/</id>
    <published>2019-07-19T06:10:53.000Z</published>
    <updated>2019-07-19T14:27:15.327Z</updated>
    
    <content type="html"><![CDATA[<h1 id="python"><a href="#python" class="headerlink" title="python"></a>python</h1><h2 id="What-can-you-do-with-python"><a href="#What-can-you-do-with-python" class="headerlink" title="What can you do with python?"></a>What can you do with python?</h2><ul><li>Versatile language, can use it across a lot of different domains</li><li>really fast to learn and fast to develop in<h2 id="Environment-Setup"><a href="#Environment-Setup" class="headerlink" title="Environment Setup"></a>Environment Setup</h2><a href="https://wiki.openhatch.org/wiki/O%27Reilly_Introduction_to_Python">link</a><h2 id="Python-basic-data-types"><a href="#Python-basic-data-types" class="headerlink" title="Python basic data types"></a>Python basic data types</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; type(1)</span><br><span class="line">&lt;type &apos;int&apos;&gt;</span><br><span class="line">&gt;&gt;&gt; type(1.0)</span><br><span class="line">&lt;type &apos;float&apos;&gt;</span><br><span class="line">Type is a functions that takes input and spits out output.</span><br></pre></td></tr></table></figure></li></ul><p><strong>a function</strong> is just the name and then input inside parentheses, and it’ll spit out output.</p><p>If you need to include the string delimiter inside the string just precede it with a backslash, as in ‘It\’s a wrap’<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; &quot;Hello &quot; + str(1)</span><br><span class="line">&apos;Hello 1&apos;</span><br></pre></td></tr></table></figure></p><h2 id="Making-choices-boolean-if-eif-else-compound-conditionals"><a href="#Making-choices-boolean-if-eif-else-compound-conditionals" class="headerlink" title="Making choices: boolean, if/eif/else, compound conditionals"></a>Making choices: boolean, if/eif/else, compound conditionals</h2><p>Boolean:</p><ul><li>True</li><li>False<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = 1</span><br><span class="line">&gt;&gt;&gt; x &gt; 0 and x &lt; 2</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; &quot;a&quot; in &quot;hello&quot; or &quot;e&quot; in &quot;hello&quot;</span><br><span class="line">True</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; temp = 32</span><br><span class="line">&gt;&gt;&gt; if temp &gt; 60 and temp &lt; 75:</span><br><span class="line">...     print(&quot;Nice and cozy&quot;)</span><br><span class="line">... else:</span><br><span class="line">...     print(&quot;Too extreme for me&quot;)</span><br><span class="line">...</span><br><span class="line">Too extreme for me</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; sister = 15</span><br><span class="line">&gt;&gt;&gt; brother =15</span><br><span class="line">&gt;&gt;&gt; if sister &gt; brother:</span><br><span class="line">...     print(&quot;Sister is older&quot;)</span><br><span class="line">... elif sister == brother:</span><br><span class="line">...     print(&quot;Same age!&quot;)</span><br><span class="line">... else:</span><br><span class="line">...     print(&quot;Brother is older&quot;)</span><br><span class="line">...</span><br><span class="line">Same age!</span><br></pre></td></tr></table></figure></li></ul><h2 id="Lists"><a href="#Lists" class="headerlink" title="Lists"></a>Lists</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; names = [&quot;Alice&quot;, &quot;Amy&quot;]</span><br><span class="line">&gt;&gt;&gt; names.append(&quot;Adam&quot;)</span><br><span class="line">&gt;&gt;&gt; names</span><br><span class="line">[&apos;Alice&apos;, &apos;Amy&apos;, &apos;Adam&apos;]</span><br><span class="line">&gt;&gt;&gt; names[len(names)-1]</span><br><span class="line">&apos;Adam&apos;</span><br><span class="line">&gt;&gt;&gt; names[-1]</span><br><span class="line">&apos;Adam&apos;</span><br></pre></td></tr></table></figure><p>The real superpower when using lists is actually to be able to loop over them.</p><h2 id="Loops"><a href="#Loops" class="headerlink" title="Loops"></a>Loops</h2><h1 id="Great-Bash"><a href="#Great-Bash" class="headerlink" title="Great Bash"></a>Great Bash</h1><ul><li><p>Redirect the output of commands</p><ul><li>Standard error is file descriptor “2” <code>ls -l myscript not.here &gt; lsout 2&gt; lserr</code></li><li>Out and error can be redirected separately or together <code>ls -l myscript not.here &amp;&gt; lsboth</code></li><li>The order of redirection is important<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ls -l myscript not.here &gt; lsout 2&gt;&amp;1</span><br><span class="line">## Redirectin error output to standard output</span><br><span class="line">## Standard output is already being re-directed to file &gt; dirlist</span><br><span class="line">## Hence, both error and standard output are written to file lsout</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Redirecting and piping input and output</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls &gt; /tmp/lsout</span><br><span class="line">wc &lt; /tmp/lsout</span><br></pre></td></tr></table></figure></li></ul><p>Use the vertical bar character | to create a pipe: <code>ls|wc</code></p><p>Connect a series of commands with | symbols to make a pipeline.</p><ul><li>Create input with here documents</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;python&quot;&gt;&lt;a href=&quot;#python&quot; class=&quot;headerlink&quot; title=&quot;python&quot;&gt;&lt;/a&gt;python&lt;/h1&gt;&lt;h2 id=&quot;What-can-you-do-with-python&quot;&gt;&lt;a href=&quot;#What-can-y
      
    
    </summary>
    
    
      <category term="python" scheme="http://223.95.78.227/tags/python/"/>
    
      <category term="programming" scheme="http://223.95.78.227/tags/programming/"/>
    
      <category term="systemadmin" scheme="http://223.95.78.227/tags/systemadmin/"/>
    
  </entry>
  
  <entry>
    <title>DevOps</title>
    <link href="http://223.95.78.227/2019/07/17/devops/"/>
    <id>http://223.95.78.227/2019/07/17/devops/</id>
    <published>2019-07-17T11:23:02.000Z</published>
    <updated>2019-09-13T14:59:52.588Z</updated>
    
    <content type="html"><![CDATA[<p><strong>What is DevOps?</strong></p><ul><li>Speed and agility enable organizations to better serve their customers and compete more effectively in the market</li><li>Combination of cultural philosophies, practices, and tools</li><li>Increases an organization’s ability to deliver applications and services at high velocity</li><li>Evolves and imprvoes products faster</li></ul><p><strong>Why DevOps?</strong></p><ul><li>Antomate manual tasks, help teams manage complex environments at scale, and keep engineers in control of the velocity that is enabled by DevOps:<ul><li>Speed</li><li>Rapid delivery</li><li>Reliability</li><li>Scale</li><li>Improved collaboration</li><li>Security</li></ul></li></ul><p>Standard Continuous delivery (CD) techniques</p><ul><li>Blue/Green deployment (where “live” and “last” deployments are maintained on live)<br>Blue-green deployment is a technique that reduces downtime and risk by running two identical production environments called Blue and Green.</li></ul><p>At any time, only one of the environments is live, with the live environment serving all production traffic. For this example, Blue is currently live and Green is idle.</p><p>As you prepare a new version of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.</p><p>This technique can eliminate downtime due to app deployment. In addition, blue-green deployment reduces risk: if something unexpected happens with your new version on Green, you can immediately roll back to the last version by switching back to Blue.</p><ul><li>Phoenix deployment (where whole system are rebuilt on each release).<br><img src="https://i.imgur.com/DXtJZOm.png" alt="devops tools"></li></ul><p><strong>Goals</strong></p><ul><li>Culture for collaboration<blockquote><p>lack of collaboration is one of the root causes of the issues</p></blockquote></li><li>Automate<blockquote><p>Manual tests that consume resources are better left to machines. This frees time that is better spent elsewhere, and provides a better environment by relinquishing mundane tasks</p></blockquote></li><li>Optimize and reduce issue in SDLC(software development life cycle)<blockquote><p>The processes being comprised in a logical order allows for optimizations to be made from recorded metrics.</p></blockquote></li><li>Consistency in process<blockquote><p>This stems mostly from automation, and provides the foundation to ensure quality. It also provides a certain level of peace of mind, having confidence that the same process that successfully ran last time will run the same the next.</p></blockquote></li><li>Improve quality and security<blockquote><p>Automation combined with consistency in process, along with the tools and practices in place to perform the necessary testing and scans, removes the possibility of human error from subsequent processes</p></blockquote></li><li>Improve deployment frequency<blockquote><p>Agile methodologies proved effective for development, and sparked the idea to apply similar principles to other areas. Deployment frequency has always been a target for efficiency, as shown by the migration to waterfall, where deployments were seldom; to hybrid methodologies that produced releases four or five times per month; to agile, where deployments are dependent upon sprint links. With DevOps, there’s a potential to release multiple times per day.</p></blockquote></li></ul><p><strong>DevOps Methodologies and Concepts</strong></p><ul><li>Automation<ul><li>Not duplicate of goals</li><li>Automation in context of applying automation to deveopment, integration, and deployment process</li></ul></li><li>CI/CD/CD<ul><li>CI: continuous integration<ul><li>Focusses on sub process of SDLC to build features and fixes perform preliminary testing then merge to master if successful</li></ul></li><li>CD: continuous delivery<ul><li>tail end of CI</li><li>refers to archiving build artifacts</li></ul></li><li>CD: continous deployment<ul><li>deploy all necessary artifacts and perform any configuration</li></ul></li></ul></li><li>Infrastructure as code, configuration as code: fail fast<ul><li>Don’t waste resources on something that will fail</li><li>Organize and optimize for efficiency</li></ul></li><li>Frequent feedback<ul><li>Compilation of a series of small and frequent feedback loops</li></ul></li></ul><p><strong>DevOps engineer’s role within a devops organization</strong></p><ul><li>Continually research, refine, and create conceopts, methodologies, practices, and tools in order to optimize the SDLC.</li><li>Implement core standards, plicies, and tools based on the previous</li><li>Asses infrastructure requirements”<ul><li>Global and application sacle</li></ul></li><li>Crate and manage infrastructure</li><li>Coordinate with other teams</li><li>Troubleshoot issues with code and infrastructure</li><li>Work with one or more teams to:<ul><li>Assess their current state</li><li>Formulate end goals</li><li>Adapt to requirements</li><li>Develop a plan of implementation</li><li>Formulate milestones</li><li>Provide instruction on the core standards, policies, and tools</li><li>Develop a pipeline</li><li>Help to change their code and processes to work with the plan</li></ul></li></ul><p><strong>philosophy</strong><br>DevOps is not something you do. It is something you are. </p><p>Devops culture is the one based on a set of principles, hierarchy of rules, by which each person operates.<br>A DevOps culture is one that allows more freedom but more responsibility.</p><p><strong>Devops lifecycle</strong></p><ul><li><p>Continuous integration</p><ul><li>Central repository</li><li>Continuous compiling, testing</li><li>Code verification</li><li>Identifying bugs early</li><li>Software in smaller chunks</li><li>Easy integration<br>Continuous integration (CI) requires developers to integrate code into a centralized repository as they finish coding and successfully pass unit testing, several times per day. The end goal is to create small workable chunks of code that are validated and integrated back into the code repository as frequently as possible. </li></ul></li><li><p>Configuration management</p><ul><li>System changes</li><li>Multiple servers</li><li>Tracking changes</li><li>Types of CM tools</li><li>Scripted builds</li><li>Identical development and production environments</li></ul></li><li><p>Continous delivery</p><ul><li>Deploying the application</li><li>Incremental or small changes</li><li>Compatible with schedule releases</li><li>Every change-ready to deploy<br>Continuous delivery simply means that every change is ready to be deployed to production as soon as automated testing validates it.<br>Note there are two manual checkpoints in this example. One is for a technical decision to approve the code before initiating activities in the CI environment. The second is a business decision to accept the changes and continue with the automated steps to production deployment.<br><img src="https://i.imgur.com/XzLyd0g.png" alt="reference pipeline-continous delivery"><br><strong>Deploying to production</strong></li></ul></li><li><p>Canary releases</p><blockquote><p>Continuous delivery deploys many builds to production. In a canary deployment, the new code is delivered only to a percentage of the existing infrastructure. For example, if the system is running on 10 load-balanced virtual servers, you can define a canary cluster of one or two servers. This way, if the deployment is not successful due to an escaped defect, it can be caught before the build is deployed to all of the servers. Canary releases are also used for pilot features to determine performance and acceptance prior to a full rollout.</p></blockquote></li><li><p>Blue/green deployment</p><blockquote><p>This is a zero-downtime deployment technique that involves a gradual release to ensure uninterrupted service. The blue/green approach is effective in virtualized environments, especially if IaaS is used. Although a blue/green deployment is a deep topic that deserves an entire chapter on its own, simply put, it includes maintaining two identical development environments—Blue and Green. One is a live environment for production traffic, whereas the other is used to deploy the new release. In our example, let’s say that Green is the current live production environment and Blue is the idle identical production environment. After the code is deployed and tested in the Blue environment, we can begin directing traffic of incoming requests from Green (current production) to Blue. You can do this gradually until the traffic redirect is 100 percent to the Blue environment. If unexpected issues occur during this gradual release, we can roll back. When it is completed, the Green environment becomes idle and the Blue environment is now the live production environment.</p></blockquote></li><li><p>Continous monitoring<br>Continous monitoring is the practice that connects operations back to development,providing visibility and relevant data throughout the development lifecycle including production monitoring. continuous monitoring aims to reduce the time between identification of a problem and deployment of the fix.<br>Monitoring begins with <strong>Sprint 1</strong> and should be integrated into the development work. As the system is built, monitoring solutions are also designed. </p></li></ul><p><strong>four different types of continuous monitoring</strong></p><ul><li>Infrastructure monitoring<blockquote><p>Visualize infrastructure events coming from all computing resources, storage and network, and measure the usage and health of infrastructure resources. <strong>AWS CloudWatch</strong> and <strong>CloudTrail</strong> are examples of infrastructure monitoring tools.</p></blockquote></li><li>Application performance monitoring (APM)<blockquote><p>Target bottlenecks in the application’s framework. <strong>Appdynamics</strong> and <strong>New Relic</strong> are industry-leading APM tools.</p></blockquote></li><li>Log management monitoring<blockquote><p>Collect performance logs in a standardized way and use analytics to identify application and system problems. <strong>Splunk</strong> and <strong>ELK</strong> are two leading products in this area.</p></blockquote></li><li>Security monitoring<blockquote><p>Reduce security and compliance risk through automation. Security configuration management, vulnerability management, and intelligence to detect attacks and breaches before they do serious damage are achieved through continuous monitoring. For example, <strong>Netflix’s Security Monkey</strong> is a tool that checks the security configuration of your cloud implementation on AWS.</p></blockquote></li></ul><p><strong>three major setps</strong></p><ol><li>monitoring</li><li>an alert system to warn the team about a problem</li><li>actions to take when an alert occurs</li></ol><ul><li>Continous testing<ul><li>Speed and quality</li><li>Testing incremental changes</li><li>Automated tests</li><li>Tests to be atomic: small test<ul><li>Continous testing during development (e.g. use open source tools like Selenium for testing)</li><li>Confidence to release</li><li>Integration with CI</li></ul></li></ul></li><li>Continous deployment<ul><li>Superset of Continuous Delivery</li><li>Deploying to production</li><li>Automates the deployment pipeline<br>Unlike continuous delivery, which means that every change is deployable but might be held back because of business considerations or other manual steps, continuous deployment strives to automate production deployment end to end. With this practice, confidence in the automated tests is extremely high, and as long as the code has passed all the tests, it will be deployed.<br><img src="https://i.imgur.com/Aq1VaJb.png" alt="cd"></li></ul></li></ul><p>DevOps: culture, automation, measurement, and sharing (CAMS)</p><p><strong>DevOps architecutres and practics</strong><br>From the DevOps movement, a set of software architectural patterns and practices have become increasingly popular. The primary logic behind the development of these architectural patterns and practices is derived from the need for scalability, no-downtime deployments, and minimizing negative customer reactions to upgrades and releases. Some of these you may have heard of (microservices), while others may be a bit vague (blue-green deployments).</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;What is DevOps?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Speed and agility enable organizations to better serve their customers and compete more eff
      
    
    </summary>
    
    
      <category term="Devops" scheme="http://223.95.78.227/tags/Devops/"/>
    
  </entry>
  
  <entry>
    <title>aws administration</title>
    <link href="http://223.95.78.227/2019/07/17/aws-admin/"/>
    <id>http://223.95.78.227/2019/07/17/aws-admin/</id>
    <published>2019-07-17T08:02:52.000Z</published>
    <updated>2019-07-20T07:03:14.782Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CodeCommit"><a href="#CodeCommit" class="headerlink" title="CodeCommit"></a>CodeCommit</h1><p>Codecommit is a source control service provided by aws(hosts private git repositories)<br><strong>why choose CodeCommit</strong></p><ul><li>Easy integration with other AWS services like CodePipeline</li><li>Repositories are private by default</li><li>Can use IAM for fine-graned authorization</li></ul><p><strong>Creating a private code repo on CodeCommit</strong><br>IAM-&gt; HTTPS Git credentials for AWS CodeCommit</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git clone https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/SampleRepo</span><br><span class="line">cd SampleRepo</span><br><span class="line">wget https://s3.amazonaws.com/aws-codedeploy-us-east-1/samples/latest/SampleApp_Linux.zip</span><br><span class="line">unzip SampleApp_Linux.zip</span><br><span class="line">rm SampleApp_Linux.zip</span><br><span class="line">git add -A</span><br><span class="line">git commit -m &quot;Initial commit&quot;</span><br><span class="line">git push</span><br></pre></td></tr></table></figure><p><strong>Migrating your project to CodeCommit</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">### - - mirror here means that we are not interested in cloning the application, however we are interested in downloading the Git binary files that make up the repository in the first place. </span><br><span class="line">git clone --mirror https://github.com/awslabs/aws-demo-php-simple-app.git aws-codecommit-demo</span><br><span class="line">git push https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/myrepo</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;initial commit to demp rep&quot;</span><br><span class="line">git remote add demo https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/demo</span><br><span class="line">git remote -v</span><br><span class="line">git push demo master</span><br></pre></td></tr></table></figure><p><a href="https://docs.aws.amazon.com/codecommit/latest/userguide/getting-started-cc.html">CodeCommit tutorials</a><br><a href="https://docs.aws.amazon.com/codecommit/latest/userguide/auth-and-access-control-iam-identity-based-access-control.html">Using IAM policies with CodeCommit</a><br><a href="https://aws.amazon.com/blogs/devops/using-aws-codecommit-pull-requests-to-request-code-reviews-and-discuss-code/">Using AWS CodeCommit Pull Requests</a><br><a href="https://datasift.github.io/gitflow/IntroducingGitFlow.html">GitFlow development release model</a></p><h1 id="Deploying-Jenkins"><a href="#Deploying-Jenkins" class="headerlink" title="Deploying Jenkins"></a>Deploying Jenkins</h1><p>Amazon linux 2 AMI<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y update</span><br><span class="line">sudo yum -y install java-1.8.0</span><br><span class="line"># remove java 7</span><br><span class="line">sudo yum remove java-1.7.0-openjdk</span><br><span class="line">java -version</span><br><span class="line">sudo wget -O /etc/yum.repos.d/jenkins.repo https:/pkg.jenkins-ci.org/redhat/jenkins.repo </span><br><span class="line">sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key</span><br><span class="line">sudo yum -y install jenkins</span><br><span class="line">sudo service jenkins start</span><br></pre></td></tr></table></figure></p><h1 id="CodeDeploy"><a href="#CodeDeploy" class="headerlink" title="CodeDeploy"></a>CodeDeploy</h1><p><img src="https://i.imgur.com/ZRCFrZP.png" alt="codedeploy ec2"></p><h1 id="Cloud9"><a href="#Cloud9" class="headerlink" title="Cloud9"></a>Cloud9</h1><p><strong>What is Cloud9</strong></p><ul><li>Cloud9 integrates with other AWS DevOps tools such as CodeCommit, CodePipeline, and CodeStar to enable a rich development pipeline with continuous delivery</li><li>AWS Cloud9 contains a collection of tools that you use to code, build, run, test, debug, and release software on the cloud</li><li>Use the AWS Cloud9 Integrated Development Environment (IDE) to work with these tools<br><strong>What can i do with aws Cloud 9</strong></li><li>Supported languages:<ul><li>C++</li><li>Java</li><li>Python</li><li>.NET</li><li>Node.js</li><li>PHP</li><li>Pearl</li><li>Ruby</li><li>Go</li><li>JavaScript</li><li>CoffeeScript</li></ul></li><li>Supported integrations:<ul><li>CodeCommit</li><li>CodePipeline</li><li>CodeStar</li><li>API gateway</li><li>Lambda</li><li>Lightsail</li><li>DynamoDB</li><li>RDS</li><li>AWS CLI</li><li>Docker</li><li>GitHub</li></ul></li><li>Supported environments<ul><li>EC2</li><li>SSH</li><li>Single-user environment</li><li>Shared team environment</li><li>virtualenv<h1 id="CodeBuild"><a href="#CodeBuild" class="headerlink" title="CodeBuild"></a>CodeBuild</h1><h1 id="CodePipeline"><a href="#CodePipeline" class="headerlink" title="CodePipeline"></a>CodePipeline</h1><h1 id="CodeStart"><a href="#CodeStart" class="headerlink" title="CodeStart"></a>CodeStart</h1></li></ul></li></ul><h1 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h1><ul><li><a href="https://aws.amazon.com/devops/what-is-devops/">What is DevOps</a></li><li><a href="https://aws.amazon.com/pricing/">AWS pricing</a></li><li><a href="https://docs.aws.amazon.com/codepiepline/latest/userguide/tutorials-simple-codecommit.html">TUtorial-create a simple pipeline</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CodeCommit&quot;&gt;&lt;a href=&quot;#CodeCommit&quot; class=&quot;headerlink&quot; title=&quot;CodeCommit&quot;&gt;&lt;/a&gt;CodeCommit&lt;/h1&gt;&lt;p&gt;Codecommit is a source control service
      
    
    </summary>
    
    
      <category term="aws" scheme="http://223.95.78.227/tags/aws/"/>
    
      <category term="Codecommit" scheme="http://223.95.78.227/tags/Codecommit/"/>
    
  </entry>
  
  <entry>
    <title>devops-with-aws</title>
    <link href="http://223.95.78.227/2019/07/15/devops-with-aws/"/>
    <id>http://223.95.78.227/2019/07/15/devops-with-aws/</id>
    <published>2019-07-15T13:44:53.000Z</published>
    <updated>2019-08-13T01:08:49.426Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Project-setup"><a href="#Project-setup" class="headerlink" title="Project setup"></a>Project setup</h1><p><a href="https://github.com/espiderinc/hapi-rest-demo">code</a></p><h2 id="Importance-of-automated-test-in-CI-CD"><a href="#Importance-of-automated-test-in-CI-CD" class="headerlink" title="Importance of automated test in CI,CD"></a>Importance of automated test in CI,CD</h2><ul><li>Automated tests<ul><li>Unit tests</li><li>Integration tests</li><li>UAT tests</li></ul></li><li>Code coverage</li><li>Notifications<h2 id="CI-CD-with-relational-databases"><a href="#CI-CD-with-relational-databases" class="headerlink" title="CI/CD with relational databases"></a>CI/CD with relational databases</h2></li><li>Managing the version of database schema<br>There is no easy way to control the version of relational database schema</li><li>Database schema migrations</li><li>DellStore2 sample database<ul><li>Products table</li></ul></li><li>Sqitch change management system<h2 id="Project-component-setup"><a href="#Project-component-setup" class="headerlink" title="Project component setup"></a>Project component setup</h2></li><li>PostgreSQL database on AWS RDS</li><li>Node.JS HAPI RESTful API project</li><li>Sqitch database mangement framework<h2 id="Setup-PostreSQL-database-instance-in-AWS-RDS"><a href="#Setup-PostreSQL-database-instance-in-AWS-RDS" class="headerlink" title="Setup PostreSQL database instance in AWS RDS"></a>Setup PostreSQL database instance in AWS RDS</h2></li></ul><ol><li>Create a rds in aws with postgresql engine version 9.4.7.</li><li>Connect to aws rds use pgAdmin 3.</li><li>Download sample schema dellstore2 from <a href="http://pgfoundry.org/projects/dbsamples/">link</a></li><li>In pgAdmin3 click Plugins-&gt; PSQL console-&gt; run command <code>\i /tmp/dellstore2.sql</code> to create a new schema.<h2 id="Setup-Node-JS-HAPI-ReSTful-API-project"><a href="#Setup-Node-JS-HAPI-ReSTful-API-project" class="headerlink" title="Setup Node.JS HAPI ReSTful API project"></a>Setup Node.JS HAPI ReSTful API project</h2><strong>HAPI</strong> is a rich application framework for building applications and RESTful APIs with Node.JS</li></ol><p>Official website for HAPI framework is HAPIJS.com</p><ol><li>install node and npm<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br><span class="line">mkdir myfirsthapiproject</span><br><span class="line">cd myfirsthapiproject</span><br><span class="line">npm init</span><br><span class="line">npm install --save hapi</span><br></pre></td></tr></table></figure></li></ol><p>2.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/espiderinc/hapi-rest-demo.git</span><br><span class="line">cd hapi-rest-demo</span><br><span class="line">npm install</span><br><span class="line">sudo npm install -g istanbul mocha</span><br><span class="line">node index.js</span><br></pre></td></tr></table></figure></p><ol start="3"><li><p><img src="https://i.imgur.com/rCcEgzW.png" alt="access by">)<br><img src="https://i.imgur.com/VdGe8f3.png" alt="Imgur"></p></li><li><p>test</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">hapi-rest-demo git:(master) ✗ npm test</span><br><span class="line"></span><br><span class="line">&gt; hapi-rest-demo@1.0.0 test /home/stan/workspace/hapi-rest-demo</span><br><span class="line">&gt; istanbul cover _mocha test/**/*.js</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(node:20777) [DEP0022] DeprecationWarning: os.tmpDir() is deprecated. Use os.tmpdir() instead.</span><br><span class="line">  Task routes</span><br><span class="line">    GET /products</span><br><span class="line">      ✓ should return statusCode 200 (381ms)</span><br><span class="line">      ✓ should return product [ACADEMY BROOKLYN] </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  2 passing (416ms)</span><br><span class="line"></span><br><span class="line">=============================================================================</span><br><span class="line">Writing coverage object [/home/stan/workspace/hapi-rest-demo/coverage/coverage.json]</span><br><span class="line">Writing coverage reports at [/home/stan/workspace/hapi-rest-demo/coverage]</span><br><span class="line">=============================================================================</span><br><span class="line"></span><br><span class="line">=============================== Coverage summary ===============================</span><br><span class="line">Statements   : 56.31% ( 58/103 )</span><br><span class="line">Branches     : 39.29% ( 11/28 )</span><br><span class="line">Functions    : 47.83% ( 11/23 )</span><br><span class="line">Lines        : 57% ( 57/100 )</span><br><span class="line">================================================================================</span><br></pre></td></tr></table></figure></li></ol><p>report generated workspace/hapi-rest-demo/coverage/lcov-report/index.html</p><h2 id="Setup-swtich-database-schema-framework"><a href="#Setup-swtich-database-schema-framework" class="headerlink" title="Setup swtich (database schema framework)"></a>Setup swtich (database schema framework)</h2><p>Managin database schema for relational databaes (with Sqitch)<br><strong>Sqitch</strong> is a standalone system without any dependency on frameworks or ORMs.</p><ul><li>handels dependencies between scripts</li><li><a href="http://sqitch.org">project site</a><br><strong>install sqitch</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker pull sqitch/sqitch</span><br><span class="line">curl -L https://git.io/fAX6Z -o sqitch &amp;&amp; chmod +x sqitch</span><br><span class="line">mv sqitch /usr/bin/</span><br><span class="line">sudo apt-get install -y libdbd-pg-perl postgresql-client</span><br><span class="line">sqitch --version</span><br></pre></td></tr></table></figure></li></ul><p><strong>use sqitch</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">mkdir stantutorial</span><br><span class="line">cd stantutorial</span><br><span class="line">sqitch init stantutorial --uri http://github.com/espiderinc/hapi-rest-demo.git</span><br><span class="line">cat sqitch.conf</span><br><span class="line"> [core]</span><br><span class="line">         engine = pg</span><br><span class="line">        # plan_file = sqitch.plan</span><br><span class="line">        # top_dir = .</span><br><span class="line">sqitch config --user user.name &apos;StanTutorial&apos;</span><br><span class="line">sqitch config --user user.email &apos;devops@cwzhou.win&apos;</span><br><span class="line">sqitch add schema -n &apos;Add schema for tutorial objects.&apos;</span><br><span class="line">Created deploy/schema.sql</span><br><span class="line">Created revert/schema.sql</span><br><span class="line">Created verify/schema.sql</span><br><span class="line">Added &quot;schema&quot; to sqitch.plan</span><br><span class="line"></span><br><span class="line"> cat deploy/schema.sql</span><br><span class="line">-- Deploy stantutorial:schema to pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">CREATE SCHEMA tutorial;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">cat revert/schema.sql</span><br><span class="line">-- Revert stantutorial:schema from pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">DROP SCHEMA tutorial;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line"> cat verify/schema.sql</span><br><span class="line">-- Verify stantutorial:schema on pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add verifications here.</span><br><span class="line"></span><br><span class="line">select 1/count(*) from information_schema.schemata where schema_name=&apos;tutorial&apos;;</span><br><span class="line"></span><br><span class="line">ROLLBACK;</span><br><span class="line"></span><br><span class="line"> sqitch add video --requires schema -n &apos;add video table to schema tutorial&apos;</span><br><span class="line"></span><br><span class="line"> cat deploy/video.sql</span><br><span class="line">-- Deploy stantutorial:video to pg</span><br><span class="line">-- requires: schema</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">SET client_min_messages = &apos;warning&apos;;</span><br><span class="line">CREATE TABLE tutorial.video(</span><br><span class="line">        subject TEXT    PRIMARY KEY,</span><br><span class="line">        comment TEXT,</span><br><span class="line">        timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW()</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">cat revert/video.sql</span><br><span class="line">-- Revert stantutorial:video from pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">DROP TABLE tutorial.video;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">cat verify/video.sql</span><br><span class="line">-- Verify stantutorial:video on pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add verifications here.</span><br><span class="line">select subject, comment, timestamp</span><br><span class="line">from tutorial.video</span><br><span class="line">where false;</span><br><span class="line"></span><br><span class="line">ROLLBACK;</span><br><span class="line">sqitch deploy db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch status db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch verify db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch revert db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch status db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br></pre></td></tr></table></figure></p><h1 id="CI-and-CD-pipeline-deep-dive"><a href="#CI-and-CD-pipeline-deep-dive" class="headerlink" title="CI and CD pipeline deep dive"></a>CI and CD pipeline deep dive</h1><h2 id="AWS-prerequisites"><a href="#AWS-prerequisites" class="headerlink" title="AWS prerequisites"></a>AWS prerequisites</h2><ul><li>IAM instance profile</li></ul><ol><li><p>Create a policy, name: CodeDeploy-EC2-Permissions, json</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class="line">    &quot;Statement&quot;: [</span><br><span class="line">     &#123;</span><br><span class="line">        &quot;Action&quot;:[</span><br><span class="line">           &quot;s3:Get*&quot;,</span><br><span class="line">           &quot;s3:List*&quot;  </span><br><span class="line">        ],</span><br><span class="line">        &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">        &quot;Resource&quot;: &quot;*&quot;</span><br><span class="line">     &#125;    </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Create a role, named CodeDeploy-EC2 -&gt; Choose role type ec2-&gt;Attach permissions policies “CodeDeploy-EC2-Permissions”</p></li></ol><ul><li>IAM service role</li></ul><ol><li>Create a role named stantutorialRole -&gt; select role type CodeDeploy</li></ol><h2 id="Jenkins-installation"><a href="#Jenkins-installation" class="headerlink" title="Jenkins installation"></a>Jenkins installation</h2><p>Ubuntu-&gt; Configure Instance Details, IAM role, select CodeDeploy-EC2 (this will allow jenkins connect to s3 buckets)-&gt;<br>Tag instance: Key group Value hapi-demo<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget -q -O - http://pkg.jenkins-ci.org/debian/jenkins-ci.org.key| sudo apt-key add -</span><br><span class="line">sudo vim /etc/apt/sources.list # add following line</span><br><span class="line">deb http://pkg.jenkins-ci.org/debian-stable binary/</span><br><span class="line">sudo apt-get install default-jdk</span><br><span class="line">sudo apt-get install jenkins</span><br><span class="line">sudo service jenkins start</span><br></pre></td></tr></table></figure></p><p>Install plugin AWS CodePipeline<br>Install node.js:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -</span><br><span class="line">apt-get install -y nodejs</span><br><span class="line">sudo npm install -g npm</span><br><span class="line">node -v</span><br></pre></td></tr></table></figure></p><p>Install sqitch<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install build-essential cpanminus perl perl-doc</span><br><span class="line">cpanm --quiet --notest App::Sqitch</span><br><span class="line">sqitch --version</span><br><span class="line">apt-get install -y postgresql libdbd-pg-perl</span><br></pre></td></tr></table></figure></p><p>Create a new instance hapi-demo install node.js and<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python3-pip</span><br><span class="line">sudo apt install ruby-full</span><br><span class="line">sudo apt install wget</span><br><span class="line">wget https://aws-codedeploy-ap-southeast-2.s3.amazonaws.com/latest/install</span><br><span class="line">chmod +x install</span><br><span class="line">sudo ./install auto</span><br></pre></td></tr></table></figure></p><h2 id="CodeDeploy-application"><a href="#CodeDeploy-application" class="headerlink" title="CodeDeploy application"></a>CodeDeploy application</h2><p>Create a new Codedeploy application, choose compute type ec2/on-premises, Service role-&gt; statutorialRole; Environment configuration tick Amazon EC2 instances, Key-&gt; Name, Value-&gt; hapi-demo; Deployment setting-&gt; CodeDeployDefault.OneAtATime</p><h2 id="Review-appSpec-yml-file"><a href="#Review-appSpec-yml-file" class="headerlink" title="Review appSpec.yml file"></a>Review appSpec.yml file</h2><p>appspec.yml file is an application specification file for aws codedeploy</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat appspec.yml</span><br><span class="line">version: 0.0</span><br><span class="line">os: linux</span><br><span class="line">files:</span><br><span class="line">  - source: /</span><br><span class="line">    destination: /myapp</span><br><span class="line">permissions:</span><br><span class="line">  - object: /myapp/startApp.sh</span><br><span class="line">    mode: 777</span><br><span class="line">hooks:</span><br><span class="line">  ApplicationStart:</span><br><span class="line">    - location: startApp.sh</span><br><span class="line">      timeout: 10</span><br></pre></td></tr></table></figure><h2 id="Setup-Jenkins-job"><a href="#Setup-Jenkins-job" class="headerlink" title="Setup Jenkins job"></a>Setup Jenkins job</h2><p>Create a freestyle jenkins job, configurat as following screenshots:<br><img src="https://i.imgur.com/yb9AZch.png" alt="screenshot01"><br><img src="https://i.imgur.com/jxkg9xA.png" alt="screenshot02"><br><img src="https://i.imgur.com/ghjvXwd.png" alt="screenshot03"></p><h2 id="Build-AWS-CodePieline"><a href="#Build-AWS-CodePieline" class="headerlink" title="Build AWS CodePieline"></a>Build AWS CodePieline</h2><ol><li>Source provider <a href="https://github.com/stanosaka/hapi-rest-demo">GitHub</a></li><li>Build provider: Add Jenkins; Prvider name must match the name in jenkin’s job</li><li>Deployment provider: aws codedeploy<br><img src="https://i.imgur.com/Zcps1fo.png" alt="aws codedeploy"><br><img src="https://i.imgur.com/e2nGdbj.png" alt="deployed pages"><br><img src="https://i.imgur.com/eJAhUJH.png" alt="api"><br><img src="https://i.imgur.com/MJs6nKN.png" alt="lcov-report"></li></ol><h1 id="Next-Steps"><a href="#Next-Steps" class="headerlink" title="Next Steps"></a>Next Steps</h1><h2 id="Notifications"><a href="#Notifications" class="headerlink" title="Notifications"></a>Notifications</h2><p>AWS SNS notifications for build and deployment status</p><ol><li>Create a policy named: notification-policy<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class="line">    &quot;Statement&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">            &quot;Action&quot;: &quot;sns:Publish&quot;,</span><br><span class="line">            &quot;Resource&quot;: &quot;*&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>Attach notification-policy to Role CodeDeploy-EC2</p><ol start="2"><li>in CodeDeploy edit deployment group;<br><img src="https://i.imgur.com/Lx8Kxdw.png" alt="create deployment trigger"><br><img src="https://i.imgur.com/Xl4OvF8.png" alt="notification"></li></ol><h2 id="Code-changes"><a href="#Code-changes" class="headerlink" title="Code changes"></a>Code changes</h2><p>Automatically and continuously deploy code without any downtime</p><h2 id="Database-schema-changes"><a href="#Database-schema-changes" class="headerlink" title="Database schema changes"></a>Database schema changes</h2><p>Consistently and automatically deploy relational database schema changes<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sqitch add product-add-comments</span><br><span class="line">cat /db/deploy/product-add-comments.sql</span><br><span class="line">-- Deploy spidertutorial:product-add-comments to pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">alter table products add comments varchar(100) default &apos;default comments&apos;;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line">git commit -a -m &quot;add new column to products&quot;</span><br><span class="line">git push origin master:master</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Project-setup&quot;&gt;&lt;a href=&quot;#Project-setup&quot; class=&quot;headerlink&quot; title=&quot;Project setup&quot;&gt;&lt;/a&gt;Project setup&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://github.co
      
    
    </summary>
    
    
      <category term="Jenkins" scheme="http://223.95.78.227/tags/Jenkins/"/>
    
      <category term="Devops" scheme="http://223.95.78.227/tags/Devops/"/>
    
      <category term="CD/CI" scheme="http://223.95.78.227/tags/CD-CI/"/>
    
  </entry>
  
  <entry>
    <title>splunk</title>
    <link href="http://223.95.78.227/2019/07/15/splunk/"/>
    <id>http://223.95.78.227/2019/07/15/splunk/</id>
    <published>2019-07-15T00:40:04.000Z</published>
    <updated>2019-07-19T12:38:59.302Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/PacktPublishing/Splunk-7.x-Quick-Start-Guide">code</a></p><h1 id="What-is-Splunk"><a href="#What-is-Splunk" class="headerlink" title="What is Splunk?"></a>What is Splunk?</h1><p>Splunk is a software platform that collects and stores all this machine data in one place.<br><img src="https://i.imgur.com/wObsIBw.png" alt="splunk data sources and use cases"></p><h2 id="Splunk-products"><a href="#Splunk-products" class="headerlink" title="Splunk products"></a>Splunk products</h2><ul><li><strong>Splunk Enterprise</strong>: designed for on-premise deployments</li><li><strong>Splunk Cloud</strong>: a cloud-based <strong>software as a service (SaaS)</strong> version of Splunk Enterprise.</li><li><strong>Splunk Light</strong>: is designed to be a small-scale solution.</li><li><strong>Splunk Free</strong>: is a free version of the core Splunk Enterprise product that has limits on users(one user), ingestion volume (500 MB/day), and other features.</li></ul><p><strong>Splunk components</strong></p><ul><li>Universal forwarder</li><li>Indexer and indexer clusters</li><li>Search head and search head clusters</li><li>Deployment server</li><li>Deployer</li><li>Cluster master</li><li>License master</li><li>Heavy forwarder<br>Universal forwarders, indexers, and search heads constitute the majority of Splunk functionality; the other components provide supporting roles for larger clustered/distributed environments.<br><img src="https://i.imgur.com/sqJ8esH.png" alt="Splunk components in a distributed deployment"></li></ul><p>The <strong>universal forwarder (UF)</strong> is a free small-footprint version of Splunk Enterprise that is installed on each application, web, or other type of server to collect data from specified log files and forward this data to Splunk for indexing(storage). In A large Splunk deployment, you may have hundreds or thousands of forwards that consume and forward data for indexing.</p><p>An <strong>indexer</strong> is the Splunk component that creates and manages indexes, which is where machine data is stored. Indexers perform two main functions: parsing and storing data, which has been received from forwarders or other data sources into indexes, and searching and returning the indexed data in response to search requests.</p><p>An indexing cluster is a group of indexers that have been configured to work together to handle higher volumes of both incmoing data to be indexed and search requests to be serviced, as well as providing redundancy by keeping duplicate copies of indexed data spread across the cluster members.</p><p>A <strong>search head</strong> is an instance of Splunk Enterprise that handles search management functions. This includes providing a web-based user interface called Splunk Web, from which users issue search requests in what is called <strong>Search Processing Language (SPL)</strong>. Search reqeusts initiated by a user ( or a report or dashboard) are sent to one or more indexers to locate and return the requested data; the search head then formates the returned data for presentation to the user.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index=_internal | stats count by source, sourcetype</span><br></pre></td></tr></table></figure><p>an example of executing a simple search in Splunk Web. The SPL specifies searching in the <code>_internal</code> index, which is where Splunk saves data about its internal operations, and provides a count of the number of events in each log for Today. The SPL command specified an <code>index</code>, and then pipes the returned results to the <code>stats</code> command to return a <code>count</code> of all the events by their <code>source</code> and `sourcetype<br><img src="https://i.imgur.com/exMXaN5.jpg" alt="Simple search in Splunk Web"></p><p>A <strong>deployment server</strong> is a Splunk Enterprise instance that acts as a centralized configuration manager ofr a number of Splunk components, but which in practice is used to manage UFs.</p><p>A <strong>deployer</strong> is a Splunk Enterprise instance that is ued to distribute Splunk apps and certain other configuration updates to search head cluster memebers.</p><p>A <strong>cluster master</strong> is a Splunk Enterprise instance that coordinates the activities of an indexing cluster.</p><p>A <strong>license master</strong> is a single Splunk Enterprise instance that provides a licensing service for the multiple instances of Splunk that have been deployed in a distributed environment.</p><p>A <strong>heavy forwarder</strong> is an instance of Splunk Enterprise that can receive data from other forwarders or data sources and parse, index, and/or send data to another Splunk instance for indexing. </p><p>Splunk Enterprise also has a monitoring tool function called the <strong>monitoring console</strong>, which lets you view detailed topology and performance information about your entire distributed deployment from one interface. </p><p><img src="https://i.imgur.com/ElU7rTv.png" alt="Splunk data pipeline"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://github.com/PacktPublishing/Splunk-7.x-Quick-Start-Guide&quot;&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;What-is-Splunk&quot;&gt;&lt;a href=&quot;#What-is-Splunk&quot; 
      
    
    </summary>
    
    
      <category term="splunk" scheme="http://223.95.78.227/tags/splunk/"/>
    
      <category term="monitoring" scheme="http://223.95.78.227/tags/monitoring/"/>
    
  </entry>
  
  <entry>
    <title>terraform</title>
    <link href="http://223.95.78.227/2019/07/13/terraform/"/>
    <id>http://223.95.78.227/2019/07/13/terraform/</id>
    <published>2019-07-13T03:29:54.000Z</published>
    <updated>2019-07-22T05:09:38.152Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS">Supplemental content</a></p><h1 id="Install-Terraform-and-Tools-on-linux"><a href="#Install-Terraform-and-Tools-on-linux" class="headerlink" title="Install Terraform and Tools on linux"></a>Install Terraform and Tools on linux</h1><h2 id="Terraform-development-environment"><a href="#Terraform-development-environment" class="headerlink" title="Terraform development environment"></a>Terraform development environment</h2><ul><li>Terraform</li><li>aws account</li><li>aws cli with credentials configured</li><li>git</li><li>shell (bash, pwoershell, cmd, git-bash)</li><li>Text editor (visual studio code with Extensions terraform)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://releases.hashicorp.com/terraform/0.12.4/terraform_0.12.4_linux_amd64.zip</span><br><span class="line">unzip terraform_0.12.4_linux_amd64.zip</span><br><span class="line">sudo mv terraform /usr/local/bin</span><br><span class="line">terraform version</span><br></pre></td></tr></table></figure></li></ul><h1 id="First-deployment-with-Terraform"><a href="#First-deployment-with-Terraform" class="headerlink" title="First deployment with Terraform"></a>First deployment with Terraform</h1><h2 id="Configuration-language-basics"><a href="#Configuration-language-basics" class="headerlink" title="Configuration language basics"></a>Configuration language basics</h2><p>Terraform uses HCL (Hashicorp configuration language)</p><ul><li>human friendliness</li><li>JSON is quite verbose and doesn’t support comments, is machine readable</li><li>YAML is quite easy to mess up indentation and it’s not always clear whether you should use a colon or hyphen(specially when you using nested maps and lists)- machine-friendly, which is designed to be written and modified by humans</li><li>can sue JSON as input to Terraform</li></ul><p><strong>main features of HCL</strong></p><ul><li>can have single-line comments, start with a double slash or a number sign</li><li>multi-line comments are wrapped in /*</li><li>Values assign syntax key = vaule</li><li>Strings are double bolded</li><li>Numbers, booleans, arrays, lists, objects, named maps or dictonaries</li><li>Interpolations, conditionals, and various build-in functions</li></ul><h2 id="Set-up-aws-provider"><a href="#Set-up-aws-provider" class="headerlink" title="Set up aws provider"></a>Set up aws provider</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir s3_backbone &amp;&amp; cd s3_backbone</span><br><span class="line">git init</span><br><span class="line">terraform init</span><br></pre></td></tr></table></figure><p>Provide: Terraform object that is responsible for managing the lifecycle of a resouce:</p><ul><li>Create, REad, Update, and Delete operations (CRUD)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat providers.tf</span><br><span class="line">provider &quot;aws&quot;&#123;</span><br><span class="line">  region = &quot;ap-southeast-2&quot;</span><br><span class="line">&#125;</span><br><span class="line">git add -A</span><br><span class="line">git commit -m &quot;Add aws provider&quot;</span><br><span class="line">terraform init</span><br><span class="line">git status</span><br><span class="line">echo &quot;.terraform&quot; &gt;&gt; .gitignore</span><br><span class="line">git status</span><br><span class="line">git add .gitignore&amp;&amp; git commit -m &quot;Add .gitignore&quot;</span><br><span class="line">terraform plan # creates an execution plan</span><br></pre></td></tr></table></figure></li></ul><h2 id="Deploy-an-s3-bucket-into-aws"><a href="#Deploy-an-s3-bucket-into-aws" class="headerlink" title="Deploy an s3 bucket into aws"></a>Deploy an s3 bucket into aws</h2><p>google terraform s3 bucket<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat s3.tf</span><br><span class="line">resource &quot;aws_s3_bucket&quot; &quot;main&quot; &#123;</span><br><span class="line">  bucket = &quot;packt-terraform-section2-bucket-stan&quot;</span><br><span class="line">  acl    = &quot;private&quot;</span><br><span class="line">&#125;</span><br><span class="line">git add . &amp;&amp; git commit -m &quot;Add S3 bucket&quot;</span><br><span class="line">terraform plan</span><br><span class="line"># The output of this command is similar to what we get when we run the diff command on Linux: resources with a plus sign are going to be created, resources with the minus sign are going to be deleted, and resources with a tilde sign are going to be modified</span><br><span class="line">terraform apply</span><br><span class="line">git status</span><br><span class="line"># notice that Terraform also created a new file, terraform.tfstate</span><br><span class="line"># it&apos;s a JSON file, which contains some information about the bucket we just created. Terraform uses the state file to map real-world resources to your configuration, and keep track of metadata</span><br></pre></td></tr></table></figure></p><p><strong>What is state?</strong></p><ul><li>Desired state</li><li>Actual state</li><li>Known state<br>When we write our configuration files, we describe the desired state. This is how we want our infrastructure to be. Then there’s the actual state: this is how our infrastructure looks like, right now. You can get this actual state by exploring your infrastructure in the web console, or running some describe commands against the API. And to bridge these two states, there is the known state, which is stored in the state file. Terraform uses it to keep track of all resources it already created for this set of templates. In general, this known state should be the same as the actual state. When we run the plan command, Terraform performs a refresh, and then determines what actions are necessary to achieve the desired state specified in the configuration files. When you run the apply command, Terraform executes the planned actions, and then stores the updated actual state in the state file.</li></ul><p>for example, you went to the web console and manually changed something - Terraform will detect such changes, and unless they also exist in the desired state, it will revert them. So, if we are going to treat our <strong>infrastructure as code</strong>, we should get into the mindset of not changing our sources manually.</p><p>Make sure the state file is ignored by Git<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> cat .gitignore</span><br><span class="line">.terraform</span><br><span class="line"></span><br><span class="line">*.tfstate*</span><br><span class="line">git add -A &amp;&amp; git commit -m &quot;Ignore TF state&quot;</span><br></pre></td></tr></table></figure></p><h2 id="Structuring-the-project"><a href="#Structuring-the-project" class="headerlink" title="Structuring the project"></a>Structuring the project</h2><p>Typical project structure<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">|-main.tf</span><br><span class="line">|-outputs.tf</span><br><span class="line">|-variables.tf</span><br></pre></td></tr></table></figure></p><p>group related resources together, and keep the configuration files to a manageable size - ideally, not longer than 200 lines of code.</p><h1 id="Modifying-resoureces"><a href="#Modifying-resoureces" class="headerlink" title="Modifying resoureces"></a>Modifying resoureces</h1><h2 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h2><p>Keep the code DRY- Don’t Repeat Yourself-SOFTWARE ENGINEERING PRICIPLE aimed at reducing interpretation of the same data</p><p>Terraform performs automatic conversion from string values to numeric and boolean values, based on context.</p><p>Maps are useful for selecting a value based on some other provided value.</p><p>A list value is an ordered sequence of strings, indexed by integers starting with 0.</p><p>Several ways to set variables:</p><ol><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">cat variables.tf</span><br><span class="line">variable &quot;s3_bucket_name&quot; &#123;</span><br><span class="line">        #default = &quot;packt-terraform-section2-bucket-stan&quot;</span><br><span class="line">        description = &quot;Name of the S3 bucket&quot;</span><br><span class="line">        type = &quot;string&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">variable &quot;s3_tags&quot; &#123;</span><br><span class="line">        type = &quot;map&quot;</span><br><span class="line"></span><br><span class="line">        default = &#123;</span><br><span class="line">                created_by = &quot;terraform&quot;</span><br><span class="line">                environment = &quot;test&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">variable &quot;s3_regions&quot; &#123;</span><br><span class="line">        type = &quot;list&quot;</span><br><span class="line">        default = [&quot;ap-southeast-2&quot;, &quot;us-west-2&quot;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">terraform plan</span><br><span class="line">var.s3_bucket_name</span><br><span class="line">  Name of the S3 bucket</span><br><span class="line"></span><br><span class="line">  Enter a value: packt-terraform-section2-bucket-stan</span><br><span class="line"></span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">terraform plan -var &apos;s3_bucket_name=&quot;packt-terraform-section2-bucket-stan&quot;&apos;</span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure></li></ol><p>3.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TF_VAR_s3_bucket_name=&quot;packt-terraform-section2-bucket-stan&quot; terraform plan</span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure></p><p><strong>Variable definition files</strong></p><ul><li>We can also have multiple tfvars files, and pass them explicitly to Terraform using the var file flag. If we pass several files, Terraform will merge their values - and if a particular variable is defined in more than one variable file, the last value that is filed wins. </li><li>Terraform automatically loads all files which match terraform.tfvars or *.auto.tfvars from the current directory</li><li>Other files can be passed explicitly using -var-file flag<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat terraform.tfvars</span><br><span class="line">s3_bucket_name = &quot;packt-terraform-section2-bucket-stan&quot;</span><br><span class="line">terraform plan</span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure></li></ul><p><strong>String Interpolation</strong></p><ul><li>The process of evaluating a string expression and replacing all paceholders with their values<br><code>&quot;${var.s3_bucket_name}&quot;</code><br><strong>First-Class Expressions</strong><br><code>var.s3_bucket_name</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> cat s3.tf</span><br><span class="line">resource &quot;aws_s3_bucket&quot; &quot;main&quot; &#123;</span><br><span class="line">  bucket = &quot;$&#123;var.s3_bucket_name&#125;&quot;</span><br><span class="line">  acl    = &quot;private&quot;</span><br><span class="line"></span><br><span class="line">  tags   = &#123;</span><br><span class="line">    env = &quot;$&#123;lookup(var.s3_tags, &quot;environment&quot;)&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  region =&quot;$&#123;var.s3_regions[0]&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line">#Terraform console is a useful tool for automation scripts, as it allows you to access arbitrary attributes from a Terraform configuration.</span><br><span class="line">terraform console</span><br><span class="line">&gt; var.s3_tags</span><br><span class="line">&#123;</span><br><span class="line">  &quot;created_by&quot; = &quot;terraform&quot;</span><br><span class="line">  &quot;environment&quot; = &quot;test&quot;</span><br><span class="line">&#125;</span><br><span class="line">&gt; var.s3_tags[&quot;environment&quot;]</span><br><span class="line">test</span><br><span class="line">&gt; exit</span><br></pre></td></tr></table></figure></li></ul><h2 id="Local-development-workflow"><a href="#Local-development-workflow" class="headerlink" title="Local development workflow"></a>Local development workflow</h2><p><strong>Using git to store state is a bad idea</strong></p><ul><li>maintenance overhead</li><li>secrets in plain text</li></ul><p><strong>State</strong></p><ul><li>Local state</li><li>Version Control</li><li>Remote state</li><li>Backends<ul><li>Terraform enterprise</li><li>S3</li><li>Consul: a service networking solution to connect and secure services across any runtime platform and public or private cloud.</li><li>Etcd</li><li>HTTP</li></ul></li></ul><p>Recommend using S3<br><strong>Local Values</strong></p><ul><li><strong>Input variables</strong> are similar to arguments of a function</li><li><strong>Local values</strong> are analogous to local variables within the function’s scope</li></ul><p>edit variables.tf file:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">locals &#123;</span><br><span class="line">        s3_tags= &#123;</span><br><span class="line">                created_by = &quot;terraform&quot;</span><br><span class="line">                environment = &quot;$&#123;var.environment&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>we can skip refreshing it again to save a couple of seconds, here. I will pass a flag, -refresh=false.<br>The state filei(terraform.tfstate) is also used to store some metadata, such as resource dependencies, or a pointer to the provider configuration in situations where multiple AWS providers are present. Another use is to store a cache of the attribute values for all the resources in the state. When we run terraform plan, Terraform must know the current state of resources, and by default it will query the providers and sync the latest attributes from all our resources. For large infrastructure, this can be too slow, and we may get throttled at the API level - so, as a performance improvement, there is an option to disable this behavior by passing refresh=false flag.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">terraform plan -refresh=false</span><br><span class="line"></span><br><span class="line">An execution plan has been generated and is shown below.</span><br><span class="line">Resource actions are indicated with the following symbols:</span><br><span class="line">-/+ destroy and then create replacement</span><br><span class="line"></span><br><span class="line">Terraform will perform the following actions:</span><br><span class="line"></span><br><span class="line">terraform apply -auto-approve  ##skip answer yes</span><br><span class="line"></span><br><span class="line">export TF_CLI_ARGS_apply=&quot;-auto-approve&quot;</span><br></pre></td></tr></table></figure></p><p><strong>Common Workflow</strong></p><ul><li>validate</li><li>plan</li><li>apply</li><li>fmt<br><a href="https://github.com/antonbabenko/pre-commit-terraform">Pre-Commit Hooks</a><h2 id="Deleting-Resources"><a href="#Deleting-Resources" class="headerlink" title="Deleting Resources"></a>Deleting Resources</h2>1.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">terraform plan -destroy</span><br><span class="line">terraform destroy</span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li>remove a resource from configuration and then run terraform plan &amp;&amp; terraform apply</li></ol><p>the 2nd one is more suted to CI/CD systems. You will most likely have some pipeline for provisioning your resources, but you may not necessarily have any automated way of destroying them, because this doesn’t happen that often. Another point is that, this way, you can destroy specific resources without having to pass special flags, which would require changes to automation scripts.</p><p><strong>Protect a resoure from deletion</strong><br>Use the life cycle meta-parameter.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lifecycle &#123;</span><br><span class="line">  prevent_destory = &quot;true&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Only protects against terraform destory.</p><h2 id="Managing-state"><a href="#Managing-state" class="headerlink" title="Managing state **"></a>Managing state <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em>**</em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h2><p><a href="https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS/tree/master/Section_3">code</a></p><p><strong>set up the remote state backend</strong></p><ol><li>Create the Terraform configuration section</li></ol><p>This block is special, as it configures the behavior of Terraform itself, such as setting up a backend or requiring a minimum Terraform version to execute a configuration.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  required_version = &quot;&gt; 0.11.7&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>if we have some configuration which we can’t migrate to the latest version, for some reason, we can pin it to an older version in this block. Let’s set the current version.</p><p><strong>Manage terraform versions for each project by Terraform switcher</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># MacOS with brew</span><br><span class="line">brew install warrensbox/tap/tfswitch</span><br><span class="line"># Linux</span><br><span class="line">curl -L https://raw.githubusercontent.com/warrensbox/terraform-switcher/release/install.sh | bash</span><br><span class="line">tfswitch</span><br></pre></td></tr></table></figure></p><ol start="2"><li><p>Add a backend</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">backend &quot;s3&quot; &#123;</span><br><span class="line">    bucket = &quot;packt-terraform-bucket-stan-test-ap-southeast-2&quot;</span><br><span class="line">    key = &quot;test/backbone&quot;</span><br><span class="line">    region = &quot;ap-southeast-2&quot;</span><br><span class="line">    encrypt = &quot;true&quot;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li><li><p>Apply</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m &quot;Configure remote state&quot;</span><br><span class="line">git clean -fdx #clean the repository of all unchecked files</span><br><span class="line">Removing .terraform/</span><br><span class="line">Removing terraform.tfstate</span><br><span class="line">Removing terraform.tfstate.backup</span><br><span class="line">terraform init</span><br><span class="line">terraform plan #there is no more local state file anymore</span><br></pre></td></tr></table></figure></li><li><p>configuration todo</p></li></ol><ul><li><p>enforce encryption by default (here use the default one, you can use KMS instead)<br>by edit s3.tf:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server_side_encryption_configuration &#123;</span><br><span class="line">  rule &#123;</span><br><span class="line">    apply_server_side_encryption_by_default &#123;</span><br><span class="line">       sse_algorithm = &quot;AES256&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>versioning: alwasy have a way back</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">versioning &#123;</span><br><span class="line">   enabled = true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>lifecycle policy: Versioning will store all previous versions of the file, which will eventually bloat the bucket size. To reverse this, we can set a lifecycle policy. Remove all the version after 90 days. In your particular case, you might want to use a different value, or maybe move them to <strong>glacier storage</strong> instead of deleting the old files.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">lifecycle_rule &#123;</span><br><span class="line">   id      = &quot;state&quot;</span><br><span class="line">   prefix  = &quot;state/&quot;</span><br><span class="line">   enabled = true</span><br><span class="line"></span><br><span class="line">   noncurrent_version_expiration &#123;</span><br><span class="line">      days = 90</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p><strong>Best Practices</strong></p><ul><li>Do not store state locally</li><li>Do not commit state to version control</li><li>If using S3:<ul><li>Enable versioning</li><li>Enforce encryption</li><li>Store state close to the infrastructure</li><li>Limit access to the bucket, consider enabling log in</li></ul></li></ul><h1 id="Building-a-multi-tier-environment"><a href="#Building-a-multi-tier-environment" class="headerlink" title="Building a multi-tier environment"></a>Building a multi-tier environment</h1><p><strong>What we will build?</strong></p><ul><li>Network layer-Virtual Private Cloud (VPC), internet gateway, public and private subnets, NAT gateway, and a bastion host)</li><li>Relational Database Service (RDS) instance running PostgreSQL</li><li>Elastic Container Service (ECS) cluster to host a dockerised app<br><strong>Provider Caching</strong></li><li><strong>terraform init</strong> downloads providers separately for each project</li><li>We can cache them by setting an environment variable<br>  export TF_PLUGIN_VACHE_DIR=”$HOME/.terraform.d/plugin-cache”<br><a href="https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS/tree/master/Section_4/vpc">code</a><br><img src="https://i.imgur.com/Rzhlc11.png" alt="AWS VPC"><br><strong>Count Meta-Parameter</strong></li><li>Available to all resources</li><li>Allows creating multiple copies of a resouce without repeating its configuration</li><li>Helps keep your infrastructure code <strong>DRY</strong><br><strong>Splat Expression</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;aws_nat_gateway&quot; &quot;main&quot; &#123;</span><br><span class="line">  count         = &quot;$&#123;length(var.availability_zones)&#125;&quot;</span><br><span class="line">  subnet_id     = &quot;$&#123;element(aws_subnet.public.*.id, count.index)&#125;&quot;</span><br><span class="line">  allocation_id = &quot;$&#123;element(aws_eip.nat.*.id, count.index)&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>The challenge, here, is that the gateways need to reference the subnets and the IPS that we created, but because we used count, we don’t have a direct reference to each resource. We can resolve this by using a splat expression, which you can see in action where we reference the subnet ID and the allocation ID. A splat expression allows to obtain a list of attribute values from a set of resources created using the count argument. Notice this asterisk, which represents all values in the generated list.</p><h2 id="Organizing-data-with-output-variables"><a href="#Organizing-data-with-output-variables" class="headerlink" title="Organizing data with output variables"></a>Organizing data with output variables</h2><p><strong>Resources and data sources</strong></p><ul><li>Resources provide <strong>Create, Read, Update</strong>,and <strong>Delete</strong> functionality (CRUD)</li><li>Data srouces support <strong>read</strong> operations only<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data &quot;aws_ami&quot; &quot;amazon_linux&quot; &#123;</span><br><span class="line">  most_recent = true</span><br><span class="line">  filter &#123;</span><br><span class="line">    name   = &quot;name&quot;</span><br><span class="line">    values = [&quot;amzn-ami-*-x86_64-gp2&quot;]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p><strong>Output Variables</strong></p><ul><li>Expose important resource attributes and make tme easier to query</li><li>Outputs are exposed to the user and stored in the state file during terraform apply</li><li>A single output block configures a single variable<br><strong>Example Output</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output &quot;vpc_id&quot; &#123;</span><br><span class="line">   value = &quot;$&#123;aws_vpc.main.id&#125;&quot;</span><br><span class="line">   description = &quot;VPC id&quot;</span><br><span class="line">   sensitive = false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>After we run the apply once, the outputs are stored in the state file - so, the next time we need to get them, we can use <code>terraform output</code>.<br>or<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">terraform output public_subnets</span><br></pre></td></tr></table></figure></p><p><strong>provider version</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> terraform providers</span><br><span class="line">.</span><br><span class="line">├── provider.aws 1.31</span><br><span class="line">└── provider.template</span><br><span class="line">ls -l ~/.terraform.d/plugin-cache/linux_amd64</span><br></pre></td></tr></table></figure></p><h2 id="Integrating-components-in-a-complex-environment"><a href="#Integrating-components-in-a-complex-environment" class="headerlink" title="Integrating components in a complex environment"></a>Integrating components in a complex environment</h2><p><img src="https://i.imgur.com/LcsUUkG.png" alt="Adding a database server"><br><strong>Steps to add a DB server</strong></p><ol><li>Create a VPC (done)</li><li>Add Subnets to the VPC (done)</li><li>Create a DB Subnet Group</li><li>Create a VPC Secruity Group</li><li>Create a DB Instance in the VPC</li></ol><p>Integrate separate Terraform configurations while keeping them in different projects</p><p>Remote state serves as a centralized source of truth:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> cat data_sources.tf</span><br><span class="line"># Remote state</span><br><span class="line">data &quot;terraform_remote_state&quot; &quot;vpc&quot; &#123;</span><br><span class="line">  backend = &quot;s3&quot;</span><br><span class="line"></span><br><span class="line">  config &#123;</span><br><span class="line">    bucket = &quot;packt-terraform-bucket-stan-test-$&#123;var.region&#125;&quot;</span><br><span class="line">    key    = &quot;test/vpc&quot;</span><br><span class="line">    region = &quot;$&#123;var.region&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Remote state allows us to share information between current projects, and to build our infrastructures in small atomic configurations focused on one thing.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db_subnet_group.tf</span><br><span class="line">subnet_ids = [&quot;$&#123;data.terraform_remote_state.vpc.private_subnets&#125;&quot;]</span><br></pre></td></tr></table></figure></p><p>Notice the interpolation syntax that we use.first, specify that it’s a data source - then its type, terraform remote state. Then comes the name of particular remote state, VPC, and lastly the attribute that we are interested in. </p><h2 id="Using-templates"><a href="#Using-templates" class="headerlink" title="Using templates"></a>Using templates</h2><p><img src="https://i.imgur.com/IjCKZfO.png" alt="Application tier"><br>deploy a small but realistic web application into our VPC. Our app runs in Docker, so we will provision an LST container service cluster - <strong>ECS</strong> - to host it in our private subnets. We will use <strong>Fargate</strong>, which is a managed compute and orchestration engine, so we won’t need to maintain EC2 instances that run our containers. </p><p><strong>Use Terraform templates to compose complex string inputs</strong><br>App: a REST API for a todo applicaton, written in Go. It uses Postgres scale database as its backend.</p><p><a href="https://hub.docker.com/r/endofcake/go-todo-rest-api-example/">public image on Docker hub</a></p><ol><li>provision an ECS cluster<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat ecs_cluster.tf</span><br><span class="line">resource &quot;aws_ecs_cluster&quot; &quot;main&quot; &#123;</span><br><span class="line">  name = &quot;$&#123;var.ecs_cluster_name&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p><strong>Partitioning Infrastructure</strong></p><ul><li>If the resources are likely to be created and destryoed together, they belong together</li><li>If some resource can be used by multiple other resources, it’s better to keep it sparate (VPC,RDS, and ECS cluster)</li></ul><p>template eg.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">bastion.tf</span><br><span class="line"># User data</span><br><span class="line">data &quot;template_file&quot; &quot;user_data&quot; &#123;</span><br><span class="line">  template = &quot;$&#123;file(&quot;$&#123;path.module&#125;/templates/user_data.sh&quot;)&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/tmplates/user_data.sh</span><br><span class="line">#!/bin/env bash</span><br><span class="line"></span><br><span class="line">set -euo pipefail</span><br><span class="line">exec &gt; &gt;(tee /var/log/user-data.log|logger -t user-data -s 2&gt;/dev/console) 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line">echo &quot;Starting user data...&quot;</span><br><span class="line">yum update -y</span><br><span class="line">yum install -y postgresql96.x86_64</span><br><span class="line">touch /home/ec2-user/success</span><br><span class="line">echo &quot;All done&quot;</span><br></pre></td></tr></table></figure></p><p>Next, I create template_cloudinit_config data source, and pull in the rendered template file. cloudinit_config allows us to compose multi-part user data scripts.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data &quot;template_cloudinit_config&quot; &quot;user_data&quot; &#123;</span><br><span class="line">  gzip          = true</span><br><span class="line">  base64_encode = true</span><br><span class="line"></span><br><span class="line">  part &#123;</span><br><span class="line">    content_type = &quot;text/x-shellscript&quot;</span><br><span class="line">    content      = &quot;$&#123;data.template_file.user_data.rendered&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>If we run terraform apply with this configuration on Windows, it most likely wouldn’t work - the problem is that Windows use a different line break tag, which is not valid on Linux. Windows use both carriage return and line feed, while Linux only uses line feed. The easiest way to check the line break tag is to look at the bottom right corner of the editor. Anyway, long story short, we want to make sure that this script is valid, even if we deploy our configuration from a Windows machine. This is probably the only case where there is any difference between running Terraform on Linux and on Windows. There are two changes that you should make to resolve this.</p><ol><li><p>add a gitattributes file</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat .gitattributes</span><br><span class="line"># Always LF</span><br><span class="line">*.sh text eol=lf</span><br></pre></td></tr></table></figure></li><li><p>use EditorConfig plugin to define how our text editor displays and saves our code<br><img src="https://i.imgur.com/55JD2B3.png" alt="editorconfig plugin"> </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat .editorconfig</span><br><span class="line">[*.sh]</span><br><span class="line">end_of_line = lf</span><br><span class="line">indent_size = 2</span><br></pre></td></tr></table></figure></li></ol><p><a href="https://github.com/stanosaka/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS/tree/master/Section_4/ecs_app_todo">ecs app todo code</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">~/terraform/ecs_app_todo|</span><br><span class="line">⇒  tree</span><br><span class="line">.</span><br><span class="line">├── cloudwatch.tf</span><br><span class="line">├── data_sources.tf</span><br><span class="line">├── ecs_task.tf</span><br><span class="line">├── graph.png</span><br><span class="line">├── iam.tf</span><br><span class="line">├── lb.tf</span><br><span class="line">├── outputs.tf</span><br><span class="line">├── providers.tf</span><br><span class="line">├── templates</span><br><span class="line">│   └── ecs_task.tpl</span><br><span class="line">├── terraform.tfvars</span><br><span class="line">└── variables.tf</span><br></pre></td></tr></table></figure></p><p>templates/ecs_task.tpl file: ECS task definition. It describes which Docker images to use, the required resources, and other configurations necessary to launch the containers. As you can see, it’s a JSON block, which I’ve extracted into a template. It requires a few parameters, mostly to set up the connection to the database. </p><p>ecs_task.tf file: This is the Terraform configuration of our ECS task. I’m using the familiar template file data source, and I’m passing the required variables using the vars parameter, which accepts a map of variables. Some of the variables come from the tfvars file, but many are imported from the remote state. </p><p>data_sources.tf file: If we check out our data sources, we see that we’re pulling in remote state from all three projects that we created earlier. </p><p>lb.tf file: another important resource that we are creating is the load balancer, which distributes income and application traffic across multiple targets, for high availability. It will also allow us to connect to our service from the public internet, and here is the security group which allows public access</p><p><strong>confirm it’s working</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">curl -d &apos;&#123;&quot;title&quot;:&quot;sample project&quot;&#125;&apos; -H &quot;Content-Type: application/json&quot; -X POST todoapp-alb-91218331.ap-southeast-2.elb.amazonaws.com/projects</span><br><span class="line">&#123;&quot;ID&quot;:1,&quot;CreatedAt&quot;:&quot;2019-07-21T12:20:38.881103057Z&quot;,&quot;UpdatedAt&quot;:&quot;2019-07-21T12:20:38.881103057Z&quot;,&quot;DeletedAt&quot;:null,&quot;title&quot;:&quot;sample project&quot;,&quot;archived&quot;:false,&quot;tasks&quot;:null&#125;</span><br><span class="line"></span><br><span class="line">curl todoapp-alb-91218331.ap-southeast-2.elb.amazonaws.com/projects</span><br><span class="line">[&#123;&quot;ID&quot;:1,&quot;CreatedAt&quot;:&quot;2019-07-21T12:20:38.881103Z&quot;,&quot;UpdatedAt&quot;:&quot;2019-07-21T12:20:38.881103Z&quot;,&quot;DeletedAt&quot;:null,&quot;title&quot;:&quot;sample project&quot;,&quot;archived&quot;:false,&quot;tasks&quot;:null&#125;]</span><br><span class="line"></span><br><span class="line">ssh bastion</span><br><span class="line">export PGPASSWORD=foobar</span><br><span class="line">export PGHOST=todoapp.foobar.ap-southeast-2.rds.amazonaws.com</span><br><span class="line">psql -U terraform -d todoapp</span><br><span class="line">todoapp=&gt; \d+</span><br><span class="line">                             List of relations</span><br><span class="line"> Schema |      Name       |   Type   |   Owner   |    Size    | Description</span><br><span class="line">--------+-----------------+----------+-----------+------------+-------------</span><br><span class="line"> public | projects        | table    | terraform | 16 kB      |</span><br><span class="line"> public | projects_id_seq | sequence | terraform | 8192 bytes |</span><br><span class="line"> public | tasks           | table    | terraform | 8192 bytes |</span><br><span class="line"> public | tasks_id_seq    | sequence | terraform | 8192 bytes |</span><br><span class="line">(4 rows)</span><br><span class="line">todoapp=&gt; select * from projects;</span><br><span class="line"> id |          created_at           |          updated_at           | deleted_at |     title      | archived</span><br><span class="line">----+-------------------------------+-------------------------------+------------+----------------+----------</span><br><span class="line">  1 | 2019-07-21 12:20:38.881103+00 | 2019-07-21 12:20:38.881103+00 |            | sample project | f</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure></p><h2 id="Working-with-dependency-graph"><a href="#Working-with-dependency-graph" class="headerlink" title="Working with dependency graph"></a>Working with dependency graph</h2><p><strong>Dependency graph</strong></p><ul><li>All resources in the configuration are organized into a graph</li><li>The graph is used to determine the order in which the resources are created<br><img src="https://i.imgur.com/9swFk8u.png" alt="Directed acyclic graph"><br>Terraform organizes all resources in a configuration in a directed acyclic graph. What this means in plain English is that the dependencies between the resources go in one direction, and there can be no cycles. So, no circular dependencies. When we run the plan command, Terraform builds this graph, checks whether there are any cycles, and then determines which operations can be run in parallel. By default, up to ten nodes in the graph can be processed concurrently. We can control this setting using the parallelism flag on the plan, apply, and destroy commands, but in most cases this is not required.<br><strong>Parallelism</strong></li><li>Up to 10 nodes can be processed concurrently by default</li><li>Conifgurable with <strong>-parallemism</strong> flag for plan, apply, and destroy commands (advanced setting)<br><strong>Dependencies</strong></li><li><p>Implicit-one resource references another resource using the interpolation syntax</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;aws_lb&quot; &quot;todo_app&quot; &#123;</span><br><span class="line">    security_groups = [&quot;$&#123;aws_security_group.lb.id&#125;&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Explicit-using depends_on metaparameter<br> <code>depends_on = [&quot;aws_security_group.lb&quot;]</code></p></li></ul><p>Use explicit dependencies to resolve race conditions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Have to set an explicit dependency here to avoid</span><br><span class="line">  # race condition with LB creation</span><br><span class="line">depends_on = [&quot;aws_lb_listener.todo_app&quot;]</span><br></pre></td></tr></table></figure></p><p><strong>tools</strong></p><ol><li><p><a href="http://graphviz.gitlab.io/download/">Graphviz</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">terraform graph|dot -Tpng &gt; graph.png</span><br><span class="line">terraform plan</span><br><span class="line">terraform graph -draw-cycles|dot -Tpng &gt; graph.png</span><br></pre></td></tr></table></figure></li><li><p><a href="https://github.com/28mm/blast-radius">blast radius</a></p></li></ol><h2 id="Main-takeaways"><a href="#Main-takeaways" class="headerlink" title="Main takeaways"></a>Main takeaways</h2><ul><li>Use outputs and remote state data source to integrate stacks of resources in a complex environment</li><li>Keep your code DRY by using <em>count</em> parameter and splat expressions</li><li>Use <strong>templates</strong> to generate complex string inputs, such as user data scripts or ECS task definitions</li></ul><h1 id="Creating-reusable-components-with-moduels"><a href="#Creating-reusable-components-with-moduels" class="headerlink" title="Creating reusable components with moduels"></a>Creating reusable components with moduels</h1><h2 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h2><ul><li>Self-contained packages of Terraform configurations that are managed as a group<br>When we want to avoid writing duplicate code in a general-purpose programming language, we usually write a library. In, Terraform, we can put our code in a <strong>module</strong>.</li><li>Improve code resue</li><li>Provide an abstration layer<br>for example, you may need to add a vault cluster to your environment, and the vault is another great Hashicorp tool which is used for managing secrets, which requires dozens of components - but instead of thinking about individual security groups or EC2 instances, you can treat all these resources as a single group which requires some parameters, and gives you a ready-to-use vault cluster. </li><li>Can be teated as blackbox</li><li>Share best practices within an organization</li><li>Versioned artifacts</li></ul><h2 id="Creating-the-first-module"><a href="#Creating-the-first-module" class="headerlink" title="Creating the first module"></a>Creating the first module</h2><ul><li>Root module:<ul><li>The current working dirctory holding Terraform files</li></ul></li><li>Child modules:<ul><li>All modules sourced by the root (parent) module<br><strong>Delaring Modules</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">module &quot;child&quot; &#123;</span><br><span class="line">source = &quot;./child&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><ol><li>rename ecs app project to module.ecs_app_web<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat main.tf</span><br><span class="line">module &quot;child&quot; &#123;</span><br><span class="line">    source = &quot;../module.ecs_app_web&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p><strong>terraform get</strong></p><ul><li>terraform get: Download modules referenced in the root module</li><li>terraform get -update: Check the downloaded modules for updates and download the new versions. if present<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> terraform get -update</span><br><span class="line">- module.child</span><br><span class="line">  Updating source &quot;../module.ecs_app_web&quot;</span><br></pre></td></tr></table></figure></li></ul><p>When you run terraform get, the local modules will be simlinked into .terraform directory, so you can inspect what’s there if you notice some unexpected behavior.</p><ol start="2"><li>copy terraform.tfvars and variables.tf, modify main.tf file, add<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">region = &quot;$&#123;var.region&#125;&quot; </span><br><span class="line">app_image_version = &quot;$&#123;var.app_image_version&#125;&quot; </span><br><span class="line">app_image_repository = &quot;$&#123;var.app_image_repository&#125;&quot; </span><br><span class="line">app_name = &quot;$&#123;var.app_name&#125;&quot; </span><br><span class="line">container_port = &quot;$&#123;var.container_port&#125;&quot; </span><br><span class="line">desired_count = &quot;$&#123;var.desired_count&#125;&quot; </span><br><span class="line">pgsslmode = &quot;$&#123;var.pgsslmode&#125;&quot; </span><br><span class="line">network_mode = &quot;$&#123;var.network_mode&#125;&quot; </span><br><span class="line">requires_compatibilities = &quot;$&#123;var.requires_compatibilities&#125;&quot; </span><br><span class="line">launch_type = &quot;$&#123;var.launch_type&#125;&quot; </span><br><span class="line">health_check_path = &quot;$&#123;var.health_check_path&#125;&quot;</span><br></pre></td></tr></table></figure></li></ol><p><strong>terraform providers</strong></p><ul><li>terraform providers:<ul><li>Print information about the providers used in the currrent configuration</li></ul></li><li>terraform providers [config-path]:<ul><li>Pass an explicit path to the configuration instead of using the current working directory by default<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> terraform providers</span><br><span class="line">.</span><br><span class="line">└── module.child</span><br><span class="line">    ├── provider.aws 1.31</span><br><span class="line">    ├── provider.template 1.0.0</span><br><span class="line">    └── provider.terraform</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>There is only one module, and it uses two providers - AWS and Template, plus a special provider called Terraform, which is responsible for working with the remote state backend.</p><p><strong>best practices</strong>: Keep explicit provider configurations only in the root module, and pass them down to descendant modules.</p><p><strong>Two wasy pass providers</strong></p><ul><li>the most common approach: let the descendant modules inherit the providers implicitly - that is, automatically</li><li>have several providers of the same type, and then pass them explicitly by alias; this can be useful if we need to create resources in different AWS regions, for example</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">root@stan-OptiPlex-380:~stan/Doc/Terraform/ecs_app_todo|master⚡</span><br><span class="line">⇒  mv ../module.ecs_app_web/providers.tf ./</span><br><span class="line">root@stan-OptiPlex-380:~stan/Doc/Terraform/ecs_app_todo|master⚡</span><br><span class="line">⇒  terraform init</span><br><span class="line">Initializing modules...</span><br><span class="line">- module.child</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line"></span><br><span class="line">Successfully configured the backend &quot;s3&quot;! Terraform will automatically</span><br><span class="line">use this backend unless the backend configuration changes.</span><br><span class="line"></span><br><span class="line">Initializing provider plugins...</span><br><span class="line">- Checking for available provider plugins on https://releases.hashicorp.com...</span><br><span class="line">- Downloading plugin for provider &quot;aws&quot; (1.31.0)...</span><br><span class="line">- Downloading plugin for provider &quot;template&quot; (1.0.0)...</span><br><span class="line"></span><br><span class="line">Terraform has been successfully initialized!</span><br><span class="line"></span><br><span class="line">You may now begin working with Terraform. Try running &quot;terraform plan&quot; to see</span><br><span class="line">any changes that are required for your infrastructure. All Terraform commands</span><br><span class="line">should now work.</span><br><span class="line"></span><br><span class="line">If you ever set or change modules or backend configuration for Terraform,</span><br><span class="line">rerun this command to reinitialize your working directory. If you forget, other</span><br><span class="line">commands will detect it and remind you to do so if necessary.</span><br><span class="line">root@stan-OptiPlex-380:~stan/Doc/Terraform/ecs_app_todo|master⚡</span><br><span class="line">⇒  terraform providers</span><br><span class="line">.</span><br><span class="line">├── provider.aws 1.31</span><br><span class="line">├── provider.template 1.0.0</span><br><span class="line">├── provider.terraform (from state)</span><br><span class="line">└── module.child</span><br><span class="line">    ├── provider.aws (inherited)</span><br><span class="line">    ├── provider.template (inherited)</span><br><span class="line">    └── provider.terraform</span><br></pre></td></tr></table></figure><p><strong>Use module-relative path for embedded files (${path.module})</strong></p><p><strong>Encapsulation</strong></p><ul><li>A language mechanism for restricting direct access to some of the object’s components</li></ul><p>we can choose to make the module as transparent as possible - and in this case, it would inject all dependencies from the root module, and keep no data sources in the child module</p><h1 id="Error-and-debug"><a href="#Error-and-debug" class="headerlink" title="Error and debug"></a>Error and debug</h1><ol><li>Error 1:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">terraform init</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line">Backend configuration changed!</span><br><span class="line"></span><br><span class="line">Terraform has detected that the configuration specified for the backend</span><br><span class="line">has changed. Terraform will now check for existing state in the backends.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Error inspecting states in the &quot;s3&quot; backend:</span><br><span class="line">    NoSuchBucket: The specified bucket does not exist</span><br><span class="line">        status code: 404, request id: E51C641611FF2763, host id: 9AN52en4R7RaZueavAicV5/N01SahL+Y1TZBT8TGnYBYYD5ywWxPKgkiiqDx8+FsgkwNNyadfSU=</span><br><span class="line"></span><br><span class="line">Prior to changing backends, Terraform inspects the source and destination</span><br><span class="line">states to determine what kind of migration steps need to be taken, if any.</span><br><span class="line">Terraform failed to load the states. The data in both the source and the</span><br><span class="line">destination remain unmodified. Please resolve the above error and try again.</span><br></pre></td></tr></table></figure></li></ol><p>Debug mode:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> TF_LOG=trace terraform init</span><br><span class="line">2019/07/21 11:50:39 [INFO] Terraform version: 0.11.7  41e50bd32a8825a84535e353c3674af8ce799161</span><br><span class="line">2019/07/21 11:50:39 [INFO] Go runtime version: go1.10.1</span><br><span class="line">2019/07/21 11:50:39 [INFO] CLI args: []string&#123;&quot;/root/.terraform.versions/terraform_0.11.7&quot;, &quot;init&quot;&#125;</span><br><span class="line">2019/07/21 11:50:39 [DEBUG] Attempting to open CLI config file: /root/.terraformrc</span><br><span class="line">2019/07/21 11:50:39 [DEBUG] File doesn&apos;t exist, but doesn&apos;t need to. Ignoring.</span><br><span class="line">2019/07/21 11:50:39 [INFO] CLI command args: []string&#123;&quot;init&quot;&#125;</span><br><span class="line">2019/07/21 11:50:39 [DEBUG] command: loading backend config file: /root/terraform/vpc</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line">2019/07/21 11:50:39 [TRACE] Preserving existing state linea</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><ol start="2"><li>Error2:<br><img src="https://i.imgur.com/NvWneaV.png" alt="error2"><br>if ecs try to connect to localhost as rds, and couldnot connect sucessfully</li></ol><p>Debug:<br>ecs_task.tpl pg environment vars are all missing</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS&quot;&gt;Supplemental content&lt;/a&gt;&lt;/p&gt;
&lt;h1 id
      
    
    </summary>
    
    
      <category term="aws" scheme="http://223.95.78.227/tags/aws/"/>
    
      <category term="terraform" scheme="http://223.95.78.227/tags/terraform/"/>
    
      <category term="automation" scheme="http://223.95.78.227/tags/automation/"/>
    
  </entry>
  
  <entry>
    <title>agile</title>
    <link href="http://223.95.78.227/2019/07/05/agile/"/>
    <id>http://223.95.78.227/2019/07/05/agile/</id>
    <published>2019-07-05T01:10:42.858Z</published>
    <updated>2019-07-05T01:10:42.858Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Agile-is-a-movement"><a href="#Agile-is-a-movement" class="headerlink" title="Agile is a movement."></a>Agile is a movement.</h1><p>Movement: a group of people working together to advance their shared political, social, or artistic ideas.</p><h2 id="Early-agile-methodologies"><a href="#Early-agile-methodologies" class="headerlink" title="Early agile methodologies"></a>Early agile methodologies</h2><ul><li>1995: Scrum<ul><li>Iterative cycles of work</li><li>Emphasis on cross-functional collaboration</li></ul></li><li>Mid-90s: Crystal<ul><li>Emphasis on adaptability and “stretch-to-fit” process</li></ul></li><li>1990: XP<ul><li>Short, iterative cycles of work</li><li>Emphasis on collaboration between developers</li></ul></li></ul><p><img src="https://i.imgur.com/MjJqXdR.jpg" alt="agile manifesto"><br><strong>Agile Values</strong></p><ul><li>Increase cross-functional collaboration</li><li>Minimize works in progress (sepecs, etc)</li><li>Work in iterative cycles to incorporate change and get frequent feedback</li><li>Make time to reflect on how you work</li></ul><hr><h1 id="Agile-Development"><a href="#Agile-Development" class="headerlink" title="Agile Development"></a>Agile Development</h1><p><strong>born-on-the-cloud model</strong>: cloud as the primary platform for both consumed and delivered services<br>Agility to get projects up and running quickly<br>streamlined process by reducing transitions from Development to Operations</p><p>Java EE application with a Minimum Viable Product (MVP)<br>setup the cloud infrastructure and Toolchain using the Born-on-the-cloud approach</p><p>Hypothesis-driven development</p><p>ranked backlog, user stories, story points<br>tracking and delivering in Timeboxed iterations</p><p><strong>backlog</strong> is a prioritized list of features (User Stores) waiting to be scheduled and implemented</p><p>Note that among other things one of the most important responsibilities of the product owner role in Agile development methodology is to keep the backlog ranked by priority, and he or she can set the priorities by simply dragging the issues and ordering them, regardless of when they were added to the backlog</p><p>User stories: who, what, why<br>story points and planning poker</p><p><strong>user story</strong> is an informal, natural language description of a chunk of functionality that is of value from an end-user perspective<br>As a <who>, I want <what> so that <why></p><p><strong>Story Points</strong> are estimates of effort as influenced by the amount of work, complexity, risk, and uncertainty.</p><ul><li>(Adapted) Fibonacci sequence: 0,1,2,3,5,8,13,20,40,100</li></ul><p><strong>Planning Poker</strong> is a consensus-based, gamified technique for estimating<br>Timeboxing refers to the act of putting strict time boundaries around an action for activity</p><p>time boxed interrogations along with story points are important to measure the team velocity over time. For example you should track the total amount of story points that team delivers each iteration, and this way you’ll be able to determine on average the team velocity metric, or in other words how many story points on average the team is able to deliver. </p><p>Architecture breakdown</p><ul><li>User interface (html/css/javascript)</li><li>CRUD Service(REST APIs with JAX-RS)</li><li>Database(NoSQL)</li></ul><p><strong>Test-Driven Development (TDD)</strong> is a technique for building software by writing automate test cases before writing any code<br>why: focus on the outcome; helps to manage risk; enables fast iterations and continous integration; keeps the code clear, simple and testable;<br>grater confidence to make applicaton changes; documentation of how the system works</p><p>How:add a test-&gt;run all tests and see if the new one fails-&gt; write the code-&gt;run tests-&gt; refactor the code-&gt;repeat</p><p>A <strong>delivery pipeline</strong> is a sequence of automated stages that retrieve input and run jobs, such as builds, tests, and deployments.<br>It automates the continuous deployment of a project, with miniumum or no-human intervention.</p><ul><li>A Stage retrieves input and run jobs, such as builds,tests, and deployments.</li><li>Jobs run in discrete working directories in containers that are created for each pipeline run</li><li>By default, stages run sequentially after changes are delivered to source control</li></ul><p><strong>showcase the applicaton</strong>: At the end of the iteration before the retrospective meeting that is a showcase meaning, also know as demo meeting, where the work done is demonstrated to the stakeholders and feedback is obtaining. The showcase meeting starts by reviewing what we have committed in the form of user stories. And finally we demonstrate what we have accomplished in the form of working software, so we can acquire feedback on the product we are building.</p><p><strong>retrospective meeting</strong>: how to conduct<br>1st way:<br>What went well?<br>what could be improved?</p><p>2nd way:<br>Start doing</p><ul><li>continuous delivery<br>stop doing</li><li>time-bxed iterations<br>continue doing</li><li>ranked backlog</li></ul><h2 id="Common-Problems"><a href="#Common-Problems" class="headerlink" title="Common Problems"></a>Common Problems</h2><h2 id="Value-Focus"><a href="#Value-Focus" class="headerlink" title="Value/Focus"></a>Value/Focus</h2><table><thead><tr><th>Problems</th><th>Solution</th></tr></thead><tbody><tr><td>Not understanding the market</td><td>Hypothesis-driven development</td></tr><tr><td>Putting wrong products into the market</td><td>Minimum Viable Product (MVP)</td></tr><tr><td>Lack of focus on value</td><td>Timboxing/Iterations</td></tr></tbody></table><h2 id="Productivity-Speed-Cost"><a href="#Productivity-Speed-Cost" class="headerlink" title="Productivity/Speed/Cost"></a>Productivity/Speed/Cost</h2><table><thead><tr><th>Problems</th><th>Solution</th></tr></thead><tbody><tr><td>Too long to get projects up and running</td><td>Born on the Cloud</td></tr><tr><td>Slow to put products into market</td><td>MVP/Delivery pipeline/Continuous delivery</td></tr><tr><td>Too costly projects</td><td>Automation/Toolchain/Delivery pipeline</td></tr></tbody></table><h2 id="Communication-Visibility"><a href="#Communication-Visibility" class="headerlink" title="Communication/Visibility"></a>Communication/Visibility</h2><table><thead><tr><th>Problems</th><th>Solution</th></tr></thead><tbody><tr><td>Priorities aren’t clear</td><td>Ranked backlog</td></tr><tr><td>Requirements not reflecting the user’s needs</td><td>User stories</td></tr><tr><td>Poor team communication</td><td>Daily standup</td></tr><tr><td>Lack of visibility into the progress</td><td>Iteration wall/Showcase meeting</td></tr></tbody></table><h2 id="Quality-Control"><a href="#Quality-Control" class="headerlink" title="Quality/Control"></a>Quality/Control</h2><table><thead><tr><th>Problems</th><th>Solution</th></tr></thead><tbody><tr><td>Low quality products</td><td>Test driven development/Delivery pipeline</td></tr><tr><td>Lack of prcess improvement</td><td>Retrospective meeting/Continous improvement</td></tr><tr><td>Bad Requirements estimations</td><td>Story points/Planning poker</td></tr><tr><td>Not honouring past our commitments</td><td>Track team’s velocity</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Agile-is-a-movement&quot;&gt;&lt;a href=&quot;#Agile-is-a-movement&quot; class=&quot;headerlink&quot; title=&quot;Agile is a movement.&quot;&gt;&lt;/a&gt;Agile is a movement.&lt;/h1&gt;&lt;p&gt;
      
    
    </summary>
    
    
      <category term="agile" scheme="http://223.95.78.227/tags/agile/"/>
    
      <category term="software development" scheme="http://223.95.78.227/tags/software-development/"/>
    
      <category term="agile development" scheme="http://223.95.78.227/tags/agile-development/"/>
    
  </entry>
  
  <entry>
    <title>Devops As A Service</title>
    <link href="http://223.95.78.227/2019/07/04/devops-as-a-service/"/>
    <id>http://223.95.78.227/2019/07/04/devops-as-a-service/</id>
    <published>2019-07-03T23:54:43.000Z</published>
    <updated>2019-07-15T13:30:57.541Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/5ci7g2C.png" alt="Imgur"><br>Business Requirements</p><ul><li>Start with business requirements</li><li>DevOps is about doing the work right</li><li>What about doing the right work? See<ul><li>(Agile) Portfolio Management- making sure the work you are doing is funded and delivering business value, and</li><li>Lean Control - making sure you get early engagement with control functions in your organisation (Audit, Compliance, Security, Architecture,<br>Accessibility, Marketing, etc.)</li></ul></li><li>Work/Requirements are comprised of<ul><li>features of business value (2-3 months), divided into …</li><li>sprints (2-3 weeks) and the sprints are made up of …</li><li>tasks (2-3 days of work)</li></ul></li></ul><p>Tasks</p><ul><li>2-3 days of work</li><li>Developers pull tasks off of a sprint queue</li><li>Sprint goals to demo working software at the end of each sprint</li></ul><p>Code</p><ul><li>Integrated continuously, Build continuously</li><li>All code is reviewed by another team member before committing</li><li>Feature branching or trunk-based development?</li><li>No long lived code branches</li></ul><p>Continuous Integration</p><ul><li>Code built continuously (multiple times per day)</li><li>Fast feedback -continous builds are very fast (&lt; 5mins)</li><li>Best practice build patterns/chains<ul><li>Compile, unit test, integration test, deploy artefacts</li></ul></li></ul><p>Metrics</p><ul><li>Code quality is vital</li><li>Code coverage measures test automation</li><li>Gold/silver/bronze accreditation</li></ul><p>Artifacts</p><ul><li>Green builds produce shippable artefacts (.jar, .dll, .exe, docker image)</li><li>Single store for all internal and external artefacts and libraries</li><li>Security policies around 3rd party libraries and external access</li></ul><p>Infrastructure as Code</p><ul><li>Operations roles change</li><li>Infrastructure provisioning and configuration is automated</li><li>Orchestration tools to provision infrastructure (Terraform, Cloud Formation for AWS)</li><li>Configuration management tools to install and manage software on provisioned infrastructure (Chef, Puppet, Ansible)</li><li>IaC is stored, tested and versioned in source code control</li><li>Organisational Change, move to Site Reliability Engineering (SRE)</li></ul><p>Service Mangement</p><ul><li>Approvals and change are automated</li><li>Products with higher levels of accreditation have lower change management overheads (more automation)</li></ul><p>Continous Deployment</p><ul><li>Infrastructure provisioned automatically</li><li>Configuration automated</li><li>Change approvals automated</li><li>Push button deployment to production</li></ul><p>Monitoring</p><ul><li>Observability driven design</li><li>Monitoring, logging, dash boarding early in the life-cycle</li><li>Issues and observations feed back to developers</li></ul><p>Security</p><ul><li>“Shift Left” security</li><li>“average total cost of a breach ranges from $2.2 million to $6.9 million”</li><li>Code vulnerability scanning in the build pipeline</li><li>Build fail if major/critical issues</li><li>Tools- CheckMarx, Fortify</li><li>Artefact scanning for security vulnerabilities</li><li>Firewalls to protect against 3rd party vulnerabilities</li><li>Tools - Nexus Lifecycle/Fiewall, BackDuck</li><li>Image scanning dof Docker images</li><li>Tools- AquaSec, Twistlock, Tennable, OpenSCAP</li></ul><p>Evolving DevOps @ Scale</p><p>Shadow DevOps -&gt; Enterprise DevOps -&gt; DevOps as a Service</p><p>10 years age -&gt; 5 years ago  -&gt; the future</p><p><img src="https://i.imgur.com/6Ei88Zz.jpg" alt="Enterprise Devops"><br><img src="https://i.imgur.com/jRJvY69.jpg" alt="Devops as a Service"><br><img src="https://i.imgur.com/kQNGOfS.jpg" alt="GitOps"><br><img src="https://i.imgur.com/Vvmeafo.jpg" alt="AWS DevOps"><br><img src="https://i.imgur.com/lwpUXVf.jpg" alt="Azure DevOps"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/5ci7g2C.png&quot; alt=&quot;Imgur&quot;&gt;&lt;br&gt;Business Requirements&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start with business requirements&lt;/li&gt;
&lt;li&gt;D
      
    
    </summary>
    
    
      <category term="Devops" scheme="http://223.95.78.227/tags/Devops/"/>
    
      <category term="aws" scheme="http://223.95.78.227/tags/aws/"/>
    
      <category term="git" scheme="http://223.95.78.227/tags/git/"/>
    
      <category term="Azure" scheme="http://223.95.78.227/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>version control</title>
    <link href="http://223.95.78.227/2019/07/03/version-control/"/>
    <id>http://223.95.78.227/2019/07/03/version-control/</id>
    <published>2019-07-03T01:55:35.000Z</published>
    <updated>2019-07-03T13:35:34.673Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Common-Terminologies"><a href="#Common-Terminologies" class="headerlink" title="Common Terminologies"></a>Common Terminologies</h1><p><strong>Repository</strong>: A unit of storage and change tracking that represents a direcotry whose contents are tacked by Git</p><p><strong>Brach</strong>: A version of a repository that represents the current state of the set of files that constitute a repository</p><p><strong>Master</strong>: The frault or main branch, it is a version of the repository that is considered the single source of truth</p><p><strong>Refrence</strong>: A Git ref or reference is a name corresponding to a commit hash</p><p><strong>HEAD</strong>: A reference to the most recent commit on a branch</p><p><strong>Working Tree</strong>: This refers to the section in which we view and make changes to the files in branch</p><p><strong>Index</strong>: This is an area where Git holds files that have been changed, added, or removed in readiness for a commit</p><p><strong>Commit</strong>: This is an entry into Git’s history that represents a change made to a set of files at a given point in time</p><p><strong>Merge</strong>: A merge is the process of incorporating change from one branch to another</p><p><strong>Workflows</strong>: Workflows refer to the approach a team takes to introduce changes to a code base.</p><h2 id="Workflows"><a href="#Workflows" class="headerlink" title="Workflows"></a>Workflows</h2><p><strong>Gitflow workflow</strong></p><ul><li>This uses two branches: master and develop</li><li>The master branch is used to track release history, while the develop branch is used to track feature integration into the product.</li></ul><p><strong>Centralized workflow</strong></p><ul><li>This approach uses the master branch as the default development branch.</li><li>The changes are committed to the master branch.</li><li>It’s a suitable workflow for small size teams and teams transitioning from Apache Subversion.</li><li>In Apache Subversion, the trunk is the equivalent of the master branch.</li></ul><p><strong>Feature branch workflow</strong></p><ul><li>In this workflow, feature development is carried out in a dedicated branch.</li><li>The branch is then merged to the master once the intended changes are approved.</li></ul><p><strong>Forking workflow</strong></p><ul><li>The individual seeking to make a change to a repository, makes a copy of the desired repository in their respective GitHub account.</li><li>The changes are made in the copy of the source repository and then it’s merged to the source repository throught a pull request.</li></ul><h1 id="Navigating-GitHub"><a href="#Navigating-GitHub" class="headerlink" title="Navigating GitHub"></a>Navigating GitHub</h1><h2 id="Organizations"><a href="#Organizations" class="headerlink" title="Organizations"></a>Organizations</h2><p><strong>Role-based membership</strong></p><ul><li><p>Each personal account that is added to an organization can belong to one of the aforementioned roles.</p></li><li><p>The owner role is the most superior and is used to conduct administrative procedures.<br><strong>Repository level permissions</strong></p><pre class="mermaid">graph TD; Read-->Write; Write-->Admin;</pre></li><li>Teams or their respective members can be assigned read, write, or admin-level permissions to a repository.</li><li>Each level dictates activities that the assigned members undertake, with a varying degree of limitations.<br><strong>Teams</strong></li><li>There are members of an organization that can be grouped into teams, with the option of nesting the teams to match an organization’s structure.<br><strong>Multi-factor authentication</strong></li><li>Organizations support the enforcement of two-factor authentication as well as business-specific single sign-on approaches such as <strong>Security Assertion Markup Language (SAML)</strong> and <strong>System for Corss-domain Identity Management</strong> (SCIM).<h3 id="Market-place-install-codacy"><a href="#Market-place-install-codacy" class="headerlink" title="Market place install codacy"></a>Market place install codacy</h3></li></ul><h1 id="Runtime-config"><a href="#Runtime-config" class="headerlink" title="Runtime config"></a>Runtime config</h1><p>Git configurations are set in three levels:</p><ul><li>System-wide configuration<ul><li>set in the <strong>/etc/gitconfig</strong> file</li><li>access use <strong>git config –system</strong></li></ul></li><li>User specific configuraton<ul><li>~/.gitconfig</li><li>git config –global</li></ul></li><li>Repository-specific configuration<ul><li>Repository specific settings are set in the <strong>path_to_repository/.git/config</strong></li><li>An example of configuration is the GitHub URL of a repository, which set at this level.</li><li>There settings are accessed via <strong>git config –local</strong></li></ul></li></ul><h2 id="Removing-configuratoin"><a href="#Removing-configuratoin" class="headerlink" title="Removing configuratoin"></a>Removing configuratoin</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global --unset [section_name].[section_variable]</span><br></pre></td></tr></table></figure><p>exampel:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global --unset user.name</span><br></pre></td></tr></table></figure></p><p>create a ssh key:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C foobar@cwzhou.win</span><br></pre></td></tr></table></figure></p><h1 id="Fundamentails-of-repositories"><a href="#Fundamentails-of-repositories" class="headerlink" title="Fundamentails of repositories"></a>Fundamentails of repositories</h1><p><strong>Tags</strong><br>There are used for the purpose of identifying specific significant points on a repository’s history.</p><ul><li><p>lightweight tages<br>Lightweight tags act as pointers to a specific commit. It only stores the reference to the commit: <strong>git tag v2.5</strong></p></li><li><p>annotated tags<br>Annotated tags act as pointers to a specific commit and additionally store information about the creator of the tag, the email, and date of creation:<br> <strong>git tag -a v2.6 -m “Support sdk version 3”</strong></p></li></ul><h1 id="Versioning-Commits"><a href="#Versioning-Commits" class="headerlink" title="Versioning Commits"></a>Versioning Commits</h1><p>In git, files can have the following statuses:</p><ul><li>Untracked: This is a file that exists in the working tree whose changes are not being monitored by Git and aren’t listed in the <strong>gitignore</strong> file.</li><li>Unstaged: This is a file whose changes are being tracked by Git; the file has been changed since the last commit and has yet to be moved to the <strong>index</strong>.</li><li>Staged: This is a file whose changes are being tracked by Git; the file has been changed since the last commit and has been moved to the index.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure><ul><li>It’s used to retrieve the details of files that are untracked, unstaged, or staged.</li><li><strong>git status</strong> lists files in order of their statuses.</li><li>The <strong>git status</strong> output is lengthy in nature</li><li>To view a brief list and status, use the <strong>-s</strong> or <strong>–short</strong> option with the <strong>git status</strong> command.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">szhou@armitage:~/DevOps/github/foobar|master</span><br><span class="line">⇒  git branch ft-add-encapsulating-class</span><br><span class="line">szhou@armitage:~/DevOps/github/foobar|master</span><br><span class="line">⇒  git checkout ft-add-encapsulating-class</span><br><span class="line">Switched to branch &apos;ft-add-encapsulating-class&apos;</span><br></pre></td></tr></table></figure></li></ul><p>ft is feature branch, bg for bug, fs for rolling out hard fixes, ch for<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add . &amp;&amp; git commit -m &quot;Added a class for match functions&quot; &amp;&amp; git push origin ft-add-encapsulating-class</span><br></pre></td></tr></table></figure></p><p><strong>git diff</strong></p><ul><li>The git diff command is uesed to compare one snapshot of changes to another.</li></ul><p>zoom in the change:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">szhou@armitage:~/DevOps/github/foobar|ft-add-encapsulating-class⚡</span><br><span class="line">⇒  git diff</span><br><span class="line">szhou@armitage:~/DevOps/github/foobar|ft-add-encapsulating-class⚡</span><br><span class="line">⇒  git diff src/lib</span><br><span class="line">szhou@armitage:~/DevOps/github/foobar|ft-add-encapsulating-class⚡</span><br><span class="line">⇒  git diff src/lib/compute.py</span><br></pre></td></tr></table></figure></p><p>Undo the change<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git rest --hard</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git diff HEAD -- src/</span><br><span class="line">git log</span><br><span class="line">git diff master</span><br><span class="line">git diff --cached</span><br><span class="line">git diff ft-add-encapsulating-class..ft-support-multiplication-arithmetic</span><br></pre></td></tr></table></figure><p><strong>git add</strong></p><ul><li>is used to add files to the index from the working tree.</li><li>syntax: <strong>git add [options] [path_to_files]</strong></li></ul><p>The options used with <strong>git add</strong> include <strong>-n</strong> and <strong>–dry-run</strong>: simulates the behaviour of git add for the specified file.</p><p><strong>-f</strong> or <strong>–force</strong>: adds ignored files to the index.</p><p><strong>-i</strong> or <strong>–interactive</strong>: creates an interactive prompt that can be used for adding files from the working tree to the index.</p><p><strong>-por –patch</strong>: caters for adding portions of a file to the index.</p><p><strong>options</strong>:</p><ul><li>?: Print help</li><li>y: Stage this hunk</li><li>n: Do not stage this hunk</li><li>q: Exit or quit. Do not stage this hunk or any of the remaining hunks.</li><li>a: Stage this hunk and all later hunks in the specified files</li><li>d: Do not stage this hunk or any of the remaining hunks in the file</li><li>g: Select a hunk to go to</li><li>/: Search for the hunk that matches the specified regex pattern</li><li>j: Leave this hunk undecided; see the next undecided hunk</li><li>J: Leave this hunk undecided; see the next hunk</li><li>k: Leave this hunk undecided; see the previous undecided hunk</li><li>K: Leave this hunk undecided; see the previous hunk</li><li>s: Split the current hunk into more granular hunks</li><li>e: Manually edit the current hunk</li></ul><p><strong>git commit</strong></p><ul><li>The <strong>git commit</strong> command saves the files in the index.</li><li>The commit operation stores a message along with the commit.</li><li>This message describes the additions or alterations associated with the created snapshot.</li></ul><p>Note: the <strong>git commit</strong> command requires that a message be provided for each commit operation.<br><strong>options</strong>:</p><ul><li>-m [text] or –message [text]: associate the index file with the commit action</li><li>-a or -all: stage tracked files that are unstaged</li><li>-p or –patch: interactive patch tool</li><li>-C [commit hash] or –resue-message=[commit hash]: resue a commit message and the author information of the specified commit hash</li><li>-F [file] or –file=[file]: specifies a file from which a commit message should be obtained</li><li>-t [file] or –template [file]: specifies the commit message template file</li><li>-e or –edit: edits the provided commit message</li><li>–no-edit: uses the specified message as is</li><li>–author=[author]: overrides the details fo a commit author</li><li>–date=[date]: overrides the data details used in a commit</li><li>-q or –quiet: suppresses the summary message that’s returned after running the <strong>git commit</strong> command</li></ul><p><strong>git rm</strong></p><p>The <strong>git rm</strong> command performs two roles.</p><ul><li>Removes files from the working directory and the index</li><li>Remove files from index<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim src/lib/scientific.py</span><br><span class="line">git add . &amp;&amp; git commit -m &quot;Added sci module&quot;</span><br><span class="line">git rm src/lib/scientific.py</span><br><span class="line">git status</span><br><span class="line">git commit -m &quot;Removed sci module&quot;</span><br></pre></td></tr></table></figure></li></ul><p><strong>git mv</strong></p><ul><li>used to rename or move a file or a directory</li><li>This command has two forms of implementation:<ul><li>git mv [options][source][destination]: used to rename a file</li><li>git mv [options][source]…[destination]: used to move a file</li></ul></li></ul><p><strong>git log command</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">git log --follow src/lib/advanced/advanced_compute.py</span><br><span class="line">git log --decorate=full</span><br><span class="line">git log --decorate=short</span><br><span class="line">git log --decorate=no</span><br><span class="line">git log -L 6,12:src/lib/compute.py</span><br><span class="line">git log -n 3</span><br><span class="line">git log -3</span><br><span class="line">git log --skip=4</span><br><span class="line">git log --since=01/01/2018</span><br><span class="line">git log --pretty=oneline</span><br><span class="line">git log --pretty=short</span><br><span class="line">git log --pretty=medium</span><br><span class="line">git log --pretty=format:&quot;%H %an&quot;</span><br></pre></td></tr></table></figure></p><h2 id="Amending-commits"><a href="#Amending-commits" class="headerlink" title="Amending commits"></a>Amending commits</h2><p>The most recent commit can be edited using the –amend option of the <strong>git commit</strong> command.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">git commit --amend</span><br><span class="line">git rebase -i HEAD~4  # retrv the last 4 commits</span><br><span class="line">pick 721d2ec Removed sci module</span><br><span class="line">pick fc150d2 Added sci module</span><br><span class="line">pick 4be4d85 Rename scientific module</span><br><span class="line">pick 9a8a4ea Moved scientific module</span><br><span class="line"></span><br><span class="line">change pick to reword save and quit the file.</span><br><span class="line"></span><br><span class="line">## change the file</span><br><span class="line">git rebase -i HEAD~3</span><br><span class="line">change pick to edit save and quit the file.</span><br><span class="line">vim src/lib/advanced/advanced_compute.py</span><br><span class="line">git status</span><br><span class="line">git add .</span><br><span class="line">git commit --amend</span><br><span class="line">git rebase --continue</span><br><span class="line">git log -4</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Common-Terminologies&quot;&gt;&lt;a href=&quot;#Common-Terminologies&quot; class=&quot;headerlink&quot; title=&quot;Common Terminologies&quot;&gt;&lt;/a&gt;Common Terminologies&lt;/h1&gt;&lt;
      
    
    </summary>
    
    
      <category term="git" scheme="http://223.95.78.227/tags/git/"/>
    
      <category term="github" scheme="http://223.95.78.227/tags/github/"/>
    
      <category term="version control" scheme="http://223.95.78.227/tags/version-control/"/>
    
  </entry>
  
  <entry>
    <title>ansible</title>
    <link href="http://223.95.78.227/2019/06/28/ansible/"/>
    <id>http://223.95.78.227/2019/06/28/ansible/</id>
    <published>2019-06-28T00:23:15.000Z</published>
    <updated>2019-09-14T01:33:07.866Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ansible-configuration"><a href="#Ansible-configuration" class="headerlink" title="Ansible configuration"></a>Ansible configuration</h1><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><p>for ubuntu:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apt-get install software-properties-common</span><br><span class="line">apt-add-repository ppa:ansible/ansible</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install ansible</span><br><span class="line">root@ansible-host:~# ansible --version</span><br><span class="line">ansible 2.8.1</span><br><span class="line">  config file = /etc/ansible/ansible.cfg</span><br><span class="line">  configured module search path = [u&apos;/root/.ansible/plugins/modules&apos;, u&apos;/usr/share/ansible/plugins/modules&apos;]</span><br><span class="line">  ansible python module location = /usr/lib/python2.7/dist-packages/ansible</span><br><span class="line">  executable location = /usr/bin/ansible</span><br><span class="line">  python version = 2.7.12 (default, Nov 12 2018, 14:36:49) [GCC 5.4.0 20160609]</span><br></pre></td></tr></table></figure></p><h2 id="Gran-access-to-modes-machines"><a href="#Gran-access-to-modes-machines" class="headerlink" title="Gran access to modes/machines:"></a>Gran access to modes/machines:</h2><ul><li>ssh-keygen</li><li>ssh-copy-id<br><strong>Setup:</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cp -R /etc/ansible local</span><br><span class="line">cd local</span><br><span class="line">edit ansible.cfg and hosts file</span><br></pre></td></tr></table></figure></li></ul><h2 id="configuration-files"><a href="#configuration-files" class="headerlink" title="configuration files"></a>configuration files</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ANSIBLE_CONFIG #an environemtn variable</span><br><span class="line">ansible.cfg # in the current directory</span><br><span class="line">.ansible.cfg #in the home directory</span><br><span class="line">/etc/ansible/ansible.cfg</span><br></pre></td></tr></table></figure><h2 id="Ansible-inventory"><a href="#Ansible-inventory" class="headerlink" title="Ansible inventory"></a>Ansible inventory</h2><p><code>/etc/ansible/hosts</code><br>INI format, support host variables, group variables and group of group<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># add to /etc/ansible/hosts</span><br><span class="line">[demo_hosts]</span><br><span class="line">node01 ansible_user=ubuntu</span><br><span class="line">node02 ansible_user=ubuntu</span><br><span class="line"># add to /etc/hosts</span><br><span class="line">172.31.5.185 node01</span><br><span class="line">172.31.8.115 node02</span><br></pre></td></tr></table></figure></p><h2 id="Verify-Ansible-Inventory"><a href="#Verify-Ansible-Inventory" class="headerlink" title="Verify Ansible Inventory"></a>Verify Ansible Inventory</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">eval `ssh-agent -s`</span><br><span class="line">ssh-add ansible-key.pem</span><br><span class="line">ansible -m ping all</span><br><span class="line"># add to /etc/ansible/hosts</span><br><span class="line">[web_server]</span><br><span class="line">node01 ansible_user=ubuntu</span><br><span class="line"></span><br><span class="line">[db_server]</span><br><span class="line">node02 ansible_user=ubuntu</span><br><span class="line">ansible web-server -m ping</span><br><span class="line">ansible db-server -m ping</span><br></pre></td></tr></table></figure><h1 id="Local-automation-execution-using-Ansible"><a href="#Local-automation-execution-using-Ansible" class="headerlink" title="Local automation execution using Ansible"></a>Local automation execution using Ansible</h1><p><img src="https://imgur.com/CA9XqyK" alt="architecture type"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Example: Ad hoc Linux echo command against a local system</span><br><span class="line"></span><br><span class="line">#&gt; ansible all -i &quot;localhost,&quot; -c local -m shell -a &apos;echo hello DevOps World&apos;</span><br><span class="line">cat hellodevopsworld.yml</span><br><span class="line"># File name: hellodevopsworld.yml</span><br><span class="line">--- </span><br><span class="line">- hosts: all</span><br><span class="line"> tasks:</span><br><span class="line"> - shell: echo &quot;hello DevOps world&quot;</span><br><span class="line"></span><br><span class="line"># Running a Playbook from the command line:</span><br><span class="line">#&gt; ansible-playbook -i &apos;localhost,&apos; -c local hellodevopsworld.yml</span><br></pre></td></tr></table></figure></p><p><strong>Remote automation execution using Ansible</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Example command: execute the playbook hellodevopsworld.yml against rpi-01</span><br><span class="line">ansible-playbook -i &apos;rpi-01,&apos; -c local  ~/Learning/ansible/hellodevopsworld.yml</span><br></pre></td></tr></table></figure></p><h1 id="Run-and-execute-ansible-tasks"><a href="#Run-and-execute-ansible-tasks" class="headerlink" title="Run and execute ansible tasks"></a>Run and execute ansible tasks</h1><h2 id="Ansible-Command-Line"><a href="#Ansible-Command-Line" class="headerlink" title="Ansible Command Line"></a>Ansible Command Line</h2><p>Two ways: ad-hoc command and playbook</p><h3 id="Ansible-Ad-hoc-Commands"><a href="#Ansible-Ad-hoc-Commands" class="headerlink" title="Ansible Ad-hoc Commands"></a>Ansible Ad-hoc Commands</h3><p><code>ansible &lt;target&gt; -m &lt;module name&gt; -a arguments</code></p><p>support parallelism: <code>&lt;command&gt; -f</code></p><p><code>ansible demo_host -m copy -a &quot;src=/tmp/test1 dest=/tmp/test1&quot;</code> #-m means module, -a optional provided a list of arguments</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ansible-doc -l</span><br><span class="line">ansible-doc copy</span><br><span class="line">ansible-doc -l|grep shell</span><br><span class="line">touch /tmp/test1</span><br><span class="line">ansible demo_hosts -m copy -a &quot;src=/tmp/test1 dest=/tmp/test1&quot;</span><br></pre></td></tr></table></figure><h2 id="Ansible-Facts"><a href="#Ansible-Facts" class="headerlink" title="Ansible Facts"></a>Ansible Facts</h2><p>A fact is a detail or piece of information collect from remote host. Can be use for grouping node, or filter node.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ansible all -m setup</span><br><span class="line">ansible demo_host -m setup</span><br></pre></td></tr></table></figure></p><h2 id="Ansible-Variables"><a href="#Ansible-Variables" class="headerlink" title="Ansible Variables"></a>Ansible Variables</h2><p>Valid Variable names</p><ul><li>Cannot use “-“ (hyphen)</li><li>Can be alphanumeric</li><li>Should start with an alphabet</li></ul><p>Ansible Variables Naming Conventions</p><p>can define variables in Inventory, playbooks file and roles.</p><h2 id="Ansible-Sections"><a href="#Ansible-Sections" class="headerlink" title="Ansible Sections"></a>Ansible Sections</h2><ul><li>Target Section: sepecify the host group</li><li>Variable Section</li><li>Task Section : list all the task</li><li>Handler Section</li><li>Loops</li><li>Conditionals</li><li>Until</li><li>Notify<h2 id="Ansible-playbooks"><a href="#Ansible-playbooks" class="headerlink" title="Ansible playbooks"></a>Ansible playbooks</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root@ansible-host:/home/ubuntu# cat sample.yaml</span><br><span class="line">---</span><br><span class="line">- hosts: demo_hosts</span><br><span class="line">  vars:</span><br><span class="line">      package1 : &quot;nginx&quot;</span><br><span class="line">      package2 : &quot;wget&quot;</span><br><span class="line">  tasks:</span><br><span class="line">   - name: Installing package nginx</span><br><span class="line">     apt: pkg=nginx state=installed update_cache=true</span><br><span class="line">     become: true</span><br><span class="line">   - name: Installing package wget</span><br><span class="line">     apt: name=&#123;&#123; package2 &#125;&#125; state=installed update_cache=true</span><br><span class="line">     become: true</span><br><span class="line">   - name: Copying test1 file</span><br><span class="line">     copy: src=/tmp/test11 dest=/tmp/test11</span><br><span class="line"></span><br><span class="line">ansible-doc apt ##check the manual for ansible apt</span><br><span class="line">ansible-playbook sample.yaml ## run ansible playbook</span><br></pre></td></tr></table></figure></li></ul><h1 id="Deep-Dive-Into-Ansible-Playbooks"><a href="#Deep-Dive-Into-Ansible-Playbooks" class="headerlink" title="Deep Dive Into Ansible Playbooks"></a>Deep Dive Into Ansible Playbooks</h1><h2 id="Install-Apache-with-Ansible-Playbook"><a href="#Install-Apache-with-Ansible-Playbook" class="headerlink" title="Install Apache with Ansible Playbook"></a>Install Apache with Ansible Playbook</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@ansible-host:~# cat apache_install.yaml</span><br><span class="line">---</span><br><span class="line">- hosts: web_portal</span><br><span class="line">  tasks:</span><br><span class="line">    - name: Apt get update</span><br><span class="line">      apt: update_cache=yes</span><br><span class="line"></span><br><span class="line">    - name: Install Apache2</span><br><span class="line">      apt: name=apache2 update_cache=no</span><br><span class="line"></span><br><span class="line">    - name: Copy data files</span><br><span class="line">      copy: src=index.html dest=/var/www/html/</span><br><span class="line"></span><br><span class="line">    - name: Stop the service</span><br><span class="line">      service: name=apache2 state=stopped</span><br><span class="line">root@ansible-host:~# ansible-playbook apache_install.yaml -b</span><br></pre></td></tr></table></figure><h2 id="Run-and-Stop-Service"><a href="#Run-and-Stop-Service" class="headerlink" title="Run and Stop Service"></a>Run and Stop Service</h2><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">root@ansible-host:~# cat current.html.j2</span><br><span class="line">this is my current file -</span><br><span class="line">my hostname is - &#123;&#123; ansible_hostname &#125;&#125;</span><br><span class="line">root@ansible-host:~# cat apache_install.yaml</span><br><span class="line">---</span><br><span class="line">- hosts: web_portal</span><br><span class="line">  tasks:</span><br><span class="line">    - name: Apt get update</span><br><span class="line">      apt: update_cache=yes</span><br><span class="line"></span><br><span class="line">    - name: Install Apache2</span><br><span class="line">      apt: name=apache2 update_cache=no</span><br><span class="line"></span><br><span class="line">    - name: Copy data files</span><br><span class="line">      copy: src=index.html dest=/var/www/html/</span><br><span class="line"></span><br><span class="line">    - name: Stop the service</span><br><span class="line">      service: name=apache2 state=stopped</span><br><span class="line"></span><br><span class="line">    - name: Copy template file</span><br><span class="line">      template: src=current.html.j2 dest=/var/www/html/current.html</span><br><span class="line">      notify:</span><br><span class="line">        - Start apache</span><br><span class="line">  handlers:</span><br><span class="line">    - name: Start apache</span><br><span class="line">      service: name=apache2 state=restarted</span><br><span class="line">### dry run ansible</span><br><span class="line">ansible-playbook apache_install.yaml -b --check</span><br></pre></td></tr></table></figure><h2 id="Debug-Statements-In-playbook"><a href="#Debug-Statements-In-playbook" class="headerlink" title="Debug Statements In playbook"></a>Debug Statements In playbook</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">root@ansible-host:~# cat apache_install.yaml</span><br><span class="line">---</span><br><span class="line">- hosts: web_portal</span><br><span class="line">  tasks:</span><br><span class="line">    - name: Apt get update</span><br><span class="line">      apt: update_cache=yes</span><br><span class="line"></span><br><span class="line">    - name: Install Apache2</span><br><span class="line">      apt: name=apache2 update_cache=no</span><br><span class="line"></span><br><span class="line">    - name: Copy data files</span><br><span class="line">      copy: src=index.html dest=/var/www/html/</span><br><span class="line">      register: copy_status</span><br><span class="line"></span><br><span class="line">    - name: Stop the service</span><br><span class="line">      service: name=apache2 state=stopped</span><br><span class="line"></span><br><span class="line">    - name: Copy template file</span><br><span class="line">      template: src=current.html.j2 dest=/var/www/html/current.html</span><br><span class="line">      notify:</span><br><span class="line">        - Start apache</span><br><span class="line"></span><br><span class="line">    - name: Copy status</span><br><span class="line">      debug: var=copy_status</span><br><span class="line"></span><br><span class="line">  handlers:</span><br><span class="line">    - name: Start apache</span><br><span class="line">      service: name=apache2 state=restarted</span><br><span class="line">root@ansible-host:~# ansible-playbook apache_install.yaml -b</span><br><span class="line"></span><br><span class="line">PLAY [web_portal] *************************************************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [Gathering Facts] ********************************************************************************************************************************</span><br><span class="line">ok: [node01]</span><br><span class="line"></span><br><span class="line">TASK [Apt get update] *********************************************************************************************************************************</span><br><span class="line"> [WARNING]: Could not find aptitude. Using apt-get instead</span><br><span class="line"></span><br><span class="line">changed: [node01]</span><br><span class="line"></span><br><span class="line">TASK [Install Apache2] ********************************************************************************************************************************</span><br><span class="line">ok: [node01]</span><br><span class="line"></span><br><span class="line">TASK [Copy data files] ********************************************************************************************************************************</span><br><span class="line">ok: [node01]</span><br><span class="line"></span><br><span class="line">TASK [Stop the service] *******************************************************************************************************************************</span><br><span class="line">ok: [node01]</span><br><span class="line"></span><br><span class="line">TASK [Copy template file] *****************************************************************************************************************************</span><br><span class="line">ok: [node01]</span><br><span class="line"></span><br><span class="line">TASK [Copy status] ************************************************************************************************************************************</span><br><span class="line">ok: [node01] =&gt; &#123;</span><br><span class="line">    &quot;copy_status&quot;: &#123;</span><br><span class="line">        &quot;changed&quot;: false,</span><br><span class="line">        &quot;checksum&quot;: &quot;9be1fe2ae3529c22cf8a1b0fd1edc53048dcf277&quot;,</span><br><span class="line">        &quot;dest&quot;: &quot;/var/www/html/index.html&quot;,</span><br><span class="line">        &quot;diff&quot;: &#123;</span><br><span class="line">            &quot;after&quot;: &#123;</span><br><span class="line">                &quot;path&quot;: &quot;/var/www/html/index.html&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;before&quot;: &#123;</span><br><span class="line">                &quot;path&quot;: &quot;/var/www/html/index.html&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;failed&quot;: false,</span><br><span class="line">        &quot;gid&quot;: 0,</span><br><span class="line">        &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">        &quot;mode&quot;: &quot;0644&quot;,</span><br><span class="line">        &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">        &quot;path&quot;: &quot;/var/www/html/index.html&quot;,</span><br><span class="line">        &quot;size&quot;: 24,</span><br><span class="line">        &quot;state&quot;: &quot;file&quot;,</span><br><span class="line">        &quot;uid&quot;: 0</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PLAY RECAP ********************************************************************************************************************************************</span><br><span class="line">node01                     : ok=7    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0</span><br></pre></td></tr></table></figure><h2 id="Loops-Conditionals-and-until-section"><a href="#Loops-Conditionals-and-until-section" class="headerlink" title="Loops, Conditionals and until section"></a>Loops, Conditionals and until section</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">root@ansible-host:~# cat apache_install.yaml</span><br><span class="line">---</span><br><span class="line">- hosts: web_portal</span><br><span class="line">  tasks:</span><br><span class="line">    - name: Apt get update</span><br><span class="line">      apt: update_cache=yes</span><br><span class="line"></span><br><span class="line">    - name: Install Apache2, nginx, nmap</span><br><span class="line">      apt: name=&#123;&#123; item &#125;&#125; update_cache=no</span><br><span class="line">      with_items:</span><br><span class="line">         - apache2</span><br><span class="line">         - nginx</span><br><span class="line">         - nmap</span><br><span class="line"></span><br><span class="line">    - name: Copy data files</span><br><span class="line">      copy: src=index.html dest=/var/www/html/</span><br><span class="line">      register: copy_status</span><br><span class="line"></span><br><span class="line">    - name: Stop the service</span><br><span class="line">      service: name=apache2 state=stopped</span><br><span class="line"></span><br><span class="line">    - name: Copy template file</span><br><span class="line">      template: src=current.html.j2 dest=/var/www/html/current.html</span><br><span class="line">      notify:</span><br><span class="line">        - Start apache</span><br><span class="line"></span><br><span class="line">    - name: Copy status</span><br><span class="line">      debug: var=copy_status</span><br><span class="line"></span><br><span class="line">  handlers:</span><br><span class="line">    - name: Start apache</span><br><span class="line">      service: name=apache2 state=restarted</span><br></pre></td></tr></table></figure><h1 id="Putting-it-all-together-with-ansible"><a href="#Putting-it-all-together-with-ansible" class="headerlink" title="Putting it all together with ansible"></a>Putting it all together with ansible</h1><h2 id="Ansible-vault"><a href="#Ansible-vault" class="headerlink" title="Ansible vault"></a>Ansible vault</h2><p>ansible-vault create foo.yml<br>ansible-vaule view foo.yml<br>ansible-playbook site.yml -ask-vault-pass</p><h2 id="Common-Ansible-Modules"><a href="#Common-Ansible-Modules" class="headerlink" title="Common Ansible Modules"></a>Common Ansible Modules</h2><ul><li>Setup module<br>ansible node01 -m setup</li><li>File module<br>ansible-doc file</li><li>Yum module<br>for redhat, centos</li><li>Apt module<br>for debian, ubuntu</li><li>Service module<br>for start and stop service</li><li>Copy module<br>which is used for copy the file</li><li>User module<br>ansible-doc user<br>ansible node01 -m user -a “user=stancloud” -b</li><li>Command module<br>ansible-doc command</li><li><p>Shell module<br>ansible node01 -m shell -a “tail /var/log/syslog”</p><h2 id="Ansible-Roles"><a href="#Ansible-Roles" class="headerlink" title="Ansible Roles"></a>Ansible Roles</h2><p>Roles are similar to project.</p><h3 id="roles-directory-structure"><a href="#roles-directory-structure" class="headerlink" title="roles directory structure"></a>roles directory structure</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">ansible-galaxy init stan</span><br><span class="line">- stan was created successfully</span><br><span class="line">root@ansible-host:/tmp# tree stan</span><br><span class="line">stan</span><br><span class="line">├── defaults</span><br><span class="line">│   └── main.yml</span><br><span class="line">├── files</span><br><span class="line">├── handlers</span><br><span class="line">│   └── main.yml</span><br><span class="line">├── meta</span><br><span class="line">│   └── main.yml</span><br><span class="line">├── README.md</span><br><span class="line">├── tasks</span><br><span class="line">│   └── main.yml</span><br><span class="line">├── templates</span><br><span class="line">├── tests</span><br><span class="line">│   ├── inventory</span><br><span class="line">│   └── test.yml</span><br><span class="line">└── vars</span><br><span class="line">    └── main.yml</span><br><span class="line">roles/</span><br><span class="line">  role-name/</span><br><span class="line">     files/</span><br><span class="line">     templates/ #j2 files</span><br><span class="line">     tasks/</span><br><span class="line">        main.yml</span><br><span class="line">     handlers/</span><br><span class="line">        main.yml</span><br><span class="line">     vars/</span><br><span class="line">        main.yml</span><br><span class="line">     defaults/</span><br><span class="line">        main.yml</span><br><span class="line">     meta</span><br></pre></td></tr></table></figure></li><li><p>Common role</p></li><li>mySQL role</li><li>Apache role</li><li>WordPress role<h3 id="Deploy-wordpress"><a href="#Deploy-wordpress" class="headerlink" title="Deploy wordpress"></a>Deploy wordpress</h3></li></ul><h2 id="Ansible-Galaxy"><a href="#Ansible-Galaxy" class="headerlink" title="Ansible Galaxy"></a>Ansible Galaxy</h2><p>root@ansible-host:/tmp# ansible-galaxy install bennojoy.nginx</p><ul><li>downloading role ‘nginx’, owned by bennojoy</li><li>downloading role from <a href="https://github.com/bennojoy/nginx/archive/master.tar.gz">https://github.com/bennojoy/nginx/archive/master.tar.gz</a></li><li>extracting bennojoy.nginx to /root/.ansible/roles/bennojoy.nginx</li><li>bennojoy.nginx (master) was installed successfully<br><a href="http://jinja.pocoo.org">jinja</a><h1 id="Manage-aws-cloud-resouces-with-ansible"><a href="#Manage-aws-cloud-resouces-with-ansible" class="headerlink" title="Manage aws cloud resouces with ansible"></a>Manage aws cloud resouces with ansible</h1><h2 id="manage-aws-ec2-instances-with-ansible"><a href="#manage-aws-ec2-instances-with-ansible" class="headerlink" title="manage aws ec2 instances with ansible"></a>manage aws ec2 instances with ansible</h2>ansible-doc -l|grep aws<br>ansible-doc -l|grep ec2<h2 id="Deploy-new-aws-ec2-instances-using-ansible-playbook"><a href="#Deploy-new-aws-ec2-instances-using-ansible-playbook" class="headerlink" title="Deploy new aws ec2 instances using ansible playbook"></a>Deploy new aws ec2 instances using ansible playbook</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat ec2_create.yaml</span><br><span class="line">---</span><br><span class="line">- hosts: localhost</span><br><span class="line">  tasks:</span><br><span class="line">    - name: Create AWS instances</span><br><span class="line">      ec2:</span><br><span class="line">        key_name: ansible-key</span><br><span class="line">        instance_type: t2.micro</span><br><span class="line">        image: ami-001dae151248753a2</span><br><span class="line">        count: 3</span><br><span class="line">        vpc_subnet_id: subnet-20615347</span><br><span class="line">        assign_public_ip: no</span><br><span class="line">        region: ap-southeast-2</span><br><span class="line"></span><br><span class="line">ansible-playbook -i &quot;localhost,&quot; -c local ec2_create.yaml</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Ansible-configuration&quot;&gt;&lt;a href=&quot;#Ansible-configuration&quot; class=&quot;headerlink&quot; title=&quot;Ansible configuration&quot;&gt;&lt;/a&gt;Ansible configuration&lt;/
      
    
    </summary>
    
    
      <category term="ansbile" scheme="http://223.95.78.227/tags/ansbile/"/>
    
  </entry>
  
  <entry>
    <title>practical jenkins</title>
    <link href="http://223.95.78.227/2019/06/24/practical-jenkins/"/>
    <id>http://223.95.78.227/2019/06/24/practical-jenkins/</id>
    <published>2019-06-24T13:57:33.000Z</published>
    <updated>2019-07-16T07:02:23.721Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Practical-Jenkins-for-Production-Deployments"><a href="#Practical-Jenkins-for-Production-Deployments" class="headerlink" title="Practical Jenkins for Production Deployments"></a>Practical Jenkins for Production Deployments</h1><ul><li>Installation, configuration, and automation of Jenkins and its dependencies</li><li>Attention to high-availability, monitoring, management, and security</li><li>Utilizing distributed architectures and ability to work with diverse infrastructure platforms</li><li>Understanding and implementing pipeline as code with special attention to multi-branch pipeline</li><li>Being able to deploy code continously</li><li>Integration with extenal services for optimal workflow desgin</li></ul><h1 id="The-Development-Stages"><a href="#The-Development-Stages" class="headerlink" title="The Development Stages"></a>The Development Stages</h1><ul><li>Feature branch forked from devlop branch</li><li>Code added/modified and then build/test is executed against it</li><li>On success, the node is merged to the develop branch</li><li>More builds/tests are executed against the develop branch including integration tests</li><li>On success, the code is merged to the master branch</li><li>A tag is created and (optionally) a package is prepared for deployment</li><li>Next setps:<ul><li>The package is deployed to target systems by Jenkins</li><li>Jenkins triggers an event in another deployment tool</li><li>Acceptance testing is performed on the target systems (optional)</li></ul></li></ul><h1 id="What-is-Continuous-Integration"><a href="#What-is-Continuous-Integration" class="headerlink" title="What is Continuous Integration?"></a>What is Continuous Integration?</h1><ul><li>It is a development practice</li><li>A new feature is added by forking an integration branch</li><li>The new feature branch is tested before merging the code to the integration branch</li><li>Errors and problems are detected early</li><li>Testing and merging happens automatically without manual intervention</li><li>New code is added, modified, and merged regularly to the integration branch</li></ul><h1 id="What-is-Continous-Delivery"><a href="#What-is-Continous-Delivery" class="headerlink" title="What is Continous Delivery?"></a>What is Continous Delivery?</h1><ul><li>It is the practice of getting code into a deployable state</li><li>This is achieved irrespective of the size of the application or number of developers making commits</li><li>Includes new features, changes, bug fixes, etc</li><li>Makes sure that all changes are ready to be deployed at any time</li><li>Makes releases low risk and of higher quality</li><li>Depends on Continous Integration</li></ul><h1 id="What-is-Continous-Deployment"><a href="#What-is-Continous-Deployment" class="headerlink" title="What is Continous Deployment?"></a>What is Continous Deployment?</h1><ul><li>It is the process of automatic releases to production</li><li>It is the next step to Continous Delivery</li><li>The level of testing decides how good the release will be </li><li>Release happends in small batches and continuously</li><li>Gradual product improvement and increase in quality</li><li>The processes of Continous Integration and Continuous Delivery need to be perfect to ensure that releases are without issues</li><li>Relieves developers and administrators from the periodic taks of releasing</li></ul><h1 id="Setting-up-git-code-repositories-and-dependencies-for-Jenkins"><a href="#Setting-up-git-code-repositories-and-dependencies-for-Jenkins" class="headerlink" title="Setting up git, code repositories, and dependencies for Jenkins"></a>Setting up git, code repositories, and dependencies for Jenkins</h1><h2 id="Storage-for-Jenkins-Data"><a href="#Storage-for-Jenkins-Data" class="headerlink" title="Storage for Jenkins Data"></a>Storage for Jenkins Data</h2><ul><li>Setting up a dedicated storage</li><li>Run on physical hardware-rate configuration with multiple disks</li><li>Run on virtualized cloud platform-dedicated elastic volumes</li><li>Home directory - /var/lib/jenkins</li></ul><p>Create a new volume in aws ec2 Elastic Block Store, attach volume to ec2 jenkins master instance, run following commmands:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fdisk -l</span><br><span class="line">mkfs.ext4 /dev/xvdf</span><br><span class="line">mkdir -p /var/lib/jenkins</span><br><span class="line">vim /etc/fstab</span><br><span class="line">/dev/xvdf /var/lib/jenkins ext4 defaults 0 0</span><br><span class="line">mount /var/lib/jenkins</span><br><span class="line">df -h</span><br><span class="line">yum -y install java-1.8.0-openjdk</span><br></pre></td></tr></table></figure></p><h2 id="Installation-of-Jenkins-from-Packages-and-WAR-Files"><a href="#Installation-of-Jenkins-from-Packages-and-WAR-Files" class="headerlink" title="Installation of Jenkins from Packages and WAR Files"></a>Installation of Jenkins from Packages and WAR Files</h2><ol><li>from Packages<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum -y install java-1.8.0-openjdk</span><br><span class="line">wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo</span><br><span class="line">rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key</span><br><span class="line">yum install -y jenkins</span><br><span class="line">systemctl start jenkins</span><br></pre></td></tr></table></figure></li></ol><p>If want to change the jenkins’ home directory vim /etc/sysconfig/jenkins<br>JENKINS_HOME=</p><ol start="2"><li><p>from WAR files</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yum intall -y tomcat</span><br><span class="line">cd /usr/share/tomcat.webapps/</span><br><span class="line">wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war</span><br><span class="line">systemctl start tomcat</span><br><span class="line">access by ipaddress:8080/jenkins</span><br><span class="line">systemctl stop tomcat</span><br><span class="line">mkdir -p /opt/jenkins_home</span><br><span class="line">chown -R tomcat:tomcat /opt/jenkins_home</span><br><span class="line">vim /etc/tomcat/contxt.xml</span><br><span class="line"># At the end of file add a new line</span><br><span class="line">&lt;Environment name=&quot;JENKINS_HOME&quot; vaule=&quot;/opt/jenkins_home&quot; type=&quot;java.lang.String&quot; /&gt;</span><br><span class="line">systemctl start tomcat</span><br></pre></td></tr></table></figure></li><li><p>use docker containers</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">yum install -y docker-ce</span><br><span class="line">systemctl start docker</span><br><span class="line">docker pull jenkins/jenkins:lts</span><br><span class="line">docker run --name jenkins_master -d -p 8080:8080 -v jenkins_home:/var/jenkins_home jenkins/jenkins:lts</span><br></pre></td></tr></table></figure></li></ol><h2 id="Configuring-reverse-proxy-and-setting-up-user-interface-for-jenkins"><a href="#Configuring-reverse-proxy-and-setting-up-user-interface-for-jenkins" class="headerlink" title="Configuring reverse proxy and setting up user interface for jenkins"></a>Configuring reverse proxy and setting up user interface for jenkins</h2><p>Install nginx:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">rpm -ihv https://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-7-11.noarch.rpm</span><br><span class="line">yum install -y nginx</span><br><span class="line">vim /etc/nginx/nginx.conf delete server &#123; part &#125;</span><br><span class="line">vim /etc/nginx/conf.d/jenkins.conf </span><br><span class="line">upstream jenkins &#123;</span><br><span class="line">    server 127.0.0.1:8080;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen      80 default;</span><br><span class="line">    server_name jenkins.course;</span><br><span class="line"></span><br><span class="line">    access_log  /var/log/nginx/jenkins.access.log;</span><br><span class="line">    error_log   /var/log/nginx/jenkins.error.log;</span><br><span class="line"></span><br><span class="line">    proxy_buffers 16 64k;</span><br><span class="line">    proxy_buffer_size 128k;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass  http://jenkins;</span><br><span class="line">        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;</span><br><span class="line">        proxy_redirect off;</span><br><span class="line"></span><br><span class="line">        proxy_set_header    Host            $host;</span><br><span class="line">        proxy_set_header    X-Real-IP       $remote_addr;</span><br><span class="line">        proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">        proxy_set_header    X-Forwarded-Proto $scheme;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>In Jenkins configuration Git plugin put git username and email address<br><img src="https://i.imgur.com/vZuSUgf.png" alt="setupcredentials"></p><h2 id="Automating-the-Jenkins-Installation-and-Configuration-Process"><a href="#Automating-the-Jenkins-Installation-and-Configuration-Process" class="headerlink" title="Automating the Jenkins Installation and Configuration Process"></a>Automating the Jenkins Installation and Configuration Process</h2><ul><li>Disabling the manual setup wizard</li><li>Automating the setup wizard steps</li><li>Creating puppet configuration to automate the installation and configuration process</li><li>Automating the process by applying the puppet module<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop jenkins</span><br><span class="line">vim /etc/system/jenkins</span><br><span class="line">modify JENKINS_JAVA_OPTIONS=&quot;-Djava.awt.headless=true -Djenkins.install.runSetupWizard=false&quot;</span><br><span class="line">mkdir -p /var/lib/jenkins/init/groovy.d</span><br><span class="line">vim /var/lib/jenkins/init/groovy.d/installPlugins.groovy</span><br><span class="line">#!groovy</span><br><span class="line"></span><br><span class="line">import jenkins.model.*</span><br><span class="line">import java.util.logging.Logger</span><br><span class="line"></span><br><span class="line">def logger = Logger.getLogger(&quot;&quot;)</span><br><span class="line">def installed = false</span><br><span class="line">def initialized = false</span><br><span class="line">def pluginParameter = &quot;ws-cleanup timestamper credentials-binding build-timeout antisamy-markup-formatter cloudbees-folder pipeline-stage-view pipeline-github-lib github-branch-source workflow-aggregator gradle ant mailer email-ext ldap pam-auth matrix-auth ssh-slaves github git&quot;</span><br><span class="line"></span><br><span class="line">def plugins = pluginParameter.split()</span><br><span class="line">logger.info(&quot;&quot; + plugins)</span><br><span class="line">def instance = Jenkins.getInstance()</span><br><span class="line">def pm = instance.getPluginManager()</span><br><span class="line">def uc = instance.getUpdateCenter()</span><br><span class="line">plugins.each &#123;</span><br><span class="line">  logger.info(&quot;Checking &quot; + it)</span><br><span class="line">  if (!pm.getPlugin(it)) &#123;</span><br><span class="line">    logger.info(&quot;Looking UpdateCenter for &quot; + it)</span><br><span class="line">    if (!initialized) &#123;</span><br><span class="line">      uc.updateAllSites()</span><br><span class="line">      initialized = true</span><br><span class="line">    &#125;</span><br><span class="line">    def plugin = uc.getPlugin(it)</span><br><span class="line">    if (plugin) &#123;</span><br><span class="line">      logger.info(&quot;Installing &quot; + it)</span><br><span class="line">        def installFuture = plugin.deploy()</span><br><span class="line">      while(!installFuture.isDone()) &#123;</span><br><span class="line">        logger.info(&quot;Waiting for plugin install: &quot; + it)</span><br><span class="line">        sleep(3000)</span><br><span class="line">      &#125;</span><br><span class="line">      installed = true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">if (installed) &#123;</span><br><span class="line">  logger.info(&quot;Plugins installed, initializing a restart!&quot;)</span><br><span class="line">  instance.save()</span><br><span class="line">  instance.restart()</span><br><span class="line">&#125;</span><br><span class="line">vim /var/lib/jenkins/init/groovy.d/security.groovy</span><br><span class="line">#!groovy</span><br><span class="line"></span><br><span class="line">import jenkins.model.*</span><br><span class="line">import hudson.security.*</span><br><span class="line">import jenkins.security.s2m.AdminWhitelistRule</span><br><span class="line">import hudson.security.csrf.DefaultCrumbIssuer</span><br><span class="line">import jenkins.model.Jenkins</span><br><span class="line"></span><br><span class="line">def instance = Jenkins.getInstance()</span><br><span class="line"></span><br><span class="line">def hudsonRealm = new HudsonPrivateSecurityRealm(false)</span><br><span class="line">hudsonRealm.createAccount(&quot;admin&quot;, &quot;admin&quot;)</span><br><span class="line">instance.setSecurityRealm(hudsonRealm)</span><br><span class="line"></span><br><span class="line">def strategy = new FullControlOnceLoggedInAuthorizationStrategy()</span><br><span class="line">strategy.setAllowAnonymousRead(false)</span><br><span class="line">instance.setAuthorizationStrategy(strategy)</span><br><span class="line">instance.save()</span><br><span class="line"></span><br><span class="line">Jenkins.instance.getInjector().getInstance(AdminWhitelistRule.class)</span><br><span class="line"></span><br><span class="line">def j = Jenkins.instance</span><br><span class="line">if(j.getCrumbIssuer() == null) &#123;</span><br><span class="line">    j.setCrumbIssuer(new DefaultCrumbIssuer(true))</span><br><span class="line">    j.save()</span><br><span class="line">    println &apos;CSRF Protection configuration has changed.  Enabled CSRF Protection.&apos;</span><br><span class="line">&#125;</span><br><span class="line">else &#123;</span><br><span class="line">    println &apos;Nothing changed.  CSRF Protection already configured.&apos;</span><br><span class="line">&#125;</span><br><span class="line">chown -R jenkins:jenkins /var/lib/jenkins/init/groovy.d/*.groovy</span><br><span class="line">systemctl start jenkins</span><br><span class="line">tail -f /var/log/jenkins/jenkins.log</span><br></pre></td></tr></table></figure></li></ul><h2 id="install-puppet"><a href="#install-puppet" class="headerlink" title="install puppet"></a>install puppet</h2><p>go to <a href="http://yum.puppetlabs.com/">puppet</a>, copy url link <a href="http://yum.puppetlabs.com/puppetlabs-release-pc1-el-7.noarch.rpm">puppetlabs-release-pc1-el-7.noarch.rpm</a>.<br>on the sever install the package by the command:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -ihv http://yum.puppetlabs.com/puppetlabs-release-pc1-el-7.noarch.rpm</span><br><span class="line"></span><br><span class="line">yum -y install puppet-agent</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br></pre></td><td class="code"><pre><span class="line">mkdir puppet</span><br><span class="line">cd puppet</span><br><span class="line">mkdir &#123;modules, manifests&#125;</span><br><span class="line">mkdir modules/jenkins</span><br><span class="line">mkdir modules/jenkins/&#123;manifests,files&#125;</span><br><span class="line">vim modules/jenkins/manifests.install.pp</span><br><span class="line">class jenkins::install &#123;</span><br><span class="line">    file &#123; &apos;jenkins_repo&apos;:</span><br><span class="line">        path   =&gt; &apos;/etc/yum.repos.d/jenkins.repo&apos;,</span><br><span class="line">        source =&gt; &apos;https://pkg.jenkins.io/redhat-stable/jenkins.repo&apos;,</span><br><span class="line">        ensure =&gt; present,</span><br><span class="line">        mode   =&gt; &apos;0644&apos;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    exec &#123; &apos;jenkins_repo_key&apos;:</span><br><span class="line">        command   =&gt; &apos;/bin/rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key&apos;,</span><br><span class="line">        unless    =&gt; &apos;/bin/rpm -q jenkins&apos;,</span><br><span class="line">        subscribe =&gt; File[&apos;jenkins_repo&apos;],</span><br><span class="line">        require   =&gt; File[&apos;jenkins_repo&apos;]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    package &#123; &apos;epel-repo&apos;:</span><br><span class="line">        name   =&gt; &apos;epel-release&apos;,</span><br><span class="line">        ensure =&gt; present,</span><br><span class="line">        source =&gt; &apos;https://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-7-11.noarch.rpm&apos;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    $packages = [ &apos;jenkins&apos;, &apos;java-1.8.0-openjdk&apos;, &apos;nginx&apos;, &apos;git&apos; ]</span><br><span class="line"></span><br><span class="line">    package &#123; $packages:</span><br><span class="line">        ensure    =&gt; present,</span><br><span class="line">        require   =&gt; [ File[&apos;jenkins_repo&apos;], Package[&apos;epel-repo&apos;] ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vim modules/jenkins/cofig.pp</span><br><span class="line">class jenkins::config &#123;</span><br><span class="line">    file &#123; &apos;groovy_script_directory&apos;:</span><br><span class="line">        path   =&gt; &apos;/var/lib/jenkins/init.groovy.d&apos;,</span><br><span class="line">        owner  =&gt; &apos;jenkins&apos;,</span><br><span class="line">        group  =&gt; &apos;jenkins&apos;,</span><br><span class="line">        mode   =&gt; &apos;0755&apos;,</span><br><span class="line">        ensure =&gt; directory</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    file &#123; &apos;security_groovy_script&apos;:</span><br><span class="line">        path    =&gt; &apos;/var/lib/jenkins/init.groovy.d/security.groovy&apos;,</span><br><span class="line">        owner   =&gt; &apos;jenkins&apos;,</span><br><span class="line">        group   =&gt; &apos;jenkins&apos;,</span><br><span class="line">        source  =&gt; &apos;puppet:///modules/jenkins/security.groovy&apos;,</span><br><span class="line">        mode    =&gt; &apos;0644&apos;,</span><br><span class="line">        require =&gt; File[&apos;groovy_script_directory&apos;]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    file &#123; &apos;plugins_groovy_script&apos;:</span><br><span class="line">        path    =&gt; &apos;/var/lib/jenkins/init.groovy.d/installPlugins.groovy&apos;,</span><br><span class="line">        owner   =&gt; &apos;jenkins&apos;,</span><br><span class="line">        group   =&gt; &apos;jenkins&apos;,</span><br><span class="line">        source  =&gt; &apos;puppet:///modules/jenkins/installPlugins.groovy&apos;,</span><br><span class="line">        mode    =&gt; &apos;0644&apos;,</span><br><span class="line">        require =&gt; File[&apos;groovy_script_directory&apos;]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    file &#123; &apos;nginx_config_jenkins&apos;:</span><br><span class="line">        path   =&gt; &apos;/etc/nginx/conf.d/jenkins.conf&apos;,</span><br><span class="line">        owner  =&gt; &apos;root&apos;,</span><br><span class="line">        group  =&gt; &apos;root&apos;,</span><br><span class="line">        source =&gt; &apos;puppet:///modules/jenkins/jenkins.conf&apos;,</span><br><span class="line">        mode   =&gt; &apos;0644&apos;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    file &#123; &apos;nginx_config&apos;:</span><br><span class="line">        path   =&gt; &apos;/etc/nginx/nginx.conf&apos;,</span><br><span class="line">        owner  =&gt; &apos;root&apos;,</span><br><span class="line">        group  =&gt; &apos;root&apos;,</span><br><span class="line">        source =&gt; &apos;puppet:///modules/jenkins/nginx.conf&apos;,</span><br><span class="line">        mode   =&gt; &apos;0644&apos;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    file &#123; &apos;jenkins_sysconfig&apos;:</span><br><span class="line">        path   =&gt; &apos;/etc/sysconfig/jenkins&apos;,</span><br><span class="line">        owner  =&gt; &apos;root&apos;,</span><br><span class="line">        group  =&gt; &apos;root&apos;,</span><br><span class="line">        source =&gt; &apos;puppet:///modules/jenkins/jenkins&apos;,</span><br><span class="line">        mode   =&gt; &apos;0644&apos;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vim modules/jenkins/service.pp</span><br><span class="line">class jenkins::service &#123;</span><br><span class="line">    service &#123; &apos;jenkins&apos;:</span><br><span class="line">        ensure =&gt; running</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    service &#123; &apos;nginx&apos;:</span><br><span class="line">        ensure =&gt; running</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vim modules/jenkins/init.pp</span><br><span class="line">class jenkins &#123;</span><br><span class="line">    include jenkins::install</span><br><span class="line">    include jenkins::config</span><br><span class="line">    include jenkins::service</span><br><span class="line"></span><br><span class="line">    Class[&apos;jenkins::install&apos;] -&gt; Class[&apos;jenkins::config&apos;] ~&gt; Class[&apos;jenkins::service&apos;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vim modules/jenkins/files/installPlugins.groovy</span><br><span class="line">#!groovy</span><br><span class="line"></span><br><span class="line">import jenkins.model.*</span><br><span class="line">import java.util.logging.Logger</span><br><span class="line"></span><br><span class="line">def logger = Logger.getLogger(&quot;&quot;)</span><br><span class="line">def installed = false</span><br><span class="line">def initialized = false</span><br><span class="line">def pluginParameter = &quot;ws-cleanup timestamper credentials-binding build-timeout antisamy-markup-formatter cloudbees-folder pipeline-stage-view pipeline-github-lib github-branch-source workflow-aggregator gradle ant mailer email-ext ldap pam-auth matrix-auth ssh-slaves github git&quot;</span><br><span class="line"></span><br><span class="line">def plugins = pluginParameter.split()</span><br><span class="line">logger.info(&quot;&quot; + plugins)</span><br><span class="line">def instance = Jenkins.getInstance()</span><br><span class="line">def pm = instance.getPluginManager()</span><br><span class="line">def uc = instance.getUpdateCenter()</span><br><span class="line">plugins.each &#123;</span><br><span class="line">  logger.info(&quot;Checking &quot; + it)</span><br><span class="line">  if (!pm.getPlugin(it)) &#123;</span><br><span class="line">    logger.info(&quot;Looking UpdateCenter for &quot; + it)</span><br><span class="line">    if (!initialized) &#123;</span><br><span class="line">      uc.updateAllSites()</span><br><span class="line">      initialized = true</span><br><span class="line">    &#125;</span><br><span class="line">    def plugin = uc.getPlugin(it)</span><br><span class="line">    if (plugin) &#123;</span><br><span class="line">      logger.info(&quot;Installing &quot; + it)</span><br><span class="line">        def installFuture = plugin.deploy()</span><br><span class="line">      while(!installFuture.isDone()) &#123;</span><br><span class="line">        logger.info(&quot;Waiting for plugin install: &quot; + it)</span><br><span class="line">        sleep(3000)</span><br><span class="line">      &#125;</span><br><span class="line">      installed = true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">if (installed) &#123;</span><br><span class="line">  logger.info(&quot;Plugins installed, initializing a restart!&quot;)</span><br><span class="line">  instance.save()</span><br><span class="line">  instance.restart()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vim modules/jenkins/files/jenkins.conf</span><br><span class="line">upstream jenkins &#123;</span><br><span class="line">    server 127.0.0.1:8080;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen      80 default;</span><br><span class="line">    server_name jenkins.course;</span><br><span class="line"></span><br><span class="line">    access_log  /var/log/nginx/jenkins.access.log;</span><br><span class="line">    error_log   /var/log/nginx/jenkins.error.log;</span><br><span class="line"></span><br><span class="line">    proxy_buffers 16 64k;</span><br><span class="line">    proxy_buffer_size 128k;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass  http://jenkins;</span><br><span class="line">        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;</span><br><span class="line">        proxy_redirect off;</span><br><span class="line"></span><br><span class="line">        proxy_set_header    Host            $host;</span><br><span class="line">        proxy_set_header    X-Real-IP       $remote_addr;</span><br><span class="line">        proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">        proxy_set_header    X-Forwarded-Proto $scheme;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vim modules/jenkins/files/nginx.conf</span><br><span class="line"># For more information on configuration, see:</span><br><span class="line">#   * Official English Documentation: http://nginx.org/en/docs/</span><br><span class="line">#   * Official Russian Documentation: http://nginx.org/ru/docs/</span><br><span class="line"></span><br><span class="line">user nginx;</span><br><span class="line">worker_processes auto;</span><br><span class="line">error_log /var/log/nginx/error.log;</span><br><span class="line">pid /run/nginx.pid;</span><br><span class="line"></span><br><span class="line"># Load dynamic modules. See /usr/share/nginx/README.dynamic.</span><br><span class="line">include /usr/share/nginx/modules/*.conf;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">                      &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class="line"></span><br><span class="line">    access_log  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile            on;</span><br><span class="line">    tcp_nopush          on;</span><br><span class="line">    tcp_nodelay         on;</span><br><span class="line">    keepalive_timeout   65;</span><br><span class="line">    types_hash_max_size 2048;</span><br><span class="line"></span><br><span class="line">    include             /etc/nginx/mime.types;</span><br><span class="line">    default_type        application/octet-stream;</span><br><span class="line"></span><br><span class="line">    # Load modular configuration files from the /etc/nginx/conf.d directory.</span><br><span class="line">    # See http://nginx.org/en/docs/ngx_core_module.html#include</span><br><span class="line">    # for more information.</span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vim modules/jenkins/files/security.groovy</span><br><span class="line">#!groovy</span><br><span class="line"></span><br><span class="line">import jenkins.model.*</span><br><span class="line">import hudson.security.*</span><br><span class="line">import jenkins.security.s2m.AdminWhitelistRule</span><br><span class="line">import hudson.security.csrf.DefaultCrumbIssuer</span><br><span class="line">import jenkins.model.Jenkins</span><br><span class="line"></span><br><span class="line">def instance = Jenkins.getInstance()</span><br><span class="line"></span><br><span class="line">def hudsonRealm = new HudsonPrivateSecurityRealm(false)</span><br><span class="line">hudsonRealm.createAccount(&quot;admin&quot;, &quot;admin&quot;)</span><br><span class="line">instance.setSecurityRealm(hudsonRealm)</span><br><span class="line"></span><br><span class="line">def strategy = new FullControlOnceLoggedInAuthorizationStrategy()</span><br><span class="line">strategy.setAllowAnonymousRead(false)</span><br><span class="line">instance.setAuthorizationStrategy(strategy)</span><br><span class="line">instance.save()</span><br><span class="line"></span><br><span class="line">Jenkins.instance.getInjector().getInstance(AdminWhitelistRule.class)</span><br><span class="line"></span><br><span class="line">def j = Jenkins.instance</span><br><span class="line">if(j.getCrumbIssuer() == null) &#123;</span><br><span class="line">    j.setCrumbIssuer(new DefaultCrumbIssuer(true))</span><br><span class="line">    j.save()</span><br><span class="line">    println &apos;CSRF Protection configuration has changed.  Enabled CSRF Protection.&apos;</span><br><span class="line">&#125;</span><br><span class="line">else &#123;</span><br><span class="line">    println &apos;Nothing changed.  CSRF Protection already configured.&apos;</span><br><span class="line">&#125;</span><br><span class="line">[root@ip-172-31-2-108 ~]# tree puppet/</span><br><span class="line">puppet/</span><br><span class="line">├── manifests</span><br><span class="line">│   └── site.pp</span><br><span class="line">└── modules</span><br><span class="line">    └── jenkins</span><br><span class="line">        ├── files</span><br><span class="line">        │   ├── installPlugins.groovy</span><br><span class="line">        │   ├── jenkins</span><br><span class="line">        │   ├── jenkins.conf</span><br><span class="line">        │   ├── nginx.conf</span><br><span class="line">        │   └── security.groovy</span><br><span class="line">        └── manifests</span><br><span class="line">            ├── config.pp</span><br><span class="line">            ├── init.pp</span><br><span class="line">            ├── install.pp</span><br><span class="line">            └── service.pp</span><br><span class="line">cd puppet</span><br><span class="line">puppet apply --modulepath ./modules manifests/site.pp</span><br></pre></td></tr></table></figure><h2 id="Creating-build-jobs-from-user-interface-and-scripts"><a href="#Creating-build-jobs-from-user-interface-and-scripts" class="headerlink" title="Creating build jobs from user interface and scripts"></a>Creating build jobs from user interface and scripts</h2><p>1.Create a new freestyle jenkins job called python-job, configure ‘Source Code Management”-&gt;’Git’-&gt; Repo URL <a href="mailto:git@github.com">git@github.com</a>:szhouchoice/python-project.git.<br>“Build” -&gt; Execute shell, command <code>python *test.py</code></p><p>2.<code>mkdir jenkins_cmd; cd jenkins_cmd</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cp /var/lib/jenkins/jobs/python-job/config.xml .</span><br><span class="line">vim config.xml</span><br><span class="line">&lt;publishers&gt;</span><br><span class="line">    &lt;hudson.plugins.ws__cleanup.WsCleanup plugin=&quot;ws-cleanup@0.34&quot;&gt;</span><br><span class="line">      &lt;patterns class=&quot;empty-list&quot;/&gt;</span><br><span class="line">      &lt;deleteDirs&gt;true&lt;/deleteDirs&gt;</span><br><span class="line">      &lt;skipWhenFailed&gt;false&lt;/skipWhenFailed&gt;</span><br><span class="line">      &lt;cleanWhenSuccess&gt;true&lt;/cleanWhenSuccess&gt;</span><br><span class="line">      &lt;cleanWhenUnstable&gt;true&lt;/cleanWhenUnstable&gt;</span><br><span class="line">      &lt;cleanWhenFailure&gt;true&lt;/cleanWhenFailure&gt;</span><br><span class="line">      &lt;cleanWhenNotBuilt&gt;true&lt;/cleanWhenNotBuilt&gt;</span><br><span class="line">      &lt;cleanWhenAborted&gt;true&lt;/cleanWhenAborted&gt;</span><br><span class="line">      &lt;notFailBuild&gt;false&lt;/notFailBuild&gt;</span><br><span class="line">      &lt;cleanupMatrixParent&gt;false&lt;/cleanupMatrixParent&gt;</span><br><span class="line">      &lt;externalDelete&gt;&lt;/externalDelete&gt;</span><br><span class="line">    &lt;/hudson.plugins.ws__cleanup.WsCleanup&gt;</span><br><span class="line">curl -s &apos;http://localhost:8080/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,&quot;:&quot;,//crumb)&apos; -u admin:admin</span><br><span class="line"></span><br><span class="line">curl -s -XPOST &apos;http://localhost:8080/createItem?name=python-project-new&apos; -u admin:admin --data-binary @config.xml -H &quot;Jenkins-Crumb:384576fea44a8984fd1afe2474c8e951&quot; -H &quot;Content-Type:text/xml&quot;</span><br></pre></td></tr></table></figure></p><h1 id="High-availability-monitoring-and-management-of-jenkins-deployments"><a href="#High-availability-monitoring-and-management-of-jenkins-deployments" class="headerlink" title="High-availability, monitoring, and management of jenkins deployments"></a>High-availability, monitoring, and management of jenkins deployments</h1><ul><li>High-availability scenario of Jenkins ecosystem and support</li><li>Creating multiple Jenkins master nodes with shared data directory</li><li>Configuring HAProxy as a load balancer for the Jenkins masters</li><li>Testing the setup by failing nodes</li></ul><h2 id="Setting-up-multiple-Jenkins-Master-with-Load-Balancer-for-high-availability"><a href="#Setting-up-multiple-Jenkins-Master-with-Load-Balancer-for-high-availability" class="headerlink" title="Setting up multiple Jenkins Master with Load Balancer for high-availability"></a>Setting up multiple Jenkins Master with Load Balancer for high-availability</h2><p><img src="https://i.imgur.com/YnYwCzR.png" alt="High-Availability Setup"></p><h3 id="1-On-aws-ec2-create-3-instances-with-Centos-7-OS-1-for-haproxy-2-for-jenkins"><a href="#1-On-aws-ec2-create-3-instances-with-Centos-7-OS-1-for-haproxy-2-for-jenkins" class="headerlink" title="1. On aws ec2 create 3 instances with Centos 7 OS. 1 for haproxy 2 for jenkins"></a>1. On aws ec2 create 3 instances with Centos 7 OS. 1 for haproxy 2 for jenkins</h3><h3 id="2-Create-a-efs-on-aws-setup-up-efs-on-two-jenkins-ec2-instances-efs-security-group-need-create-a-new-one-open-nfs-port-to-everywhere"><a href="#2-Create-a-efs-on-aws-setup-up-efs-on-two-jenkins-ec2-instances-efs-security-group-need-create-a-new-one-open-nfs-port-to-everywhere" class="headerlink" title="2. Create a efs on aws, setup up efs on two jenkins ec2 instances. efs security group need create a new one open nfs port to everywhere"></a>2. Create a efs on aws, setup up efs on two jenkins ec2 instances. efs security group need create a new one open nfs port to everywhere</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">yum -y install nfs-utils</span><br><span class="line">vim /etc/fstab</span><br><span class="line">ap-southeast-2a.fs-foobar.efs.ap-southeast-2.amazonaws.com:/ /var/lib/jenkins/jobs nfs defaults 0 0</span><br><span class="line">systemctl stop jenkins</span><br><span class="line">mount /var/lib/jenkins/jobs</span><br><span class="line">df -h</span><br><span class="line">chown -R jenkins:jenkins /var/lib/jenkins/jobs</span><br><span class="line">ls -l /var/lib/jenkins/</span><br><span class="line">systemctl start jenkins</span><br></pre></td></tr></table></figure><h3 id="3-On-Jenkins-master-passive-node"><a href="#3-On-Jenkins-master-passive-node" class="headerlink" title="3. On Jenkins master passive node"></a>3. On Jenkins master passive node</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/jenkins_reload.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">crumb_id=$(curl -s &apos;http://localhost:8080/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,&quot;:&quot;,//crumb)&apos; -u admin:admin)</span><br><span class="line">curl -s -XPOST &apos;http://localhost:8080/reload&apos; -u admin:admin -H &quot;$crumb_id&quot;</span><br><span class="line">chmod +x /opt/jenkins_reload.sh</span><br><span class="line">vim /etc/cron.d/jenkins_reload.sh</span><br><span class="line">*/1 * * * * root /bin/bash /opt/jenkins_reload.sh #run every min</span><br></pre></td></tr></table></figure><h3 id="4-On-HA-Proxy-server"><a href="#4-On-HA-Proxy-server" class="headerlink" title="4. On HA Proxy server"></a>4. On HA Proxy server</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">yum -y install haproxy</span><br><span class="line">cat /dev/null&gt; /etc/haproxy/haproxy.cfg</span><br><span class="line">vim /etc/haproxy/haproxy.cfg</span><br><span class="line">defaults</span><br><span class="line">  log  global</span><br><span class="line">  maxconn  2000</span><br><span class="line">  mode  http</span><br><span class="line">  option  redispatch</span><br><span class="line">  option  forwardfor</span><br><span class="line">  option  http-server-close</span><br><span class="line">  retries  3</span><br><span class="line">  timeout  http-request 10s</span><br><span class="line">  timeout  queue 1m</span><br><span class="line">  timeout  connect 10s</span><br><span class="line">  timeout  client 1m</span><br><span class="line">  timeout  server 1m</span><br><span class="line">  timeout  check 10s</span><br><span class="line"></span><br><span class="line">frontend ft_jenkins</span><br><span class="line">  bind *:80</span><br><span class="line">  default_backend  bk_jenkins</span><br><span class="line">  reqadd  X-Forwarded-Proto:\ http</span><br><span class="line"></span><br><span class="line">backend bk_jenkins</span><br><span class="line"> server jenkins1 172.31.2.108:8080 check</span><br><span class="line"> server jenkins2 172.31.2.132:8080 check backup</span><br><span class="line"></span><br><span class="line">systemctl start haproxy</span><br><span class="line">ps-ef|grep haproxy</span><br></pre></td></tr></table></figure><h2 id="Backing-up-and-restoring-Jenkins-data"><a href="#Backing-up-and-restoring-Jenkins-data" class="headerlink" title="Backing up and restoring Jenkins data"></a>Backing up and restoring Jenkins data</h2><h3 id="Steps-of-backup-and-resotre"><a href="#Steps-of-backup-and-resotre" class="headerlink" title="Steps of backup and resotre"></a>Steps of backup and resotre</h3><ul><li>Decide on what to back up (specific directories or everything)</li><li>Set up a dedicated local directory where backups would be stored</li><li>Decide the archiving method to use for the backup (.zip, tar.gz, and so on)</li><li>Set up a schedule for backups to take place</li><li>Configure a highly-available remove location where old backups can be transferred for archiving</li><li>Keep a certain number of the most recent backups to be readily available for restores</li><li>When restoring, unarchive the most recent backup and copy over files<h3 id="Backup-and-Restore-Methods"><a href="#Backup-and-Restore-Methods" class="headerlink" title="Backup and Restore Methods"></a>Backup and Restore Methods</h3></li><li>Use periodic Backup plugin available in Jenkins</li><li>Manually copy and archive files using scripts</li><li>Select a remote location for storing data such as S3, EFS, and so on</li><li>Use local tools such as scp, rsync, s3cmd, and son on to transfer data</li><li>Use specialized open source tools such as Amanda or Bacula to perform backups or enterprise tools such as Netbackup</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/jenkins_backups</span><br><span class="line">chown -R jenkins:jenkins /opt/jenkins_backups/</span><br></pre></td></tr></table></figure><p>Install plugin called Periodic Backup Manager, configure it as following:<br><img src="https://i.imgur.com/fvgXK7C.png" alt="periodicbackupconf"></p><p>click button Backup Now!</p><h2 id="Monitoring-Jenkins-components-and-data"><a href="#Monitoring-Jenkins-components-and-data" class="headerlink" title="Monitoring Jenkins components and data"></a>Monitoring Jenkins components and data</h2><h3 id="Install-plugin-monitoring-after-that-under-‘Manage-Jenkins’-will-have-Monitoring-of-Jenkins-master"><a href="#Install-plugin-monitoring-after-that-under-‘Manage-Jenkins’-will-have-Monitoring-of-Jenkins-master" class="headerlink" title="Install plugin monitoring, after that under ‘Manage Jenkins’ will have Monitoring of Jenkins master:"></a>Install plugin monitoring, after that under ‘Manage Jenkins’ will have Monitoring of Jenkins master:</h3><p><img src="https://i.imgur.com/88b0cnX.png" alt="Monitoring"></p><h3 id="install-configure-graphite-grafana"><a href="#install-configure-graphite-grafana" class="headerlink" title="install configure graphite grafana"></a>install configure graphite grafana</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">#Install EPEL repo</span><br><span class="line">rpm -ihv https://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-7-11.noarch.rpm</span><br><span class="line"></span><br><span class="line">#Install Graphite and dependencies</span><br><span class="line">yum -y install graphite-web mysql mariadb-server MySQL-python net-tools mlocate wget python-carbon python-pip gcc python-devel libffi python-cffi cairo cairo-devel fontconfig freetype*</span><br><span class="line"></span><br><span class="line">#Start database server</span><br><span class="line">systemctl start mariadb</span><br><span class="line"></span><br><span class="line">#Configure database and perms</span><br><span class="line">mysql -e &quot;CREATE DATABASE graphite;&quot;</span><br><span class="line">mysql -e &quot;GRANT ALL PRIVILEGES ON graphite.* TO &apos;graphite&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;j3nk1nsdb&apos;;&quot;</span><br><span class="line">mysql -e &apos;FLUSH PRIVILEGES;&apos;</span><br><span class="line"></span><br><span class="line">#Edit file</span><br><span class="line">vi /etc/graphite-web/local_settings.py</span><br><span class="line"></span><br><span class="line">#Add content</span><br><span class="line">DATABASES = &#123;</span><br><span class="line">    &apos;default&apos;: &#123;</span><br><span class="line">        &apos;NAME&apos;: &apos;graphite&apos;,</span><br><span class="line">        &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;,</span><br><span class="line">        &apos;USER&apos;: &apos;graphite&apos;,</span><br><span class="line">        &apos;PASSWORD&apos;: &apos;j3nk1nsdb&apos;,</span><br><span class="line">        &apos;HOST&apos;: &apos;localhost&apos;,</span><br><span class="line">        &apos;PORT&apos;: &apos;3306&apos;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#Change perms</span><br><span class="line">chown -R apache:apache /var/lib/graphite-web /usr/share/graphite/</span><br><span class="line"></span><br><span class="line">#Edit file</span><br><span class="line">vi /etc/httpd/conf.d/graphite-web.conf</span><br><span class="line"></span><br><span class="line">#Add content</span><br><span class="line"></span><br><span class="line">&lt;VirtualHost *:80&gt;</span><br><span class="line">    ServerName graphite-web</span><br><span class="line">    DocumentRoot &quot;/usr/share/graphite/webapp&quot;</span><br><span class="line">    ErrorLog /var/log/httpd/graphite-web-error.log</span><br><span class="line">    CustomLog /var/log/httpd/graphite-web-access.log common</span><br><span class="line"></span><br><span class="line">    # Header set Access-Control-Allow-Origin &quot;*&quot;</span><br><span class="line">    # Header set Access-Control-Allow-Methods &quot;GET, OPTIONS&quot;</span><br><span class="line">    # Header set Access-Control-Allow-Headers &quot;origin, authorization, accept&quot;</span><br><span class="line">    # Header set Access-Control-Allow-Credentials true</span><br><span class="line"></span><br><span class="line">    WSGIScriptAlias / /usr/share/graphite/graphite-web.wsgi</span><br><span class="line">    WSGIImportScript /usr/share/graphite/graphite-web.wsgi process-group=%&#123;GLOBAL&#125; application-group=%&#123;GLOBAL&#125;</span><br><span class="line"></span><br><span class="line">    &lt;Location &quot;/content/&quot;&gt;</span><br><span class="line">        SetHandler None</span><br><span class="line">    &lt;/Location&gt;</span><br><span class="line"></span><br><span class="line">    Alias /media/ &quot;/usr/lib/python2.7/site-packages/django/contrib/admin/media/&quot;</span><br><span class="line">    &lt;Location &quot;/media/&quot;&gt;</span><br><span class="line">        SetHandler None</span><br><span class="line">    &lt;/Location&gt;</span><br><span class="line"></span><br><span class="line">   &lt;Directory &quot;/usr/share/graphite/&quot;&gt;</span><br><span class="line">    Require all granted</span><br><span class="line">    Order allow,deny</span><br><span class="line">    Allow from all</span><br><span class="line">   &lt;/Directory&gt;</span><br><span class="line">&lt;/VirtualHost&gt;</span><br><span class="line"></span><br><span class="line">#Edit file</span><br><span class="line">vi /etc/graphite-web/local_settings.py</span><br><span class="line"></span><br><span class="line">#Add content</span><br><span class="line">SECRET_KEY = &apos;jenkinsapp&apos;</span><br><span class="line"></span><br><span class="line">#Run command</span><br><span class="line">/usr/lib/python2.7/site-packages/graphite/manage.py syncdb</span><br><span class="line"># user admin password admin</span><br><span class="line"></span><br><span class="line">#Edit file</span><br><span class="line">vi /etc/yum.repos.d/grafana.repo</span><br><span class="line"></span><br><span class="line">#Add content</span><br><span class="line">[grafana]</span><br><span class="line">name=grafana</span><br><span class="line">baseurl=https://packagecloud.io/grafana/stable/el/6/$basearch</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://packagecloud.io/gpg.key https://grafanarel.s3.amazonaws.com/RPM-GPG-KEY-grafana</span><br><span class="line">sslverify=1</span><br><span class="line">sslcacert=/etc/pki/tls/certs/ca-bundle.crt</span><br><span class="line"></span><br><span class="line">#Install grafana</span><br><span class="line">yum -y install grafana</span><br><span class="line"></span><br><span class="line">#Start services</span><br><span class="line">systemctl start carbon-cache</span><br><span class="line">systemctl start httpd</span><br><span class="line">systemctl start grafana-server</span><br></pre></td></tr></table></figure><p>1.Install jenkins plugin call ‘Metrics Graphite Reporting’<br>2.Go to Manage Jenkins -&gt; Configure Sytem-&gt; Graphite metrics report input Hostname ipaddress Port 2003 Prefix jenkins.<br>3.Access grafana server ipaddress:3000 -&gt; Add Graphite -&gt; http settings url <a href="http://localhost">http://localhost</a><br>4.Import grafana dashboard: go to grafana.com/dashboards search for Jenkins: Performance and health overview-&gt; copy id<br>5.<img src="https://i.imgur.com/jeagEZ9.png" alt="import dashboard"> Options grahite choose jenkins-test</p><h3 id="Install-monit"><a href="#Install-monit" class="headerlink" title="Install monit"></a>Install monit</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">yum install -y monit</span><br><span class="line">vim /etc/monitrc</span><br><span class="line">set mailserver smtp.gmail.com port 587</span><br><span class="line">    username &quot;EMAIL&quot; password &quot;PASSWORD&quot;</span><br><span class="line">    using tlsv12</span><br><span class="line">vim /etc/monit.d/jenkins</span><br><span class="line">check system $HOST</span><br><span class="line">    if loadavg (5min) &gt; 3 then alert</span><br><span class="line">    if loadavg (15min) &gt; 1 then alert</span><br><span class="line">    if memory usage &gt; 80% for 4 cycles then alert</span><br><span class="line">    if swap usage &gt; 20% for 4 cycles then alert</span><br><span class="line">    if cpu usage (user) &gt; 80% for 2 cycles then alert</span><br><span class="line">    if cpu usage (system) &gt; 20% for 2 cycles then alert</span><br><span class="line">    if cpu usage (wait) &gt; 80% for 2 cycles then alert</span><br><span class="line">    if cpu usage &gt; 200% for 4 cycles then alert</span><br><span class="line"></span><br><span class="line">check process jenkins with pidfile /var/run/jenkins.pid</span><br><span class="line">    start program = &quot;/bin/systemctl start jenkins&quot;</span><br><span class="line">    stop program  = &quot;/bin/systemctl stop jenkins&quot;</span><br><span class="line">    if failed host 192.168.33.200 port 8080 then restart</span><br><span class="line"></span><br><span class="line">check process nginx with pidfile /var/run/nginx.pid</span><br><span class="line">    start program = &quot;/bin/systemctl start nginx&quot;</span><br><span class="line">    stop program  = &quot;/bin/systemctl stop nginx&quot;</span><br><span class="line">    if failed host 192.168.33.200 port 80 then restart</span><br><span class="line"></span><br><span class="line">check filesystem jenkins_mount with path /dev/sda2</span><br><span class="line">    start program  = &quot;/bin/mount /var/lib/jenkins&quot;</span><br><span class="line">    stop program  = &quot;/bin/umount /var/lib/jenkins&quot;</span><br><span class="line">    if space usage &gt; 80% for 3 times within 5 cycles then alert</span><br><span class="line">    if space usage &gt; 99% then stop</span><br><span class="line">    if inode usage &gt; 30000 then alert</span><br><span class="line">    if inode usage &gt; 99% then stop</span><br><span class="line"></span><br><span class="line">check directory jenkins_home with path /var/lib/jenkins</span><br><span class="line">    if failed permission 755 then exec &quot;/bin/chmod 755 /var/lib/jenkins&quot;</span><br></pre></td></tr></table></figure><p>Enable gmail account Allow less secure apps to ‘on’<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start monit</span><br><span class="line">tail -f /var/log/monit.log</span><br><span class="line"># test by systemctl stop jenkins</span><br></pre></td></tr></table></figure></p><p><img src="https://i.imgur.com/gG5igvY.png" alt="monit"></p><h2 id="Implementing-security-and-roles-for-Jenkins"><a href="#Implementing-security-and-roles-for-Jenkins" class="headerlink" title="Implementing security and roles for Jenkins"></a>Implementing security and roles for Jenkins</h2><h3 id="Jenkins-Security-best-practices"><a href="#Jenkins-Security-best-practices" class="headerlink" title="Jenkins Security best practices"></a>Jenkins Security best practices</h3><ul><li>Disable job execution on the mater and use slave nodes for builds</li><li>Use job restrictions plugin to confine specific jobs to specific nodes irrespective of the label used<br>install plugin job restrictions-&gt; Manage Jenkins-&gt; Manage Nodes<br><img src="https://imgur.com/1gwJ4gM" alt="restrict jobs execution at node"></li><li>Enable CSRF protection and update scripts to use crumbs<br><img src="https://i.imgur.com/9q0FIpP.png" alt="configure csrf"></li><li>Enable the slave to master access control<br><img src="https://i.imgur.com/lPoxSai.png" alt="config"></li><li>For large encironments, use role and matrix based authorization strategies to isolate project access<br>install plugin Role-based Authorization Strategy<br><img src="https://i.imgur.com/H0bz6rU.png" alt="Project-based Matrix Authorization Strategy"><br><img src="https://i.imgur.com/YkFDXf5.png" alt="Enable project-based security"><h3 id="use-LDAP-server-and-role-based-strategy"><a href="#use-LDAP-server-and-role-based-strategy" class="headerlink" title="use LDAP server and role-based strategy"></a>use LDAP server and role-based strategy</h3>1.ldap server config on centos 7<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br></pre></td><td class="code"><pre><span class="line">yum -y install openldap-servers openldap-clients</span><br><span class="line">cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG</span><br><span class="line">chown ldap. /var/lib/ldap/DB_CONFIG</span><br><span class="line">systemctl start slapd</span><br><span class="line"></span><br><span class="line">slappasswd -&gt; Enter new password twice -&gt; GENERATED_PASSWORD</span><br><span class="line"></span><br><span class="line">#New file</span><br><span class="line">config.ldif</span><br><span class="line"></span><br><span class="line">#Add content</span><br><span class="line">dn: olcDatabase=&#123;0&#125;config,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcRootPW</span><br><span class="line">olcRootPW: GENERATED_PASSWORD</span><br><span class="line"></span><br><span class="line">#Run commands</span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f config.ldif</span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif</span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif</span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif</span><br><span class="line"></span><br><span class="line">#New file</span><br><span class="line">domain.ldif</span><br><span class="line"></span><br><span class="line">#Add content</span><br><span class="line">dn: olcDatabase=&#123;1&#125;monitor,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcAccess</span><br><span class="line">olcAccess: &#123;0&#125;to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth&quot;</span><br><span class="line">  read by dn.base=&quot;cn=Manager,dc=practicaljenkins,dc=com&quot; read by * none</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcSuffix</span><br><span class="line">olcSuffix: dc=practicaljenkins,dc=com</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcRootDN</span><br><span class="line">olcRootDN: cn=Manager,dc=practicaljenkins,dc=com</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcRootPW</span><br><span class="line">olcRootPW: &#123;SSHA&#125;mviTD7um1R+LygfAN01MzQOtK4ezm1ob</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcAccess</span><br><span class="line">olcAccess: &#123;0&#125;to attrs=userPassword,shadowLastChange by</span><br><span class="line">  dn=&quot;cn=Manager,dc=practicaljenkins,dc=com&quot; write by anonymous auth by self write by * none</span><br><span class="line">olcAccess: &#123;1&#125;to dn.base=&quot;&quot; by * read</span><br><span class="line">olcAccess: &#123;2&#125;to * by dn=&quot;cn=Manager,dc=practicaljenkins,dc=com&quot; write by * read</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Run command</span><br><span class="line">ldapmodify -Y EXTERNAL -H ldapi:/// -f domain.ldif</span><br><span class="line"></span><br><span class="line">systemctl restart slapd</span><br><span class="line"></span><br><span class="line">#New file</span><br><span class="line">base.ldif</span><br><span class="line"></span><br><span class="line">#Add content</span><br><span class="line">dn: dc=practicaljenkins,dc=com</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: dcObject</span><br><span class="line">objectclass: organization</span><br><span class="line">o: practicaljenkins</span><br><span class="line">dc: practicaljenkins</span><br><span class="line"></span><br><span class="line">dn: cn=Manager,dc=practicaljenkins,dc=com</span><br><span class="line">objectClass: organizationalRole</span><br><span class="line">cn: Manager</span><br><span class="line">description: Directory Manager</span><br><span class="line"></span><br><span class="line">dn: ou=users,dc=practicaljenkins,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: users</span><br><span class="line"></span><br><span class="line">dn: ou=groups,dc=practicaljenkins,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: groups</span><br><span class="line"></span><br><span class="line">#Run command - enter password of slappasswd command when asked</span><br><span class="line"></span><br><span class="line">ldapadd -x -D cn=Manager,dc=practicaljenkins,dc=com -W -f base.ldif</span><br><span class="line"></span><br><span class="line">## configure phpldapadmin</span><br><span class="line">yum -y install httpd php php-mbstring php-pear</span><br><span class="line">systemctl start httpd</span><br><span class="line">yum -y install epel-release</span><br><span class="line">yum clean all &amp;&amp; yum makecache fast &amp;&amp; yum update</span><br><span class="line">vim /etc/phpldapadmin/config.php</span><br><span class="line">&lt;?php</span><br><span class="line">$config-&gt;custom-&gt;session[&apos;blowfish&apos;] = &apos;d7458abe84f9622a42ce3f9e45dfc457&apos;;  # Autogenerated for ip-172-31-4-228.ap-southeast-2.compute.internal</span><br><span class="line"></span><br><span class="line">$config-&gt;custom-&gt;commands[&apos;cmd&apos;] = array(</span><br><span class="line">&apos;entry_internal_attributes_show&apos; =&gt; true,</span><br><span class="line">&apos;entry_refresh&apos; =&gt; true,</span><br><span class="line">&apos;oslinks&apos; =&gt; true,</span><br><span class="line">&apos;switch_template&apos; =&gt; true</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">$config-&gt;custom-&gt;commands[&apos;script&apos;] = array(</span><br><span class="line">&apos;add_attr_form&apos; =&gt; true,</span><br><span class="line">&apos;add_oclass_form&apos; =&gt; true,</span><br><span class="line">&apos;add_value_form&apos; =&gt; true,</span><br><span class="line">&apos;collapse&apos; =&gt; true,</span><br><span class="line">&apos;compare&apos; =&gt; true,</span><br><span class="line">&apos;compare_form&apos; =&gt; true,</span><br><span class="line">&apos;copy&apos; =&gt; true,</span><br><span class="line">&apos;copy_form&apos; =&gt; true,</span><br><span class="line">&apos;create&apos; =&gt; true,</span><br><span class="line">&apos;create_confirm&apos; =&gt; true,</span><br><span class="line">&apos;delete&apos; =&gt; true,</span><br><span class="line">&apos;delete_attr&apos; =&gt; true,</span><br><span class="line">&apos;delete_form&apos; =&gt; true,</span><br><span class="line">&apos;draw_tree_node&apos; =&gt; true,</span><br><span class="line">&apos;expand&apos; =&gt; true,</span><br><span class="line">&apos;export&apos; =&gt; true,</span><br><span class="line">&apos;export_form&apos; =&gt; true,</span><br><span class="line">&apos;import&apos; =&gt; true,</span><br><span class="line">&apos;import_form&apos; =&gt; true,</span><br><span class="line">&apos;login&apos; =&gt; true,</span><br><span class="line">&apos;logout&apos; =&gt; true,</span><br><span class="line">&apos;login_form&apos; =&gt; true,</span><br><span class="line">&apos;mass_delete&apos; =&gt; true,</span><br><span class="line">&apos;mass_edit&apos; =&gt; true,</span><br><span class="line">&apos;mass_update&apos; =&gt; true,</span><br><span class="line">&apos;modify_member_form&apos; =&gt; true,</span><br><span class="line">&apos;monitor&apos; =&gt; true,</span><br><span class="line">&apos;purge_cache&apos; =&gt; true,</span><br><span class="line">&apos;query_engine&apos; =&gt; true,</span><br><span class="line">&apos;rename&apos; =&gt; true,</span><br><span class="line">&apos;rename_form&apos; =&gt; true,</span><br><span class="line">&apos;rdelete&apos; =&gt; true,</span><br><span class="line">&apos;refresh&apos; =&gt; true,</span><br><span class="line">&apos;schema&apos; =&gt; true,</span><br><span class="line">&apos;server_info&apos; =&gt; true,</span><br><span class="line">&apos;show_cache&apos; =&gt; true,</span><br><span class="line">&apos;template_engine&apos; =&gt; true,</span><br><span class="line">&apos;update_confirm&apos; =&gt; true,</span><br><span class="line">&apos;update&apos; =&gt; true</span><br><span class="line">);</span><br><span class="line">$servers = new Datastore();</span><br><span class="line">$servers-&gt;newServer(&apos;ldap_pla&apos;);</span><br><span class="line">$servers-&gt;setValue(&apos;server&apos;,&apos;name&apos;,&apos;Stan Local LDAP Server&apos;);</span><br><span class="line">$servers-&gt;setValue(&apos;server&apos;,&apos;host&apos;,&apos;172.31.4.228&apos;);</span><br><span class="line">$servers-&gt;setValue(&apos;appearance&apos;,&apos;password_hash&apos;,&apos;&apos;);</span><br><span class="line">$servers-&gt;setValue(&apos;login&apos;,&apos;attr&apos;,&apos;dn&apos;);</span><br><span class="line">$servers-&gt;setValue(&apos;login&apos;,&apos;class&apos;,array(&apos;dc=practicaljenkins,dc=com&apos;));</span><br><span class="line">?&gt;</span><br><span class="line"></span><br><span class="line">systemctl restart httpd</span><br><span class="line">vim /etc/httpd/conf.d/phpldapadmin.conf</span><br><span class="line">#</span><br><span class="line">#  Web-based tool for managing LDAP servers</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line">Alias /phpldapadmin /usr/share/phpldapadmin/htdocs</span><br><span class="line">Alias /ldapadmin /usr/share/phpldapadmin/htdocs</span><br><span class="line"></span><br><span class="line">&lt;Directory /usr/share/phpldapadmin/htdocs&gt;</span><br><span class="line">  &lt;IfModule mod_authz_core.c&gt;</span><br><span class="line">    # Apache 2.4</span><br><span class="line">    #Require local</span><br><span class="line">    Require all granted</span><br><span class="line">  &lt;/IfModule&gt;</span><br><span class="line">  &lt;IfModule !mod_authz_core.c&gt;</span><br><span class="line">    # Apache 2.2</span><br><span class="line">    Order Deny,Allow</span><br><span class="line">    Deny from all</span><br><span class="line">    Allow from 127.0.0.1</span><br><span class="line">    Allow from ::1</span><br><span class="line">  &lt;/IfModule&gt;</span><br><span class="line">&lt;/Directory&gt;</span><br><span class="line">cat /etc/selinux/config</span><br><span class="line"></span><br><span class="line"># This file controls the state of SELinux on the system.</span><br><span class="line"># SELINUX= can take one of these three values:</span><br><span class="line">#     enforcing - SELinux security policy is enforced.</span><br><span class="line">#     permissive - SELinux prints warnings instead of enforcing.</span><br><span class="line">#     disabled - No SELinux policy is loaded.</span><br><span class="line">SELINUX=disabled</span><br><span class="line"># SELINUXTYPE= can take one of three values:</span><br><span class="line">#     targeted - Targeted processes are protected,</span><br><span class="line">#     minimum - Modification of targeted policy. Only selected processes are protected.</span><br><span class="line">#     mls - Multi Level Security protection.</span><br><span class="line">#SELINUXTYPE=targeted</span><br><span class="line"></span><br><span class="line">systemctl restart httpd</span><br><span class="line">systemctl enable slapd</span><br><span class="line">systemctl enable httpd</span><br><span class="line">netstat -atnulp</span><br></pre></td></tr></table></figure></li></ul><p>Login to ipaddress/phpldapadmin<br>Ligin DN: cn=Manager,dc=practialjenkins.dc=com<br>Password: </p><p>Under ou=groups create a child entry-&gt; Generic: Posix Group<br>3 groups: admins, developers, devops</p><p>Under ou=users create Generic: User Account a b c</p><p>Under cn=admins Add new attribue mumberUid a<br>same for other groups</p><p>Configure Global Security<br><img src="https://i.imgur.com/JM1wDEf.png" alt="ldap config"><br>Group membership filter -&gt; (| (member={0}) (uniqueMember={0}) (memberUid={1}))</p><p>Under Authorization choose Role-Based Strategy</p><p>Under Manage Jenkins click Mange and Assign Roles -&gt; Manage Role-&gt; Role to add “admins, developers and devops”<br><img src="https://i.imgur.com/l1wUQY3.png" alt="managerole"></p><p>Assign Roles-&gt; User/group to add-&gt; admins, developers, and devops<br><img src="https://i.imgur.com/10Cbmz6.png" alt="assignrole"></p><p>User different user for login:<br><img src="https://i.imgur.com/R8fVL74.png" alt="login"></p><h2 id="Using-the-jenkinss-api-and-automating-plugin-management"><a href="#Using-the-jenkinss-api-and-automating-plugin-management" class="headerlink" title="Using the jenkinss api and automating plugin management"></a>Using the jenkinss api and automating plugin management</h2><p>get API token from ‘People’&gt; admin-&gt; configure-&gt;API Token</p><p>Automatically tirgger the build by:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -u admin:20fda2a6ed2ff7a8cf9db9dd50a0c2b0 &quot;http://localhost:8080/api/json?pretty=true&quot;</span><br><span class="line">curl -s &apos;http://localhost:8080/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,&quot;:&quot;,//crumb)&apos; -u admin:admin</span><br><span class="line">curl -X POST -u admin:20fda2a6ed2ff7a8cf9db9dd50a0c2b0 &quot;http://localhost:8080/job/python-job/build&quot; -H &quot;Jenkins-Crumb:f40b9f1084de9e60cca87085b30e6159&quot;</span><br></pre></td></tr></table></figure></p><p>Jenkins CLI:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget --auth-no-challenge &quot;http://localhost:8080/jnlpJars/jenkins-cli.jar&quot;</span><br><span class="line">java -jar jenkins-cli.jar -auth admin:20fda2a6ed2ff7a8cf9db9dd50a0c2b0 -s http://localhost:8080 help</span><br><span class="line">java -jar jenkins-cli.jar -auth admin:20fda2a6ed2ff7a8cf9db9dd50a0c2b0 -s http://localhost:8080 install-plugin aws-codebuild -deploy</span><br><span class="line">java -jar jenkins-cli.jar -auth admin:20fda2a6ed2ff7a8cf9db9dd50a0c2b0 -s http://localhost:8080 install-plugin http://updates.jenkins-ci.org/latest/ansicolor.hpi -deploy</span><br><span class="line">java -jar jenkins-cli.jar -auth admin:20fda2a6ed2ff7a8cf9db9dd50a0c2b0 -s http://localhost:8080 install-plugin http://updates.jenkins-ci.org/download/plugins/beaker-builder/1.6/beaker-builder.hpi -deploy</span><br></pre></td></tr></table></figure></p><h1 id="Integrating-Jenkins-with-external-services"><a href="#Integrating-Jenkins-with-external-services" class="headerlink" title="Integrating Jenkins with external services"></a>Integrating Jenkins with external services</h1><h2 id="Integrating-with-Github"><a href="#Integrating-with-Github" class="headerlink" title="Integrating with Github"></a>Integrating with Github</h2><p><img src="https://i.imgur.com/hkwPMqG.png" alt="workflow"></p><ul><li>Preparing Github and configuring Jenkins to work together<br>Github-&gt;Setting-&gt;Developer setting-&gt;Personal access tokens-&gt; Genere a new token-&gt; select scopes (repo:all |admin:repo_hook all| admin:org_hook)-&gt;copy token</li></ul><p>Jenkins-&gt;Add credentials-&gt; Kind username with password |scope global| username szhouchoice| password access token|id jenkins-secret<br>add another credentials-&gt; kind secret test-&gt; secret token|id jenkins-token-&gt;save</p><p>Username with password will use for multi-branch pipeline<br>secret text will be use in Global configuration for github server<br><img src="https://i.imgur.com/u4OVbH2.png" alt="github server setting"></p><p>Install GitHub Branch Source Plugin</p><ul><li>Configuring the Pipeline to create a code build workflow<br><a href="https://github.com/practicaljenkins/sample-php-project">project</a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git add -A</span><br><span class="line">git commit -m &quot;adding code&quot;</span><br><span class="line">git push origin master</span><br><span class="line">git checkout -b develop</span><br><span class="line">git push orgin develop</span><br></pre></td></tr></table></figure></li></ul><p>In Jenkins-&gt; Create new Multibranch Pipeline-&gt;<br><img src="https://i.imgur.com/Tn2maPQ.png" alt="Branch sources setting"></p><ul><li>Testing the pipelines with different scenarios<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b feature-001</span><br><span class="line">vim src/ConnectTest.php</span><br></pre></td></tr></table></figure></li></ul><p>push feature branch to github<br><img src="https://i.imgur.com/JOkzC9O.png" alt="merge in github"><br>will trigger the build in Jenkins</p><h2 id="Integrating-with-Sonarqube"><a href="#Integrating-with-Sonarqube" class="headerlink" title="Integrating with Sonarqube"></a>Integrating with Sonarqube</h2><ul><li>setting up Sonarqube prerequisites for Jenkins</li><li>Install and configure Sonarqube plugin</li><li>Configure Jenkins pipeline for Sonarqube action</li><li>Generate Sonarqube analysis report from Jenkins pipeline</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Practical-Jenkins-for-Production-Deployments&quot;&gt;&lt;a href=&quot;#Practical-Jenkins-for-Production-Deployments&quot; class=&quot;headerlink&quot; title=&quot;Prac
      
    
    </summary>
    
    
      <category term="Jenkins" scheme="http://223.95.78.227/tags/Jenkins/"/>
    
      <category term="Devops" scheme="http://223.95.78.227/tags/Devops/"/>
    
      <category term="CD/CI" scheme="http://223.95.78.227/tags/CD-CI/"/>
    
  </entry>
  
  <entry>
    <title>useful commands</title>
    <link href="http://223.95.78.227/2019/06/19/useful-commands/"/>
    <id>http://223.95.78.227/2019/06/19/useful-commands/</id>
    <published>2019-06-19T07:11:17.000Z</published>
    <updated>2019-09-17T10:42:20.642Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br></pre></td><td class="code"><pre><span class="line">cp /etc/vsftpd/vsftpd.conf&#123;,.bak&#125;</span><br><span class="line"></span><br><span class="line">[root@agent1 ~]# &gt;/etc/motd #删除文件内容</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@puppetmaster ~]# mv /etc/puppet/autosign.conf&#123;,.bak&#125;   #删除自动注册ACL列表</span><br><span class="line"></span><br><span class="line">[root@linux-node1 /]# grep &apos;^[a-z]&apos; /etc/elasticsearch/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">sudo tar xfz pycharm-*.tar.gz -C /opt/</span><br><span class="line"></span><br><span class="line">nohup &amp; screen</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># send a command to be executed on the remote machine and send back the output:</span><br><span class="line">ssh -t user1@server1.packt.co.uk cat /etc/hosts</span><br><span class="line"></span><br><span class="line">#use SSH to send files between two machines to or from a remote machine, using the scp command:</span><br><span class="line">scp user1@server1.packt.co.uk:/home/user1/Desktop/file1.txt  ./Desktop/</span><br><span class="line"></span><br><span class="line">ssh key-based authentication</span><br><span class="line">ssh-keygen -t rsa -b 2048 -v</span><br><span class="line">ssh-copy-id user1@server1.packt.co.uk</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# cat /tmp/passwd-truncated</span><br><span class="line">root:x:0:0:root:/root:/bin/bash</span><br><span class="line">bin:x:1:1:bin:/bin:/sbin/nologin</span><br><span class="line">daemon:x:2:2:daemon:/sbin:/sbin/nologin</span><br><span class="line">adm:x:3:4:adm:/var/adm:/sbin/nologin</span><br><span class="line">lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin</span><br><span class="line">[root@ip-172-31-5-191 ~]# cut -d: -f2,3 /tmp/passwd-truncated</span><br><span class="line">x:0</span><br><span class="line">x:1</span><br><span class="line">x:2</span><br><span class="line">x:3</span><br><span class="line">x:4</span><br><span class="line">[root@ip-172-31-5-191 ~]# cut -d: -f2,3 --output-delimiter &quot; &quot; /tmp/passwd-truncated</span><br><span class="line">x 0</span><br><span class="line">x 1</span><br><span class="line">x 2</span><br><span class="line">x 3</span><br><span class="line">x 4</span><br><span class="line">[root@ip-172-31-5-191 ~]# egrep -v &apos;#|^$&apos; /etc/services |head -5 &gt; /tmp/services-truncated</span><br><span class="line">[root@ip-172-31-5-191 ~]# cat /tmp/services-truncated</span><br><span class="line">echo            7/tcp</span><br><span class="line">echo            7/udp</span><br><span class="line">discard         9/tcp           sink null</span><br><span class="line">discard         9/udp           sink null</span><br><span class="line">systat          11/tcp          users</span><br><span class="line">[root@ip-172-31-5-191 ~]# sed  &apos;s/ /*/g&apos; /tmp/services-truncated</span><br><span class="line">echo************7/tcp</span><br><span class="line">echo************7/udp</span><br><span class="line">discard*********9/tcp***********sink*null</span><br><span class="line">discard*********9/udp***********sink*null</span><br><span class="line">systat**********11/tcp**********users</span><br><span class="line">[root@ip-172-31-5-191 ~]# awk -F&apos; &apos; &apos;&#123;print $2&quot; &quot;$3&#125;&apos; /tmp/services-truncated</span><br><span class="line">7/tcp</span><br><span class="line">7/udp</span><br><span class="line">9/tcp sink</span><br><span class="line">9/udp sink</span><br><span class="line">11/tcp users</span><br><span class="line">[root@ip-172-31-5-191 ~]# # tr [CHARACTER_FROM] [CHARACTER_TO]</span><br><span class="line">[root@ip-172-31-5-191 ~]# cat /tmp/services-truncated |tr &apos;a&apos; &apos;X&apos;</span><br><span class="line">echo            7/tcp</span><br><span class="line">echo            7/udp</span><br><span class="line">discXrd         9/tcp           sink null</span><br><span class="line">discXrd         9/udp           sink null</span><br><span class="line">systXt          11/tcp          users</span><br><span class="line">[root@ip-172-31-5-191 ~]# cat /tmp/services-truncated |tr &apos;[a-z]&apos; &apos;[A-Z]&apos;</span><br><span class="line">ECHO            7/TCP</span><br><span class="line">ECHO            7/UDP</span><br><span class="line">DISCARD         9/TCP           SINK NULL</span><br><span class="line">DISCARD         9/UDP           SINK NULL</span><br><span class="line">SYSTAT          11/TCP          USERS</span><br><span class="line">[root@ip-172-31-5-191 ~]# awk -F &apos; &apos; &apos;&#123;print $1&#125;&apos; /etc/services |egrep -v &apos;^#|^$&apos;| sort| uniq -c| sort -n -k1,1 -r|head</span><br><span class="line">      4 exp2</span><br><span class="line">      4 exp1</span><br><span class="line">      4 discard</span><br><span class="line">      3 v5ua</span><br><span class="line">      3 syslog-tls</span><br><span class="line">      3 sua</span><br><span class="line">      3 ssh</span><br><span class="line">      3 nfsrdma</span><br><span class="line">      3 nfs</span><br><span class="line">      3 megaco-h248</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# cp /etc/services /tmp/services</span><br><span class="line">[root@ip-172-31-5-191 ~]# gzip /tmp/services</span><br><span class="line">[root@ip-172-31-5-191 ~]# ls -lh /etc/services /tmp/services.gz</span><br><span class="line">-rw-r--r--. 1 root root 655K Jun  7  2013 /etc/services</span><br><span class="line">-rw-r--r--. 1 root root 133K Jun 19 06:01 /tmp/services.gz</span><br><span class="line">[root@ip-172-31-5-191 ~]# gunzip /tmp/services.gz</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# tar zcf /tmp/archive.tar.gz /home/centos</span><br><span class="line">tar: Removing leading `/&apos; from member names</span><br><span class="line">[root@ip-172-31-5-191 ~]# mkdir /tmp/extracted</span><br><span class="line">[root@ip-172-31-5-191 ~]# tar xvf /tmp/archive.tar.gz -C /tmp/extracted</span><br><span class="line">home/centos/</span><br><span class="line">home/centos/.bash_logout</span><br><span class="line">home/centos/.bash_profile</span><br><span class="line">home/centos/.bashrc</span><br><span class="line">home/centos/.ssh/</span><br><span class="line">home/centos/.ssh/authorized_keys</span><br><span class="line">home/centos/.bash_history</span><br><span class="line">[root@ip-172-31-5-191 ~]# cat /proc/meminfo</span><br><span class="line">MemTotal:        3878872 kB</span><br><span class="line">MemFree:         2586524 kB</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# free -mh</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           3.7G        716M        2.5G         16M        546M        2.7G</span><br><span class="line">Swap:            0B          0B          0B</span><br><span class="line">[root@ip-172-31-5-191 ~]# df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/xvda1       60G  2.2G   58G   4% /</span><br><span class="line">devtmpfs        1.9G     0  1.9G   0% /dev</span><br><span class="line">tmpfs           1.9G     0  1.9G   0% /dev/shm</span><br><span class="line">tmpfs           1.9G   17M  1.9G   1% /run</span><br><span class="line">tmpfs           1.9G     0  1.9G   0% /sys/fs/cgroup</span><br><span class="line">tmpfs           379M     0  379M   0% /run/user/1000</span><br><span class="line">[root@ip-172-31-5-191 ~]# du -h</span><br><span class="line">4.0K./.ssh</span><br><span class="line">0./.pki/nssdb</span><br><span class="line">0./.pki</span><br><span class="line">52K.</span><br><span class="line">[root@ip-172-31-5-191 ~]# du -h / --max-depth=1</span><br><span class="line">0/dev</span><br><span class="line">du: cannot access ‘/proc/14331/task/14331/fd/3’: No such file or directory</span><br><span class="line">du: cannot access ‘/proc/14331/task/14331/fdinfo/3’: No such file or directory</span><br><span class="line">du: cannot access ‘/proc/14331/fd/4’: No such file or directory</span><br><span class="line">du: cannot access ‘/proc/14331/fdinfo/4’: No such file or directory</span><br><span class="line">0/proc</span><br><span class="line">17M/run</span><br><span class="line">0/sys</span><br><span class="line">35M/etc</span><br><span class="line">52K/root</span><br><span class="line">641M/var</span><br><span class="line">4.5M/tmp</span><br><span class="line">1.3G/usr</span><br><span class="line">183M/boot</span><br><span class="line">76K/home</span><br><span class="line">0/media</span><br><span class="line">0/mnt</span><br><span class="line">0/opt</span><br><span class="line">0/srv</span><br><span class="line">2.2G/</span><br><span class="line">root@ip-172-31-5-191 ~]# dd if=/dev/zero of=/tmp/lgig_file.empty bs=1M count=1024</span><br><span class="line">1024+0 records in</span><br><span class="line">1024+0 records out</span><br><span class="line">1073741824 bytes (1.1 GB) copied, 3.61028 s, 297 MB/s</span><br><span class="line">$ su -c &apos;dd if=/dev/sda1 of=/tmp/img.image&apos;</span><br><span class="line">[root@ip-172-31-5-191 ~]# dd if=/home/centos/.bashrc of=/tmp/.bashrc-copy</span><br><span class="line">0+1 records in</span><br><span class="line">0+1 records out</span><br><span class="line">231 bytes (231 B) copied, 0.000164855 s, 1.4 MB/s</span><br><span class="line">[root@ip-172-31-5-191 ~]# rsync -rav /home/centos/ /tmp/new-centos-home</span><br><span class="line">sending incremental file list</span><br><span class="line">created directory /tmp/new-centos-home</span><br><span class="line">./</span><br><span class="line">.bash_history</span><br><span class="line">.bash_logout</span><br><span class="line">.bash_profile</span><br><span class="line">.bashrc</span><br><span class="line">.ssh/</span><br><span class="line">.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line">sent 1,280 bytes  received 169 bytes  2,898.00 bytes/sec</span><br><span class="line">total size is 843  speedup is 0.58</span><br><span class="line"></span><br><span class="line"># rsync -rav /home/centos/ stan@192.168.178.300:/tmp</span><br><span class="line"># rsync -rav stan@192.168.178.300:/tmp/stan /tmp/another-copy</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# telnet google.com 80</span><br><span class="line">Trying 216.58.200.110...</span><br><span class="line">Connected to google.com.</span><br><span class="line">Escape character is &apos;^]&apos;.</span><br><span class="line">^]</span><br><span class="line">HTTP/1.0 400 Bad Request</span><br><span class="line">Content-Type: text/html; charset=UTF-8</span><br><span class="line">Referrer-Policy: no-referrer</span><br><span class="line">Content-Length: 1555</span><br><span class="line">Date: Wed, 19 Jun 2019 06:30:24 GMT</span><br><span class="line"></span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=en&gt;</span><br><span class="line">  &lt;meta charset=utf-8&gt;</span><br><span class="line">  &lt;meta name=viewport content=&quot;initial-scale=1, minimum-scale=1, width=device-width&quot;&gt;</span><br><span class="line">  &lt;title&gt;Error 400 (Bad Request)!!1&lt;/title&gt;</span><br><span class="line">  &lt;style&gt;</span><br><span class="line">    *&#123;margin:0;padding:0&#125;html,code&#123;font:15px/22px arial,sans-serif&#125;html&#123;background:#fff;color:#222;padding:15px&#125;body&#123;margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px&#125;* &gt; body&#123;background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px&#125;p&#123;margin:11px 0 22px;overflow:hidden&#125;ins&#123;color:#777;text-decoration:none&#125;a img&#123;border:0&#125;@media screen and (max-width:772px)&#123;body&#123;background:none;margin-top:0;max-width:none;padding-right:0&#125;&#125;#logo&#123;background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px&#125;@media only screen and (min-resolution:192dpi)&#123;#logo&#123;background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0&#125;&#125;@media only screen and (-webkit-min-device-pixel-ratio:2)&#123;#logo&#123;background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%&#125;&#125;#logo&#123;display:inline-block;height:54px;width:150px&#125;</span><br><span class="line">  &lt;/style&gt;</span><br><span class="line">  &lt;a href=//www.google.com/&gt;&lt;span id=logo aria-label=Google&gt;&lt;/span&gt;&lt;/a&gt;</span><br><span class="line">  &lt;p&gt;&lt;b&gt;400.&lt;/b&gt; &lt;ins&gt;That’s an error.&lt;/ins&gt;</span><br><span class="line">  &lt;p&gt;Your client has issued a malformed or illegal request.  &lt;ins&gt;That’s all we know.&lt;/ins&gt;</span><br><span class="line">Connection closed by foreign host.</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# wget -O /tmp/output.txt http://whatthecommit.com/index.txt</span><br><span class="line">--2019-06-19 06:32:13--  http://whatthecommit.com/index.txt</span><br><span class="line">Resolving whatthecommit.com (whatthecommit.com)... 52.86.186.182, 52.200.233.201, 52.202.60.111, ...</span><br><span class="line">Connecting to whatthecommit.com (whatthecommit.com)|52.86.186.182|:80... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 14 [text/plain]</span><br><span class="line">Saving to: ‘/tmp/output.txt’</span><br><span class="line"></span><br><span class="line">100%[=============================================================&gt;] 14          --.-K/s   in 0s</span><br><span class="line"></span><br><span class="line">2019-06-19 06:32:13 (1.88 MB/s) - ‘/tmp/output.txt’ saved [14/14]</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# cat /tmp/output.txt</span><br><span class="line">Popping stash</span><br><span class="line">[root@ip-172-31-5-191 ~]# wget -qO- http://whatthecommit.com/index.txt</span><br><span class="line">clarify further the brokenness of C++. why the fuck are we using C++?</span><br><span class="line"></span><br><span class="line">root@stan-OptiPlex-380:~|⇒  nc -l -p 9999 &lt; /etc/lsb-release</span><br><span class="line">stan-OptiPlex-380% nc 192.168.199.178 9999 &gt; /tmp/redhat-release</span><br><span class="line">^C</span><br><span class="line">stan-OptiPlex-380% cat /tmp/redhat-release</span><br><span class="line">DISTRIB_ID=LinuxMint</span><br><span class="line">DISTRIB_RELEASE=19</span><br><span class="line">DISTRIB_CODENAME=tara</span><br><span class="line">DISTRIB_DESCRIPTION=&quot;Linux Mint 19 Tara&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># links www.duckduckgo.com</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# echo &apos;(8-(3+1))/4&apos; |bc</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# screen</span><br><span class="line"></span><br><span class="line">Ctrl + A + D</span><br><span class="line"></span><br><span class="line">[detached from 17091.pts-0.ip-172-31-5-191]</span><br><span class="line">[root@ip-172-31-5-191 ~]# exit</span><br><span class="line">logout</span><br><span class="line">[centos@ip-172-31-5-191 ~]$ exit</span><br><span class="line">logout</span><br><span class="line">Connection to 54.66.232.147 closed.</span><br><span class="line"></span><br><span class="line">ssh cicd</span><br><span class="line">Last login: Wed Jun 19 05:39:48 2019 from 220.240.212.9</span><br><span class="line">[centos@ip-172-31-5-191 ~]$ sudo -i</span><br><span class="line">[root@ip-172-31-5-191 ~]# screen -list</span><br><span class="line">There is a screen on:</span><br><span class="line">17091.pts-0.ip-172-31-5-191(Detached)</span><br><span class="line">1 Socket in /var/run/screen/S-root.</span><br><span class="line"></span><br><span class="line">[root@ip-172-31-5-191 ~]# screen -r 17091.pts-0.ip-172-31-5-191</span><br><span class="line"></span><br><span class="line">Type exit for quit</span><br><span class="line">[screen is terminating]</span><br></pre></td></tr></table></figure><hr><h2 id="various-top-like-programs"><a href="#various-top-like-programs" class="headerlink" title="various top-like programs"></a>various top-like programs</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">iotop ## Get a live view on the input and output, or short I/O, bandwidth usage of your system</span><br><span class="line"></span><br><span class="line">iftop ## which gets a live view on network traffic and network bandwidth usage and monitor</span><br><span class="line"></span><br><span class="line">htop ## improved version of the normal top program</span><br><span class="line">lsof | grep lib64 ## To print out a list of all open files, which means programs accessing files at the moment</span><br></pre></td></tr></table></figure><hr><h2 id="Largest-files-and-directories-report"><a href="#Largest-files-and-directories-report" class="headerlink" title="Largest files and directories report"></a>Largest files and directories report</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">FS=&apos;./&apos;;resize;clear;echo &quot;== Server Time: ==&quot;;date;echo -e &quot;\n== Filesystem Information: ==&quot;;df -PTh $&#123;FS&#125; | column -t;echo -e &quot;\n== Inode Information: ==&quot;;df -PTi $&#123;FS&#125; | column -t;echo -e &quot;\n== Largest Directories: ==&quot;;du -hcx --max-depth=2 $&#123;FS&#125; 2&gt;/dev/null | grep -P &apos;^([0-9]\.*)*G(?!.*(\btotal\b|\./$))&apos; | sort -rnk1,1 | head -10 | column -t;echo -e &quot;\n== Largest Files: ==&quot;;find $&#123;FS&#125; -mount -ignore_readdir_race -type f -exec du &#123;&#125; + 2&gt;&amp;1 | sort -rnk1,1 | head -20 | awk &apos;BEGIN&#123; CONVFMT=&quot;%.2f&quot;;&#125;&#123; $1=( $1 / 1024 )&quot;M&quot;; print;&#125;&apos; | column -t;echo -e &quot;\n== Largest Files Older Than 30 Days: ==&quot;;find $&#123;FS&#125; -mount -ignore_readdir_race -type f -mtime +30 -exec du &#123;&#125; + 2&gt;&amp;1 | sort -rnk1,1 | head -20 | awk &apos;BEGIN&#123; CONVFMT=&quot;%.2f&quot;;&#125;&#123; $1=( $1 / 1024 )&quot;M&quot;; print; &#125;&apos; | column -t;</span><br><span class="line"></span><br><span class="line">== Server Time: ==</span><br><span class="line">Thu Jun 20 04:57:53 UTC 2019</span><br><span class="line"></span><br><span class="line">== Filesystem Information: ==</span><br><span class="line">Filesystem  Type  Size  Used  Avail  Use%  Mounted  on</span><br><span class="line">/dev/xvda1  xfs   60G   3.9G  57G    7%    /</span><br><span class="line"></span><br><span class="line">== Inode Information: ==</span><br><span class="line">Filesystem  Type  Inodes    IUsed  IFree     IUse%  Mounted  on</span><br><span class="line">/dev/xvda1  xfs   31456704  62835  31393869  1%     /</span><br><span class="line"></span><br><span class="line">== Largest Directories: ==</span><br><span class="line"></span><br><span class="line">== Largest Files: ==</span><br><span class="line">0.00M  ./.ssh/authorized_keys</span><br><span class="line">0.00M  ./.lesshst</span><br><span class="line">0.00M  ./.bashrc</span><br><span class="line">0.00M  ./.bash_profile</span><br><span class="line">0.00M  ./.bash_logout</span><br><span class="line">0.00M  ./.bash_history</span><br><span class="line">0M     ./stuff/5.txt</span><br><span class="line">0M     ./stuff/4.txt</span><br><span class="line">0M     ./stuff/3.txt</span><br><span class="line">0M     ./stuff/2.txt</span><br><span class="line">0M     ./stuff/1.txt</span><br><span class="line"></span><br><span class="line">== Largest Files Older Than 30 Days: ==</span><br><span class="line">0.00M  ./.bashrc</span><br><span class="line">0.00M  ./.bash_profile</span><br><span class="line">0.00M  ./.bash_logout</span><br></pre></td></tr></table></figure><hr><h2 id="check-the-port-is-open-or-not"><a href="#check-the-port-is-open-or-not" class="headerlink" title="check the port is open or not"></a>check the port is open or not</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nmap -vv -n -sS -sU -p443 52.62.248.48/32 | grep &quot;Discovered open port&quot; |awk &#123;&apos;print $6&apos;&#125; | awk -F/ &#123;&apos;print$1&apos;</span><br></pre></td></tr></table></figure><hr><h2 id="AWS-cli-commands"><a href="#AWS-cli-commands" class="headerlink" title="AWS cli commands"></a>AWS cli commands</h2><p>List all the ec2 instances details:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 describe-instances --output text --query &apos;Reservations[*].Instances[*].[InstanceId, InstanceType, ImageId, State.Name, LaunchTime, Placement.AvailabilityZone, Placement.Tenancy, PrivateIpAddress, PrivateDnsName, PublicDnsName, [Tags[?Key==`Name`].Value] [0][0], [Tags[?Key==`purpose`].Value] [0][0], [Tags[?Key==`environment`].Value] [0][0], [Tags[?Key==`team`].Value] [0][0] ]&apos;&#125;`</span><br></pre></td></tr></table></figure></p><hr><p><strong>List server files information</strong><br><code>FS=&#39;./&#39;;resize;clear;echo &quot;== Server Time: ==&quot;;date;echo -e &quot;\n== Filesystem Information: ==&quot;;df -PTh ${FS} | column -t;echo -e &quot;\n== Inode Information: ==&quot;;df -PTi ${FS} | column -t;echo -e &quot;\n== Largest Directories: ==&quot;;du -hcx --max-depth=2 ${FS} 2&gt;/dev/null | grep -P &#39;^([0-9]\.*)*G(?!.*(\btotal\b|\./$))&#39; | sort -rnk1,1 | head -10 | column -t;echo -e &quot;\n== Largest Files: ==&quot;;find ${FS} -mount -ignore_readdir_race -type f -exec du {} + 2&gt;&amp;1 | sort -rnk1,1 | head -20 | awk &#39;BEGIN{ CONVFMT=&quot;%.2f&quot;;}{ $1=( $1 / 1024 )&quot;M&quot;; print;}&#39; | column -t;echo -e &quot;\n== Largest Files Older Than 30 Days: ==&quot;;find ${FS} -mount -ignore_readdir_race -type f -mtime +30 -exec du {} + 2&gt;&amp;1 | sort -rnk1,1 | head -20 | awk &#39;BEGIN{ CONVFMT=&quot;%.2f&quot;;}{ $1=( $1 / 1024 )&quot;M&quot;; print; }&#39; | column -t;</code></p><hr><h1 id="about-file"><a href="#about-file" class="headerlink" title="about file"></a>about file</h1><p><strong>Change the extension of multiple files</strong></p><h2 id="add-an-extension-for-the-source-files"><a href="#add-an-extension-for-the-source-files" class="headerlink" title="add an extension for the source files"></a>add an extension for the source files</h2><p><code>for f in *; do mv -- &quot;$f&quot; &quot;${f%.\*}.pdf&quot;;done</code></p><h2 id="find-the-file-size"><a href="#find-the-file-size" class="headerlink" title="find the file size"></a>find the file size</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@stan-OptiPlex-380:~|⇒  du -sh /*</span><br><span class="line">17M     /bin</span><br><span class="line">77M     /boot</span><br><span class="line">4.0K    /cdrom</span><br><span class="line">0       /dev</span><br><span class="line">17M     /etc</span><br><span class="line">1.6G    /home</span><br><span class="line">0       /initrd.img</span><br><span class="line">0       /initrd.img.old</span><br><span class="line">582M    /lib</span><br><span class="line">4.0K    /lib64</span><br><span class="line">16K     /lost+found</span><br><span class="line">4.0K    /media</span><br></pre></td></tr></table></figure><p><strong>about node process</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat startApp.sh</span><br><span class="line">#!/bin/sh</span><br><span class="line">export NODE_ENV=production</span><br><span class="line">export DB_PRD_HOST=stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com</span><br><span class="line">export DB_PRD_USER=stantest</span><br><span class="line">export NODE_HOST=localhost</span><br><span class="line">export NODE_PORT=8080</span><br><span class="line">node /myapp/index.js&amp;</span><br><span class="line">exit 0</span><br><span class="line">cat stopApp.sh</span><br><span class="line">#!/bin/sh</span><br><span class="line">kill `ps -axf |grep node |grep -v grep|awk &apos;&#123;print $1&#125;&apos;` | exit 0</span><br></pre></td></tr></table></figure></p><p>pgrep: pgrep, pkill - look up or signal processes based on name and other attributes</p><hr><h1 id="python"><a href="#python" class="headerlink" title="python"></a>python</h1><p>create a random password:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">stan@dockerfordevops:~/Projects/MobyDock$ python</span><br><span class="line">Python 2.7.12 (default, Nov 12 2018, 14:36:49) </span><br><span class="line">[GCC 5.4.0 20160609] on linux2</span><br><span class="line">Type <span class="string">"help"</span>, <span class="string">"copyright"</span>, <span class="string">"credits"</span> or <span class="string">"license"</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt; import os</span><br><span class="line">&gt;&gt;&gt; import binascii</span><br><span class="line">&gt;&gt;&gt; binascii.b2a_hex(os.urandom(31))</span><br></pre></td></tr></table></figure></p><h1 id="postgres"><a href="#postgres" class="headerlink" title="postgres"></a>postgres</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubernetes-release-1.5 psql -h database -U postgres</span><br><span class="line">psql (11.4 (Ubuntu 11.4-1.pgdg18.04+1), server 9.4.23)</span><br><span class="line">Type &quot;help&quot; for help.</span><br><span class="line"></span><br><span class="line">postgres-# \dd</span><br><span class="line">         Object descriptions</span><br><span class="line"> Schema | Name | Object | Description</span><br><span class="line">--------+------+--------+-------------</span><br><span class="line">(0 rows)</span><br></pre></td></tr></table></figure><p>$ mkdir vagrant_ubuntu_xenial_1 &amp;&amp; cd $_</p><p>wget <a href="https://raw.githubusercontent.com/yogeshraheja/Effective-DevOps-with-AWS/master/Chapter02/helloworld.conf">https://raw.githubusercontent.com/yogeshraheja/Effective-DevOps-with-AWS/master/Chapter02/helloworld.conf</a> -O scripts/helloworld.conf</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class
      
    
    </summary>
    
    
      <category term="linux" scheme="http://223.95.78.227/tags/linux/"/>
    
      <category term="commands" scheme="http://223.95.78.227/tags/commands/"/>
    
  </entry>
  
</feed>
