
 <!DOCTYPE HTML>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  
    <title>Stan Zhou&#39;s Hexo Technical Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Stan Zhou">
    

    
    <meta name="description" content="Infrastructure as code">
<meta property="og:type" content="website">
<meta property="og:title" content="Stan Zhou&#39;s Hexo Technical Blog">
<meta property="og:url" content="http://223.95.78.227/index.html">
<meta property="og:site_name" content="Stan Zhou&#39;s Hexo Technical Blog">
<meta property="og:description" content="Infrastructure as code">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Stan Zhou&#39;s Hexo Technical Blog">
<meta name="twitter:description" content="Infrastructure as code">
<meta name="twitter:creator" content="@stanosaka">

    
    <link rel="alternative" href="/atom.xml" title="Stan Zhou&#39;s Hexo Technical Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/toad.ico">
    
    
    <link rel="apple-touch-icon" href="/img/toadman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/toadman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>
</html>
  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/toadman.png" alt="Stan Zhou&#39;s Hexo Technical Blog" title="Stan Zhou&#39;s Hexo Technical Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Stan Zhou&#39;s Hexo Technical Blog">Stan Zhou&#39;s Hexo Technical Blog</a></h1>
				<h2 class="blog-motto">Innovation Evangelist</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:223.95.78.227">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/08/16/effective-devops-with-aws/" title="effective devops with aws" itemprop="url">effective devops with aws</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-08-15T14:15:29.000Z" itemprop="datePublished"> Published 2019-08-16</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><strong>Code</strong></p>
<p><a href="https://github.com/stanosaka/ansible">source code ansible</a><br><a href="https://github.com/00root/helloworld">source code helloworld</a></p>
<h1 id="Continuous-Delivery"><a href="#Continuous-Delivery" class="headerlink" title="Continuous Delivery"></a>Continuous Delivery</h1><p><img src="https://i.imgur.com/QOYWSYb.png" alt="codepipline01"><br><img src="https://i.imgur.com/an0PPjD.png" alt="codepipline02"><br><img src="https://i.imgur.com/P7gdZBo.png" alt="Source"><br><img src="https://i.imgur.com/O6LNT3M.png" alt="Test"><br><img src="https://i.imgur.com/gD0EYZ7.png" alt="Deploy"><br><img src="https://i.imgur.com/uAnMDQk.png" alt="Approval"><br><img src="https://i.imgur.com/OoeILa2.png" alt="Production"><br><img src="https://i.imgur.com/Mz3RM0I.png" alt="Jenkins01"><br><img src="https://i.imgur.com/88C8zGu.png" alt="Jenkins02"><br><img src="https://i.imgur.com/7YXnt5L.png" alt="Jenkins03"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm config set registry http://registry.npmjs.org/ </span><br><span class="line">npm install</span><br><span class="line">./node_modules/mocha/bin/mocha</span><br></pre></td></tr></table></figure></p>
<p><strong>Creating the new cloudformation stack for production</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">aws cloudformation create-stack --capabilities CAPABILITY_IAM --stack-name helloworld-production --template-body file://nodeserver-cf.template --parameters ParameterKey=KeyPair,ParameterValue=EffectiveDevOpsAWS</span><br><span class="line"> aws cloudformation wait stack-create-complete --stack-name helloworld-production</span><br><span class="line"> 3683  arn=$(aws deploy get-deployment-group --application-name helloworld --deployment-group-name staging --query &apos;deploymentGroupInfo.serviceRoleArn&apos;)</span><br><span class="line"> 3685  aws deploy create-deployment-group --application-name helloworld --ec2-tag-filters Key=aws:cloudformation:stack-name,Type=KEY_AND_VALUE,Value=helloworld-production --deployment-group-name production --service-role-arn $arn</span><br><span class="line"> 3687  aws deploy create-deployment-group --application-name helloworld --ec2-tag-filters Key=aws:cloudformation:stack-name,Type=KEY_AND_VALUE,Value=helloworld-production --deployment-group-name production --service-role-arn arn:aws:iam::012152306932:role/CodeDeployRole</span><br><span class="line"> 3688  aws deploy list-deployment-groups --application-name helloworld</span><br><span class="line"> 3689  aws sns create-topic --name production-deploy-approval</span><br><span class="line"> 3690  aws sns subscribe --topic-arn arn:aws:sns:ap-southeast-2:012152306932:production-deploy-approval --protocol email --notification-endpoint stan.osaka@gmail.com</span><br></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/08/03/vagrant/" title="vagrant" itemprop="url">vagrant</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-08-03T13:35:53.000Z" itemprop="datePublished"> Published 2019-08-03</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Vagrant can be used for automatically provisioning VMs, and even whole development environments.</p>
<p>On ubuntu host:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install vagrant</span><br><span class="line">$ vagrant --version</span><br><span class="line">$ mkdir Vagrant;cd Vagrant</span><br><span class="line">$ vagrant init</span><br><span class="line"># Every Vagrant development environment requires a box. You can search for</span><br><span class="line">  # boxes at https://vagrantcloud.com/search.</span><br><span class="line">  config.vm.box = &quot;base&quot;</span><br><span class="line">$ sed -i &apos;s#config.vm.box = &quot;base&quot;#config.vm.box = &quot;centos/7&quot;#g&apos; Vagrantfile</span><br><span class="line">$ vagrant up</span><br><span class="line">$ vagrant ssh</span><br><span class="line">$ vagrant destroy</span><br></pre></td></tr></table></figure></p>
<p><strong>Components</strong></p>
<ul>
<li>Providers:<ul>
<li>Backend of Vagrant</li>
<li>VirtualBox</li>
<li>VMware</li>
<li>Hyper-V</li>
<li>vCloud</li>
<li>AWS</li>
</ul>
</li>
<li>Boxes:<ul>
<li>Predefined images</li>
<li><a href="https://app.vagrantup.com/boxes/search">Public Vagrant box catalog</a></li>
</ul>
</li>
<li>Vagrantfile:<ul>
<li>A Ruby file</li>
<li>How many VMs</li>
<li>Configure VMs</li>
<li>Provision VMs</li>
<li>Committed to version control<br><img src="https://i.imgur.com/lb7muP9.png" alt="example of Vagrantfile"></li>
</ul>
</li>
<li>Provisioners:<ul>
<li>Automatically install software, alter configurations</li>
<li>Boxes may not be a complete use case for you</li>
<li>Multiple options</li>
<li>Shell Script</li>
<li>Ansible</li>
<li>Chef</li>
<li>Docker</li>
<li>Puppet<br><img src="https://i.imgur.com/U5cISEK.png" alt="workflow of vagrant"></li>
</ul>
</li>
</ul>
<p><strong>Operations</strong></p>
<ul>
<li>Adding a vagrant box:<ul>
<li>Syntax: vagrant box add <name> <url> <provider></li>
<li>Example: vagrant box add ubuntu/trusty32</li>
</ul>
</li>
<li>Listing and removing vagrant boxes:<ul>
<li>vagrant box list</li>
<li>vagrant box remove</li>
</ul>
</li>
<li>Creating a VM environment:<ul>
<li>Syntax: vagrant init <your box name></li>
<li>Example: vagrant init ubuntu/trusty32</li>
</ul>
</li>
<li>Starting a VM environment:<ul>
<li>vagrant up ubuntu/trusty32</li>
<li>vagrant up </li>
</ul>
</li>
<li>Connecting:<ul>
<li>vagrant ssh ubuntu/trusty32</li>
<li>vagrant ssh</li>
</ul>
</li>
<li>Stopping, restarting, and destroying<ul>
<li>vagrant halt</li>
<li>vagrant reload</li>
<li>vagrant destroy</li>
</ul>
</li>
</ul>
<p><strong>Provisioning of vagrant</strong></p>
<ul>
<li>Creating a VM and provisioning it with Apache installed and prot forwarding</li>
<li><p>Add theses lines in Vagrantfile:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8080</span><br><span class="line">config.vm.provision &apos;shell&apos;, path: &apos;provision.sh&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Create provision.sh file with these entries:</p>
<ul>
<li>sudo apt-get update</li>
<li>sudo apt-get install -y apache2</li>
</ul>
</li>
<li><p>Destroy and start the virtual machine:</p>
<ul>
<li>vagrant destroy</li>
<li>vagrant up</li>
</ul>
</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/vagrant/">vagrant</a><a href="/tags/Hashicorp/">Hashicorp</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/29/jenkins-blue-ocean/" title="Jenkins Pipeline" itemprop="url">Jenkins Pipeline</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-29T01:00:54.000Z" itemprop="datePublished"> Published 2019-07-29</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="An-Example-of-Declarative-Pipeline"><a href="#An-Example-of-Declarative-Pipeline" class="headerlink" title="An Example of Declarative Pipeline:"></a>An Example of Declarative Pipeline:</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">       node &#123;</span><br><span class="line">           label <span class="string">'master'</span></span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(<span class="string">'Build'</span>) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh <span class="string">'mvn clean verify -DskipITs=true'</span></span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage (<span class="string">'Static Code Analysis'</span>) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh <span class="string">'mvn clean verify sonar:sonar'</span></span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage (<span class="string">'Publish to Artifactory'</span>) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               script &#123;</span><br><span class="line">                   def server = Artifactory.server <span class="string">'Default Artifactory'</span></span><br><span class="line">                   def uploadSpec = <span class="string">""</span><span class="string">"&#123;</span></span><br><span class="line"><span class="string">                       "</span>files<span class="string">": [</span></span><br><span class="line"><span class="string">                           &#123;</span></span><br><span class="line"><span class="string">                               "</span>pattern<span class="string">": "</span>target/*.war<span class="string">",</span></span><br><span class="line"><span class="string">                               "</span>target<span class="string">": "</span>helloworld/<span class="variable">$&#123;BUILD_NUMBER&#125;</span>/<span class="string">",</span></span><br><span class="line"><span class="string">                               "</span>pattern<span class="string">": "</span>Unit-Tested=Yes<span class="string">",</span></span><br><span class="line"><span class="string">                           &#125;</span></span><br><span class="line"><span class="string">                        ]</span></span><br><span class="line"><span class="string">                    &#125;"</span><span class="string">""</span></span><br><span class="line">                    server.upload(uploadSpec)</span><br><span class="line">		&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Jenkinsfile</strong><br>A Jenkinsfile is a file that contains Pipeline code.</p>
<h2 id="Declarative-Pipeline-Syntax"><a href="#Declarative-Pipeline-Syntax" class="headerlink" title="Declarative Pipeline Syntax"></a>Declarative Pipeline Syntax</h2><p><strong>Sections</strong></p>
<p>Sections in Declarative Pipeline Syntax can contain one or more Directive or Steps.</p>
<h3 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h3><ul>
<li>The <em>agent</em> section defines where the whole Pipleline, or a specific stage, runs. It is positioned right at the beginnning of the <em>pipeline { }</em> block the is compolsory.</li>
<li>can also use it inside the <em>stage</em> directive, but that’s optional.<br>The <em>agent</em> section allow specific parameters to suit various use-cases.</li>
</ul>
<p><strong>any</strong></p>
<p>Use <em>agent any</em> inside your <em>pipleine {}</em> block, or <em>stage</em> directive, to run them on any agent available in Jenkins.<br><img src="https://i.imgur.com/6ByXXdT.png" alt="A pipleline{}Block with agent any"></p>
<p><strong>none</strong></p>
<p>Use <em>agent node</em> inside your <em>pipeline {}</em> block to stop any global agent from running your pipeline. In such case, each <em>stage</em> directive inside your pipeline must have its <em>agent</em> section.<br><img src="https://i.imgur.com/MQIQ9ID.png" alt="A Pipeline{}Block with Agnet None"></p>
<p><strong>label</strong></p>
<p>Run your complete pipeline, or stage, on an agent available in Jenkins with specific label.<br><img src="https://i.imgur.com/fw2xBh7.png" alt="A pipeline{} block with agent { label &#39;....&#39;} section"></p>
<p><strong>node</strong></p>
<p>Run your complete pipeline, or stage, on an agent available in Jenkins with s specific label. The behavior is similar to the <em>label</em> parameter. Howerver, the <em>node</em> parameter allows you to specify additional options such as <em>customWorkspace</em>. Workspace, or Jenkins Pipeline workspace, is a reserved directory on your Jenkins agent, where all your source code is downloaded and where your builds are performed.</p>
<p><img src="https://i.imgur.com/jtj39sB.png" alt="agent node customWorkspace section"></p>
<p><strong>docker</strong></p>
<p>Run your complete pipeline, or stage, inside a docker container. The container will be dynamically spawned on a pre-configured docker host.</p>
<p>The <em>docker</em> option also takes an <em>args</em> parameter that allows you to pass arguments directly to the <em>docker run</em> command.</p>
<p><img src="https://i.imgur.com/oINFaFW.png" alt="An agent section with docker parameter"></p>
<p><strong>dockerfile</strong></p>
<p>Run your pipeline, or stage, inside a conatiner build from a <em>dockerfile</em>. To use this option, the <em>jenkinsfile</em> and the <em>dockerfile</em> should be present inside the root of your source code.</p>
<p><img src="https://i.imgur.com/M2e1Xq0.png" alt="agent section with dockerfile"></p>
<p><strong>post</strong></p>
<p>The <em>post</em> section allows you to run additional <em>setps</em> after running a pipeline or a stage.<br><img src="https://i.imgur.com/xctaUYY.png" alt="a post section at the end of a pipeline"></p>
<p><img src="https://i.imgur.com/wmfuirh.png" alt="add specific conditions to post section"></p>
<p><strong>stages</strong></p>
<p>The <em>stages</em> section contains a sequence of one or more <em>stage</em> directives. It’s used to segregate a sinle or a collection of <em>stage</em> directives form the rest of the code.</p>
<p>The <em>stages</em> section has no parameters and gets used at least once in the pipeline.</p>
<p><strong>steps</strong></p>
<p>The <em>steps</em> section contains one or more steps that should run inside a <em>stage</em> directive. The <em>steps</em> section is used to segrate a single or a collection of steps from the rest of the code inside a <em>stage</em> directive.<br><img src="https://i.imgur.com/FxgpLwC.png" alt="a pipeline{} block with steps section"></p>
<h3 id="Directives"><a href="#Directives" class="headerlink" title="Directives"></a>Directives</h3><p>Directives are supporting actors that give direction, set conditions, and provide assistance to the steps of your pipeline in order to archieve the required purpose. In the following section we will see all the <em>Directives</em> that are available to you with the Declarative Pipeline Syntax.</p>
<p><strong>environment</strong><br>The <em>environment</em> directive is used to specify a set of key value pairs that are available as environment variables for all the steps of your pipeline, or only for the steps of a specific stage, depending on where you place the <em>environment</em> directive.</p>
<p><img src="https://i.imgur.com/g07NWDy.png" alt="pipeline block with environment section"></p>
<p><strong>options</strong><br>The <em>options</em> directive allows you to define pipeline-specific <em>options</em> from within the pipeline.</p>
<ol>
<li><p>buildDiscarder<br>Allows you to keep a certain number of recent builds run.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Will keep the last 10 Pipeline logs and artifacts in Jenkins.</span><br><span class="line">options &#123;</span><br><span class="line">   biuldDiscarder(logRotator(numToKeepStr: &apos;10&apos;))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>disableConcurrentBuilds<br>Disallows concurrent executions of the Pipeline.<br>To understand the usage of this option, imagine a situation. You have a Pipeline in Jenkins Blue Ocean that’s triggered on every push on your source code repository. Moreover, you have a single build agent to run your Pipeline.</p>
</li>
</ol>
<p>Now, if there are multiple pushes to the repository in a short duration of time (say three different pushes at once), then there is a pipeline for every push (say, Pipelines #1, #2, and #3). However, since we have a single build agent, Pipelines #2 and #3 wait in a queue with Pipeline #1 running. Pipelines #2 and #3 run whenever the build agent is free again.</p>
<p>To disable this functionality, and discard everything that’s in the queue, you should use the disableConcurrentBuilds option. The following option is useful to perform incremental builds.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">options &#123;    </span><br><span class="line">   disableConcurrentBuilds ()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ol start="3">
<li>newContainerPerStage</li>
</ol>
<p>The <em>newContainerPerStage</em> option is used inside an agent section that employs the docker or dockerfile parameters.</p>
<p>When specified, each stage runs in a new container on the same docker host, as opposed to all stages utilizing the same container.</p>
<p>This option only works with an <em>agent</em> section defined at the top-level of your <em>Pipeline {}</em> block.</p>
<ol start="4">
<li>preserveStashes<br>In Jenkins, you can pass artifacts between stages. You do it using stash. The <em>preserveStashes</em> option allows you to preserve stashes of the completed Pipelines. It’s useful if you have to re-run a stage from a completed Pipeline.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Preserver stashes from the most recent completed Pipeline.</span><br><span class="line">options &#123;</span><br><span class="line">   perserveStashes()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>or<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Preserve stashes from the ten most recent completed Pipelines.</span><br><span class="line">options &#123;</span><br><span class="line">   perserveStashes(10)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ol start="5">
<li><p>retry<br>The retry option allows you to retry a Pipeline, or a stage, on failure.<br><img src="https://i.imgur.com/ifB8mza.png" alt="retry"></p>
</li>
<li><p>skipDefaultCheckout<br>The <em>skipDefaultCheckout</em> option is another handy choice. In Jenkins Declarative Pipeline, the source code by default gets checked out in every <em>stage</em> directive of a Pipeline.</p>
</li>
</ol>
<p>Use this option to skip checking out source code in a given <em>stage</em> directive.</p>
<p><img src="https://i.imgur.com/hLjjGBF.png" alt="block with skipDefaultCheckout options"></p>
<ol start="7">
<li>timeout<br>The <em>timeout</em> option allows you to set a timeout period for your Pipeline run. If the pipeline run teimes out the duration defined using a <em>timeout</em>, Jenkins aborts the Pipeline.</li>
</ol>
<p>It is possible to use the timeout option at the Pipeline or stage level.</p>
<p><img src="https://i.imgur.com/Kv5XzMK.png" alt="timeout option"></p>
<p>There are times when a pipeline that’s waiting for a process runs forever, generating huge logs and bringing down Jenkins server. The timeout option comes handy in such cases.</p>
<ol start="8">
<li>timestamps<br>The <em>timestamps</em> option prepend all lines of the console log with a timestamp. The following option is useful in debugging issues where you would need the time of execution of a specific command as evidence.</li>
</ol>
<p>It is possible to use the <em>timestamps</em> option at the Pipeline or stage level.</p>
<p><img src="https://i.imgur.com/QBq3HBf.png" alt="timestamps"></p>
<h3 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h3><p>The <em>parameters</em> directive allows a user to provide a list of specific parameters when triggering a Pipeline.</p>
<p>Following are the types of available parameters that I find useful.</p>
<ol>
<li>string</li>
</ol>
<p>Use the <em>string</em> parameter to pass a string.<br><img src="https://i.imgur.com/QIBJjWM.png" alt="string"></p>
<ol start="2">
<li>text</li>
</ol>
<p>Use the <em>text</em> parameter to pass a multiline text.<br><img src="https://i.imgur.com/vSrmP5T.png" alt="text"></p>
<ol start="3">
<li>booleanParam</li>
</ol>
<p>Use the <em>booleanParam</em> parameter to pass true for false.<br><img src="https://i.imgur.com/AVmdPvS.png" alt="booleanParam"></p>
<ol start="4">
<li>choice</li>
</ol>
<p>Use the <em>choice</em> parameter to allow you to choose from a set of values, and them pass it to the pipeline<br><img src="https://i.imgur.com/bzZ8FsZ.png" alt="choice"></p>
<ol start="5">
<li>file</li>
</ol>
<p>A <em>file</em> parameter allows you to specify a file to upload that your pipeline might require.<br><img src="https://i.imgur.com/zXmC4BJ.png" alt="file"></p>
<h3 id="Triggers"><a href="#Triggers" class="headerlink" title="Triggers"></a>Triggers</h3><p>The <em>triggers</em> directive defines the various ways to rigger a pipeline.</p>
<p>Pipelines created using Jenkins Blue Ocean may not require triggers, since such Pipelines are triggered using webhooks configured on the source code repository (Git/GitHub/GitLab).</p>
<p>Following are the two triggers directives that might be useful, in some scenarios, for your Continuous Delivery pipeline.</p>
<ol>
<li><p>cron<br>The <em>cron</em> trigger accepts a cron-style string to define a regular interval at which the piepleine shoulde be re-triggered, for example:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    triggers &#123;</span><br><span class="line">       cron(&apos;H */4 * * 1-5&apos;)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&apos;Long running test&apos;) &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">             // Do something</span><br><span class="line">          &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>upstream<br>The <em>upstream</em> trigger allows you to define a comma-sparated list of jobs and a threshold. When any of the jobs from the list finishes with the defined threshold, your pipeline gets triggererd. This feature is useful if your CI and CD Pipelines are two separate Jenkins Pipelines.<br><img src="https://i.imgur.com/TOK46DZ.png" alt="upstream"></p>
</li>
</ol>
<h3 id="Stage"><a href="#Stage" class="headerlink" title="Stage"></a>Stage</h3><p>A pipeline stage contains one or more <em>steps</em> to achieve a task, for example: Build, Unit-Test, Staic Code Analysis, etc. The <em>stage</em> directive contains one or more <em>steps</em> sections, an <em>agent</em> section (optional), and other stage-related directives.<br>In the previous sections, you have already seen many examples demonstrating the stage directive. It is possible to run multiple stage directives in sequence, in parallel, or a combination of both. You’ll see it shortly.</p>
<h3 id="tools"><a href="#tools" class="headerlink" title="tools"></a>tools</h3><p>A <em>tools** directive allows you to install a tool on your agent automatically. It can be defined inside a </em>pipeline {}<em> or a </em>stage {}* block.<br><img src="https://i.imgur.com/NtZHRhQ.png" alt=""></p>
<p>For the tools directive to work, the respective tool must be pre-configured in Jenkins under <strong>Manage Jenkins</strong>-&gt; <strong>Global Tool Configuraton</strong>. However, the tools directive gets ingnored if you put an <em>agent none</em> section in the <em>pipeline {}</em> block.</p>
<p>As of today, only the following tools work in Declarative Pipeline:</p>
<ul>
<li>maven</li>
<li>jdk</li>
<li>gradle</li>
</ul>
<h3 id="input"><a href="#input" class="headerlink" title="input"></a>input</h3><p>The <em>input</em> directive allows the Pipleine to prompt for input. The <em>input</em> directive works with the <em>stage</em> directive. When used, the <em>stage</em> directive pauses and wait for your input, and when you provide the input, the stage then continues to run.<br><img src="https://i.imgur.com/qrWOh2L.png" alt="input options table"></p>
<p><img src="https://i.imgur.com/AQuF2fa.png" alt="input code"></p>
<h3 id="when"><a href="#when" class="headerlink" title="when"></a>when</h3><p>The <em>when</em> directive allows your Pipeline to decide whether a <em>stage</em> directive should be run based on some conditions.</p>
<p>The <em>when</em> directive must contain at least one condition. If the <em>when</em> directive contains more than one condition, all the chould conditions must return true for the stage to execute.</p>
<ol>
<li>branch<br>Run a <em>stage</em> directive only if the branch that’s being built matches the branch pattern provided.<br><img src="https://i.imgur.com/ofJR2Gl.png" alt="branch condition"></li>
</ol>
<p>The <em>Performance Testing</em> stage in this Pipeline runs for all branches that start with a <em>release</em>-string. Example: <em>release-beta, release-1.0.0.1</em>.</p>
<ol start="2">
<li><p>buildingTag<br>The <em>buildingTag</em> option allows you to run a stage only if the Pipeline is building a tag.<br><img src="https://i.imgur.com/378lFdP.png" alt="buildingTag"></p>
</li>
<li><p>tag<br>The <em>tag</em> option allows you to run a <em>stage</em> directive only if the <em>TAG_NAME</em> variable matches the pattern provided.</p>
</li>
</ol>
<p>If you provide an empty pattern, and your Pipeline is building some tag, then the <em>tag</em> option behaves the same as a <em>buildingTag()</em>.</p>
<p><img src="https://i.imgur.com/JZ4zMRT.png" alt="tag"></p>
<p>To the <em>tag</em> option, you can add a <em>comparator</em> parameter to define how a given pattern must get evaluated. The options for the <em>comparator</em> parameter include <em>EQUALS</em> for simple string comparison, <em>GLOB</em> (the default) for an ANT style path glob, <em>orREGEXP</em> for regular expression matching.</p>
<p><img src="https://i.imgur.com/JbP9Liu.png" alt="comarator"></p>
<p>The Publish stage in the above Pipeline runs if the tags being built match anything between release-0.0.0.0-nightly and release-9.9.9.9-nightly.</p>
<ol start="4">
<li>changelog<br>The <em>changelog</em> option allows you to execute a <em>stage</em> directive only if the Pipeline’s SCM changelog contains a specific regular expression pattern. The SCM changelog contains information about the list of modified files, the branch of the repository where the respective files were modified, the user who made the changes, and more.</li>
</ol>
<p><img src="https://i.imgur.com/9uUBGHD.png" alt="changelog"></p>
<ol start="5">
<li>changeset<br>The <em>changeset</em> option allows you to execute a <em>stage</em> directive if the Pipeline’s SCM changeset contains one or more files matching the given string or glob. The SCM changeset is a list of modified files relating to a commit.</li>
</ol>
<p><img src="https://i.imgur.com/13dSS1R.png" alt="changeset"></p>
<p>By default the matching is case-insensitive; to make case-sensitive, use the <em>caseSensitive</em> parameter.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">when &#123; changeset glob: &quot;Simlulator_SAS.*&quot;, caseSensitive: true &#125;</span><br></pre></td></tr></table></figure></p>
<ol start="6">
<li>environment<br>The <em>environment</em> option allows you to execute a <em>stage</em> directive only when a specific environment variable is set to the given value. To give you an example use-case, let us assume that you have multiple geographical regions where you are required to deploy your successfully tested artifacts—let’s say, apac and japac. And, for all these environments, the deployment steps are different. So, using the <em>when</em> directive with <em>environment</em> condition, you can design your pipeline as shown here.</li>
</ol>
<p><img src="https://i.imgur.com/9vXmWEx.png" alt="environment"></p>
<ol start="7">
<li>equals<br>The <em>equals</em> option allows you to execute a <em>stage</em> directive only when an expected value equals the real value.</li>
</ol>
<p><img src="https://i.imgur.com/nT7HPpR.png" alt="equals"></p>
<ol start="8">
<li><p>expression<br>The <em>expression</em> option allows you to run a stage only when the specified Groovy expression holds true.<br><img src="https://i.imgur.com/xRBayPL.png" alt="expression"></p>
</li>
<li><p>not<br>Use the <em>not</em> option to execute a <em>stage</em> directive when all of the nested conditions are true and must contain at least one condition.<br><img src="https://i.imgur.com/QOlR9f3.png" alt="not"></p>
</li>
<li><p>allOf<br>Use the <em>allOf</em> option to execute a <em>stage</em> directive when all of the nested conditions are true and must contain at least one condition.<br><img src="https://i.imgur.com/JKFI18a.png" alt=""></p>
</li>
<li><p>anyOf<br>Use the <em>anyOf</em> option to execute a <em>stage</em> directive when at least one of the nested conditions are true and must contain at least one condition.</p>
</li>
</ol>
<p><img src="https://i.imgur.com/r9Lcscp.png" alt=""></p>
<ol start="12">
<li>Evaluate When Before Entering the Stage’s Agent<br>By default the when condition for a stage directive gets evaluated after entering the agent defined for the stage.To change this behavior, use the beforeAgent option within the when {} block.</li>
</ol>
<p><img src="https://i.imgur.com/pcRUia1.png" alt=""></p>
<h2 id="Sequentail-stages"><a href="#Sequentail-stages" class="headerlink" title="Sequentail stages"></a>Sequentail stages</h2><p>Multiple <em>stage</em> directives in Declarative Pipeline can be defined in sequence. A <em>stage</em> directive can contain only one <em>steps {}, parallen {},</em> or <em>stages {}</em> block.</p>
<ol>
<li>Simple Sequential Stages<br><img src="https://i.imgur.com/HqdwQaB.png" alt="Simple sequential stages figure"></li>
</ol>
<p><img src="https://i.imgur.com/lbHccu0.png" alt="Simple sequential stages code"></p>
<p>The <em>pipeline {}</em> block compulsory has a <em>stages {}</em> block. All the <em>stage</em> directives that should run in the sequence are defined inside the <em>stages {}</em> block, one after the other.</p>
<ol start="2">
<li>Nested sequential stages<br>In Declarative Pipeline, it is possible to nest multiple stage directives that are in sequence inside another stage directive.<br><img src="https://i.imgur.com/yLSxMZI.png" alt="Nested sequential stages figure"><br><img src="https://i.imgur.com/8iAt69F.png" alt="Nested sequential stages code"><br>Notice the two <em>stage</em> directives that are in sequence (highlighted in bold) are not placed directly inside the parent <em>stage (‘Stage 1.2’) {…}</em> block. But, they are first added to a <em>stages {}</em> block, which is them placed inside the <em>stage (‘Stage 1.2’) {…}</em> block.</li>
</ol>
<h2 id="Parallel-stages"><a href="#Parallel-stages" class="headerlink" title="Parallel stages"></a>Parallel stages</h2><p>It is possible to define multiple <em>stage</em> directives in Declarative Pipeline to run in parallel with one another.<br>A <em>stage</em> directive can contain only one <em>steps {}, parallen {},</em> or <em>stages {}</em> block. Also, the nested stages cannot contain further parallel stages.</p>
<p>A <em>stage</em> directive that contains a <em>parallen {}</em> block cannot contain <em>agent</em> or <em>tools</em> sections since they are not applicable without the <em>steps {}</em> block.</p>
<ol>
<li>Simple parallel stages<br><img src="https://i.imgur.com/7fqNbdX.png" alt="Simple parallel stages figure"><br><img src="https://i.imgur.com/rc05gg4.png" alt="Simple parallel stages code"><br>The pipeline {} block compulsory has a stages {} block. All the stage directives that should run in parallel are defined one after the other inside a parallel {} block. The parallel {} block is then defined inside the parent stage {} block.</li>
<li>Nested parallel stages<br>In Declarative Pipeline, it is possible to nest multiple stage directives that are in parallel inside another stage directive.<br><img src="https://i.imgur.com/82ksxy9.png" alt="Nested parallel stages figure"><br><img src="https://i.imgur.com/KIxaHqF.png" alt="Nested parallel stages code "></li>
</ol>
<h2 id="STEPS"><a href="#STEPS" class="headerlink" title="STEPS"></a>STEPS</h2><p>There are a large number of steps available for Jenkins. You can find them at <a href="https://jenkins.io/doc/pipeline/steps/">https://jenkins.io/doc/pipeline/steps/</a></p>
<p>Every new Jenkins Plugin that’s compatible with the Scripted Pipeline adds a new step to the list of steps. However, not all of the steps available for Jenkins are compatible with the Declarative Pipeline. The ones that are compatible are available as a step inside the Visual Pipeline Editor.</p>
<p>To make the incompatible steps work with Declarative Pipeline, you need to enclose them inside the script {} block, also called the script step.</p>
<p>However, if you are creating a pipeline using the Visual Pipeline Editor, the script step is available as Run Arbitrary Pipeline Script inside the list of Steps.</p>
<h2 id="Script"><a href="#Script" class="headerlink" title="Script"></a>Script</h2><p>In simple terms, the script {} block allows you to execute a Scripted Pipeline inside a Declarative Pipeline.</p>
<p><img src="https://i.imgur.com/Gm6EcNy.png" alt="script"></p>
<p>There is no limit to the size of Scripted Pipeline you can run inside the script {} block. However, it is recommended to move anything bigger than a few lines to Shared Libraries. Also, any piece of code that is common across multiple pipelines must be moved to Shared Libraries.In the final chapter, you’ll learn to extend your Jenkins Blue Ocean pipelines or, shall we say, the Declarative Pipeline, using the script step and Shared Libraries.</p>
<h1 id="Shared-Library"><a href="#Shared-Library" class="headerlink" title="Shared Library"></a>Shared Library</h1><p>A Jenkins Shared Library is an external source control repository containing your complex Groovy code. It acts like a function that could be used on-demand inside your Declarative Pipeline.</p>
<p><em>A Groovy Script (example.groovy)Inside Jenkins Shared Library Repository:</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def greet(message) &#123;</span><br><span class="line">   echo &quot;Hello $&#123;message&#125;, welcome to Jenkins Blue Ocean.&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>Jenkins Declarative Pipeline Utilizing the Shared Library:</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@Library(&apos;Example_shared_Library&apos;) _</span><br><span class="line"></span><br><span class="line">pipeline &#123;</span><br><span class="line">  agent none</span><br><span class="line">  stage (&apos;Example&apos;) &#123;</span><br><span class="line">     steps &#123;</span><br><span class="line">        script &#123;</span><br><span class="line">           example.greet &apos;Readers&apos;</span><br><span class="line">        &#125;</span><br><span class="line">     &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Setting-up-Jenkins-Blue-Ocean"><a href="#Setting-up-Jenkins-Blue-Ocean" class="headerlink" title="Setting up Jenkins Blue Ocean"></a>Setting up Jenkins Blue Ocean</h1><h2 id="Setting-up-Blue-Ocean-using-docker"><a href="#Setting-up-Blue-Ocean-using-docker" class="headerlink" title="Setting up Blue Ocean using docker"></a>Setting up Blue Ocean using docker</h2><p><strong>Downloading the latest Jenkins Blue Ocean</strong></p>
<ol>
<li><p>docker pull jenkinsci/blueocean</p>
</li>
<li><p>To list the downloaded docker image: docker images</p>
</li>
</ol>
<p>Docker containers generate and use data. When a container gets deleted, its relevant data also gets lost.<br>To make the data persistent, we use docker volumes.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker volume create jenkins_home</span><br><span class="line">docker volume ls</span><br><span class="line">docker volume inspect jenkins_home <span class="comment">#get detailed info about docker volume</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Run-Jenkins-blue-ocrean-behind-a-reverse-proxy"><a href="#Run-Jenkins-blue-ocrean-behind-a-reverse-proxy" class="headerlink" title="Run Jenkins blue ocrean behind a reverse proxy"></a>Run Jenkins blue ocrean behind a reverse proxy</h2><ol>
<li><p>Run a Jenkins container</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name jenkins -v jenkins_home:/var/jenkins_home jenkinsci/blueocean</span><br></pre></td></tr></table></figure>
</li>
<li><p>Download the docker image for Nginx</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p>Spawn a Dockr container for Nginx. Also, link the nginx container to the jenkins container using the <em>–link</em> option.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name ngingx -p 80:80 --link jenkins nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p>Get inside the Ningx container using the <em>docker exec</em> command</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it ningx /bin/bash</span><br></pre></td></tr></table></figure>
</li>
<li><p>Update the Ubuntu package lists<br><code>apt-get update</code></p>
</li>
<li>Install vim text editor<br><code>apt-get install vim</code></li>
<li><p>Take the backup of the default.conf file inside /etc/nginx/conf.d/</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp etc/ningx/conf.d/default.conf etc/nginx/conf.d/default.conf.backup</span><br></pre></td></tr></table></figure>
</li>
<li><p>Next, replace the content of the default.conf file with the following:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">upstream jenkins &#123;</span><br><span class="line">  server jenkins:8080;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">  listen 80;</span><br><span class="line">  server_name jenkins.example.com;</span><br><span class="line">  </span><br><span class="line">  location / &#123;</span><br><span class="line">     proxy_pass         http://jenkins;</span><br><span class="line">     proxy_set_header   Host <span class="variable">$host</span>;</span><br><span class="line">     proxy_set_header   X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">     proxy_set_header   X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">     proxy_set_header   X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Exit the Nginx container.<br><code>exit</code></p>
</li>
<li>Restart the Nginx container.<br><code>docker restart nginx</code></li>
<li>Run the following docker command to fetch the content of initialAdminPassword file.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it jenkins /bin/bash -c \ <span class="string">"cat /var/jenkins_home/secrets/initialAdminPassword"</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Creating-Pipeline"><a href="#Creating-Pipeline" class="headerlink" title="Creating Pipeline"></a>Creating Pipeline</h1><p><strong>Prerequisites</strong>     </p>
<ol>
<li>fork <a href="https://github.com/Apress/beginning-jenkins-blue-ocean/tree/master/Ch03/example-maven-project">example maven project</a></li>
<li>pulling the docker image for jenkins agent<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nikhilpathania/jenkins_ssh_agent</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The docker image is based on Ubuntu and comes with Git,Java JDK, Maven, and sshd installed.<br>The image also contains a user account named <em>jenkins</em>.</p>
<p><strong>Creating credentials for the docker image in Jenkins</strong><br>Add credentials inside Jenkins that allow it to interact with the docker image nikhilpathania/jenkins_ssh_agent</p>
<ol>
<li>Classic Jenkins dashboard -&gt; Credentials-&gt; System-&gt; Global credential (unrestricted).</li>
<li>Add Credentials</li>
<li>Options<ol>
<li>Kind: Username with password</li>
<li>Username: the username to interact with the docker image: jenkins</li>
<li>Password: the password to interact with the docker image: jenkins</li>
<li>ID: add a meaningful name to recognize these credentials.</li>
<li>Descritpion: Add a meaningful description for these credentials.<br><img src="https://i.imgur.com/pFaHQuZ.png" alt="configuring the credential"><br><strong>Installing the docker plugin</strong><br>To spawn on-demand docker containers serving as Jenkins agents, need to install the docker plugin<br><img src="https://i.imgur.com/nUi1uKk.png" alt="Installing the Docker Plugin for Jenkins">   </li>
</ol>
</li>
</ol>
<p><strong>Configuring the docker plugin</strong><br>Manage Jenkins-&gt; Configure System-&gt; Cloud-&gt; Add a new cloud-&gt; Docker</p>
<p>Options to configure:</p>
<ol>
<li>Docker Host URI: This is the URL used by Jenkins to talk to the docker host.</li>
</ol>
<hr>
<p><strong>ENABLING DOCKER REMOTE API (CRITICAL)</strong><br>The Docker remote API allows external applications to communicate with the Docker server using REST APIs . Jenkins (through the Docker Plugin) uses the docker remote API to communicate with a docker host.</p>
<p>To enable the Docker remote API on your Docker host, you’ll need to modify Docker’s configuration file. Depending on your OS version and the way you have installed Docker on your machine, you might need to choose the right configuration file to modify. Shown here are two methods that work on Ubuntu. Try them one by one.</p>
<p><strong>Modifying the docker.conf File</strong><br>Follow these steps to modify the docker.conf file :</p>
<ol>
<li>Log in to your docker server; make sure you have sudo privileges.</li>
</ol>
<ol start="2">
<li>Execute the following command to edit the file docker.conf :</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /etc/init/docker.conf</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>Inside the docker.conf file, go to the line containing “DOCKER_OPTS=” .</li>
</ol>
<p>You’ll find “DOCKER_OPTS=” variable at multiple places inside the docker.conf file. Use the DOCKER_OPTS= that is available under the pre-start script or script section.</p>
<ol start="4">
<li>Set the value of DOCKER_OPTS as shown here. Do not copy and paste; type it all in a single line.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DOCKER_OPTS=&apos;-H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock&apos;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The above setting binds the Docker server to the UNIX socket as well on TCP port 4243.</p>
<p>“0.0.0.0” makes Docker engine accept connections from anywhere. If you would like your Docker server to accept connections only from your Jenkins server, then replace “0.0.0.0” with your Jenkins Server IP.</p>
<ol start="5">
<li>Restart the Docker server using the following command:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="6">
<li>To check if the configuration has worked, execute the following command. It lists all the images currently present on your Docker server.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X GET http://&lt;Docker Server IP&gt;:4243/images/json</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="7">
<li>If this command does not return a meaningful output, try the next method.</li>
</ol>
<p><strong>Modifying the docker.service File</strong><br>Follow these steps to modify the docker.service file :</p>
<ol>
<li>Execute the following command to edit the docker.service file.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /lib/systemd/system/docker.service</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="2">
<li>Inside the docker.service file, go to the line containing ExecStart= and set its value as shown here. Do not copy and paste; type it all in a single line.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ExecStart=/usr/bin/dockerd -H fd:// -H tcp://0.0.0.0:4243</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The above setting binds the docker server to the UNIX socket as well on TCP port 4243.</p>
<p>“0.0.0.0” makes the Docker engine accept connections from anywhere. If you would like your Docker server to accept connections only from your Jenkins server, then replace “0.0.0.0” with your Jenkins Server IP.</p>
<ol start="3">
<li>Execute the following command to make the Docker demon notice the modified configuration:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="4">
<li>Restart the Docker server using the below command:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="5">
<li>To check if the configuration has worked, execute the following command. It lists all the images currently present on your Docker server.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X GET http://&lt;Docker Server IP&gt;:4243/images/json</span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<ol start="2">
<li>Server Credentials: If your docker host requireds a login, you need to add the credentials to Jenkins using the <strong>Add</strong> button. However, do nothing if you are using a docker host that’s running your Jenkins server container.</li>
<li>Test Connection: Click on this to test the communication between your Jenkins server and the docker host. You should see the docker version and the API version [4] if the connection is successful.</li>
<li>Enabled: A checkbox to enable/disable the current configuration.<br><img src="https://i.imgur.com/RKOm2V2.png" alt="Configuring the Docker host URI and testing the connection"></li>
</ol>
<p><strong>Add Docker Template</strong> button. Click on it to configure the docker image that Jenkins shoudl use to spawn container.<br><img src="https://i.imgur.com/6NOb5kY.png" alt="docker template figure"></p>
<ol>
<li>Labels: The label that you type in under the Labels field gets used inside your Pipeline to define agents for your stages. In this way, Jenkins knows that it has to use docker to spawn agents. </li>
<li>Enabled: This checkbox is used to enable/disable the current configuration. </li>
<li>Docker Image: Add the name of the docker image that should be used to spawn agents containers. </li>
<li>Remote File System Root: This is the directory inside the container that holds the workspace of the Pipeline that runs inside it. </li>
<li>Usage: We would like only to build pipelines that have the right agent label, in our case it is docker.</li>
<li>Connect method : Choose to Connect with SSH option to allow Jenkins to connect with the container using the SSH protocol.</li>
<li>SSH Key: Choose use configured SSH credentials from the options to use the SSH credentials as the preferred mode of authentication.</li>
<li>SSH Credentials: From the list of options choose the credentials that you have created earlier, in the section: Creating Credentials for the Docker Image in Jenkins.</li>
<li>Host Key Verification Strategy: Choose Non verifying Verification Strategy to keep things simple. However, this is not the recommended setting for a production Jenkins server.<h1 id="Using-the-pipeline-creation-wizard-configure-Jenkins-Blue-Ocean-with-various-types-of-source-code-repositories"><a href="#Using-the-pipeline-creation-wizard-configure-Jenkins-Blue-Ocean-with-various-types-of-source-code-repositories" class="headerlink" title="Using the pipeline creation wizard, configure Jenkins Blue Ocean with various types of source code repositories."></a>Using the pipeline creation wizard, configure Jenkins Blue Ocean with various types of source code repositories.</h1><h1 id="Using-the-Visual-Pipeline-Editor-to-design-Pipeline"><a href="#Using-the-Visual-Pipeline-Editor-to-design-Pipeline" class="headerlink" title="Using the Visual Pipeline Editor to design Pipeline."></a>Using the Visual Pipeline Editor to design Pipeline.</h1></li>
</ol>
<ul>
<li>Downloads the source code from the Github repository</li>
<li>Performs a build and some testing</li>
<li>Publishes the testing results under the Pipeline’s Test page</li>
<li>Uploads the built artifact to Henkins Blue Ocean</li>
</ul>
<p><strong>Assigning a global agent</strong><br>The pipeline that you are going to create should have two stages, and each stage is supposed to run inside a docker<br>container. You’ll define the agents for each stage sparately in the stage’s settings.<br>Therefore, let’s keep the Pipeline’s global agent setting to none.<br><img src="https://i.imgur.com/fBKsY4k.png" alt="Assigning a global agent"></p>
<p><strong>Creating a build &amp; test stage</strong><br>Type in the name <strong>Build &amp; Test</strong> for your stage.<br><img src="https://i.imgur.com/SOXKlCZ.png" alt="Naming your stage"></p>
<p><strong>Adding steps</strong><br>Let’s add some steps to our <strong>Build &amp; Test</strong> stage.<br><img src="https://i.imgur.com/FR5koOy.png" alt="Adding a new step"><br><strong>Adding a shell script setp</strong><br>Our source code is a Maven project, and we would like to build and test it using an mvn command, which eventually<br>gets executed inside a shell on the Jenkins agent.<br><img src="https://i.imgur.com/zdRO91W.png" alt="Adding a shell script step"><br>Paste the below code which is a maven command to build, test, and create a package out of your source code.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn -Dmaven.test,failure,ignore clean package</span><br></pre></td></tr></table></figure></p>
<p><strong>Adding a stash step to pass artifact between stages</strong><br>Add another step to stash the build package and the testing report generated by the maven command.<br>Look for the step <strong>Stash some files to be used later in the build</strong><br><img src="https://i.imgur.com/yguB0hB.png" alt="Adding a Stash step"></p>
<p>Add the name “build-test-artifacts” fro your stash using the Name<em> field, which is mandatory.<br>Add the following to the Included field: **/target/surefire-reports/TEST-</em>.xml,target/*.jar</p>
<p>With this configuration you are telling Jenkins to stash any .jar file (build package) from the target directory,<br>and the TEST-*.xml file(test report) from the <code>**/target/surefire-reports/</code> directory on the build agent.<br><img src="https://i.imgur.com/ZtwyY00.png" alt="configuring a Stash step"></p>
<p>piple line code so far:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent none</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(&apos;Build &amp; Test&apos;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &apos;mvn -Dmaven.test.failure.ignore clean package&apos;</span><br><span class="line">                stash(name: &apos;build-test-artifacts&apos;, \</span><br><span class="line">                includes: &apos;**/target/surefire-reports/TEST-*.xml,target/*.jar&apos;)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>Assigning an agent for the build &amp; test stage</strong><br>You’ll assign a build agent for your <strong>Build &amp; Test</strong> stage. The agent is going to be a docker container that will be spawn automatically by Jenkins. ONce the stage is complete, Jenkins will destroy the container.<br><img src="https://i.imgur.com/8QGv9eH.png" alt="assigning an agent to a stage"><br>With the following configuration, Jenkins looks for an agent with the label <strong>docker</strong>. Remember the section, wherein you configured the docker plugin in Jenkins. You specified the label <strong>docker</strong> while configure the <strong>Docker Agent<br>Template</strong>.</p>
<p><strong>Creating a report &amp; publish stage</strong><br>Add another stage named <strong>Report &amp; Publish</strong> that will publish the testing results on the <strong>Test</strong> page of the Pipeline and that will publish the build package on the <strong>Artifacts</strong> page of the pipeline.<br><img src="https://i.imgur.com/1wyyhNT.png" alt="Naming your stage"></p>
<p><strong>Adding an un-stash step</strong><br>Before we do anything in the <strong>Report &amp; Publish</strong> stage. it is first crucial to un-stash the files that were stashed<br>in the previous stage. So let’s add step to un-stash a stash from the previous stage.<br><img src="https://i.imgur.com/e0XDMmW.png" alt="Adding a restore files previously stashed step"><br>You’ll see a text field Name* where you should paste the name of your stash precisely as it was defined during its<br>creation.<br><img src="https://i.imgur.com/O5Do1D7.png" alt="Configuring the Restore files previously stashed step"></p>
<p><strong>Report testing results</strong><br>The stash contains a JUnit test results .xml file that you’ll publish on the pipeline’s Test page. For this, we need<br>to add a step named <strong>Archive Junit-formatted test results</strong></p>
<p>Use the TestResults<em> field to provide Jenkins with the path to your JUnit test result file. In our case, it is<br>`**/target/surefire-reports/TEST-</em>.xml`</p>
<p><img src="https://i.imgur.com/Skz6Yg7.png" alt="Configuring an Archive Junit-formatted test results step"></p>
<p><strong>Upload artifacts to blue ocean</strong><br>Add a step that will upload the build package to the Pipleine’s Artifacts page. From the un-stashed files, you also<br>have a .jar file that is the build package.</p>
<p>To upload it to the Pipeline Artifacts page, use the <strong>Archive the artifacts</strong> step.<br>Use the Artifacts<em> filed to provide Jenkins with the path to your build package file. In our case, it is target/</em>.jar.Also, tick the option OnlyIfSuccessful to upload the artifacts only if the Pipeline status is green or yellow.<br><img src="https://i.imgur.com/X1ogakY.png" alt="Configuring the Archive the Artifacts step"> </p>
<p><strong>Assigning an aget for the report &amp; publish stage</strong><br>you’ll assign a build agent for your Report &amp; Publish stage. The agent is going to be a docker container that will be spawn automatically by Jenkins. Once the stage is complete, Jenkins will destroy the container.</p>
<p><img src="https://i.imgur.com/zg4Jc5G.png" alt="Assigning an agent to a stage"></p>
<p>You are new done with creating the pipeline. To save the changes, click on the Save button.</p>
<p>When you click on the <strong>Save</strong> button, Jenkins in the back end converts your UI configurations into a Jenkinsfile that follows the Declarative Pipeline Syntax.</p>
<p><img src="https://i.imgur.com/2HYkBP5.png" alt="Committing your pipeline configurations changes"></p>
<p><strong>Run an artifactory server</strong><br>To spawn an Artifactory server with docker. Artifactory is a popular tool to manage and version control software build artifacts. </p>
<ol>
<li>Log in to your docker host</li>
<li>docker volume create –name artifactory_data</li>
<li>docker pull docker.bintray.io/jfrog/artifactory-oss:latest  # downloading the latest version of Artifactory community edition</li>
<li>docker run –name artifactory -d -v artifactory_data:/var/opt/jfrog/ -p 8081:8081 docker.bintray.io/jfrog/artifactory-oss:latest</li>
<li>access your Artifactory server: http://&lt;Docker_host_ip&gt;:8081/artifactory/webapp/#/home</li>
<li>using the admin credentials (username: admin, and password as password). Note the default example repository in Artifactory named example-repo-local.</li>
</ol>
<p><strong>Installing the artifactory plugin for jenkins</strong><br>Manage Jenkins-&gt; Manage Plugins-&gt; Artifactory</p>
<p><strong>Configuring the artifactory plugin in jenkins</strong><br><img src="https://i.imgur.com/2HYkBP5.png" alt="configuring the artifactory plugin"></p>
<p><strong>Creating a Publish to Artifactory Stage (Parallel Stage)</strong><br>Add a stage in parallel to existing <strong>Report &amp; Publish</strong> stage.<br><img src="https://i.imgur.com/HAq6sYq.png" alt="creating a new stage"><br><img src="https://i.imgur.com/vXUpngZ.png" alt="naming your stage"><br>Your new stage first downloads the stash files from the previous stage, and then it publishes the built artifacts to<br>the Artifactory server.</p>
<p><strong>Adding a scripted pipeline step</strong><br>does two things</p>
<ol>
<li>it fetches the stash files from the previous stage.</li>
<li>it runs a filespec that uploads the build package to the Artifactory server.<br><img src="https://i.imgur.com/9W9fTUQ.png" alt="add a scripted pipeline step"><br>Script to Un-Stash Built Artifacts and Upload Them to the Artifactory Server<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">unstash &apos;build-test-artifacts&apos;</span><br><span class="line">def server = Artifactory.server &apos;Artifactory&apos;</span><br><span class="line">def uploadSpec = &quot;&quot;&quot;&#123;</span><br><span class="line">  &quot;files&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;pattern&quot;: &quot;target/*.jar&quot;,</span><br><span class="line">      &quot;target&quot;: &quot;example-repo-local/$&#123;BRANCH_NAME&#125;/$&#123;BUILD_NUMBER&#125;/&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;&quot;&quot;&quot;</span><br><span class="line">server.upload(uploadSpec)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">███████╗██╗  ██╗██████╗ ██╗      █████╗ ██╗███╗   ██╗</span><br><span class="line">██╔════╝╚██╗██╔╝██╔══██╗██║     ██╔══██╗██║████╗  ██║</span><br><span class="line">█████╗   ╚███╔╝ ██████╔╝██║     ███████║██║██╔██╗ ██║</span><br><span class="line">██╔══╝   ██╔██╗ ██╔═══╝ ██║     ██╔══██║██║██║╚██╗██║</span><br><span class="line">███████╗██╔╝ ██╗██║     ███████╗██║  ██║██║██║ ╚████║</span><br><span class="line">╚══════╝╚═╝  ╚═╝╚═╝     ╚══════╝╚═╝  ╚═╝╚═╝╚═╝  ╚═══╝</span><br></pre></td></tr></table></figure>
<p>The code line unstash ‘build-test-artifacts’ downloads the previously stashed package. The rest of the code is a Filespec that uploads the target/*jar file, which is our built package file, to the Artifactory server on the repository example-repo-local.</p>
<p>Notice that the target path contains Jenkins Global variables, ${BRANCH_NAME} and ${BUILD_NUMBER}, representing the branch name and build number, respectively. Doing so uploads the built artifacts to a unique path on Artifactory every single time a pipeline runs.</p>
<p><strong>Assigning an Agent for the Publish to Artifactory Stage</strong><br>you’ll assign a build agent for your Publish to Artifactory stage. The agent is going to be the docker container that gets spawned automatically by Jenkins. Once the stage is complete, Jenkins destroys the container.<br><img src="https://i.imgur.com/l3VMpHu.png" alt="Assigning an agent to a stage"></p>
<p>Final pipeline code:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  agent none</span><br><span class="line">  stages &#123;</span><br><span class="line">    stage(&apos;Build &amp; Test&apos;) &#123;</span><br><span class="line">      agent &#123;</span><br><span class="line">        node &#123;</span><br><span class="line">          label &apos;docker&apos;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">      steps &#123;</span><br><span class="line">        sh &apos;mvn -Dmaven.test.failure.ignore clean package&apos;</span><br><span class="line">        stash(name: &apos;build-test-artifacts&apos;, includes: &apos;**/target/surefire-reports/TEST-*.xml,target/*.jar&apos;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(&apos;Report &amp; Publish&apos;) &#123;</span><br><span class="line">      parallel &#123;</span><br><span class="line">        stage(&apos;Report &amp; Publish&apos;) &#123;</span><br><span class="line">          agent &#123;</span><br><span class="line">            node &#123;</span><br><span class="line">              label &apos;docker&apos;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">          steps &#123;</span><br><span class="line">            unstash &apos;build-test-artifacts&apos;</span><br><span class="line">            junit &apos;**/target/surefire-reports/TEST-*.xml&apos;</span><br><span class="line">            archiveArtifacts(artifacts: &apos;target/*.jar&apos;, onlyIfSuccessful: true)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&apos;Publish to Artifactory&apos;) &#123;</span><br><span class="line">          agent &#123;</span><br><span class="line">            node &#123;</span><br><span class="line">              label &apos;docker&apos;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">          steps &#123;</span><br><span class="line">            script &#123;</span><br><span class="line">              unstash &apos;build-test-artifacts&apos;</span><br><span class="line"></span><br><span class="line">              def server = Artifactory.server &apos;Artifactory&apos;</span><br><span class="line">              def uploadSpec = &quot;&quot;&quot;&#123;</span><br><span class="line">                &quot;files&quot;: [</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;pattern&quot;: &quot;target/*.jar&quot;,</span><br><span class="line">                    &quot;target&quot;: &quot;example-repo-local/$&#123;BRANCH_NAME&#125;/$&#123;BUILD_NUMBER&#125;/&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                ]</span><br><span class="line">              &#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">              server.upload(uploadSpec)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><img src="https://i.imgur.com/id9vL50.png" alt="Committing your pipeline configurations changes"><br><img src="https://i.imgur.com/Ec4LinF.png" alt="build artifact uploaded to Artifactory"></p>
<p><strong>Running a pipeline for a pull requrest</strong><br>Jenkins Blue Ocean can detect pull requests on your Github repositories and run a pipeline with it for you. The<br>pipeline run result (fail/pass/canceled) gets reported back to your source code repository.</p>
<p>The person who is reponsible for accepting the pull request can then decide based on the pipeline run result whether<br>he should merge the new changes into the destination branch or not.<br><img src="https://i.imgur.com/kUvGGZM.jpg" alt="pull request"></p>
<h2 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h2><p>pull requests not showing<br>fix by: <img src="https://i.imgur.com/63ETSbk.png" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Jenkins/">Jenkins</a><a href="/tags/Devops/">Devops</a><a href="/tags/CD-CI/">CD/CI</a><a href="/tags/Pipeline/">Pipeline</a><a href="/tags/Blue-Ocean/">Blue Ocean</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/23/LinuxSystemAdmin/" title="LinuxSystemAdmin" itemprop="url">LinuxSystemAdmin</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-22T23:00:22.000Z" itemprop="datePublished"> Published 2019-07-23</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="TCP-IP-networking"><a href="#TCP-IP-networking" class="headerlink" title="TCP/IP networking"></a>TCP/IP networking</h1><h2 id="Troubleshoot-networking"><a href="#Troubleshoot-networking" class="headerlink" title="Troubleshoot networking"></a>Troubleshoot networking</h2><p><strong>Tools for troubleshooting the network</strong></p>
<ul>
<li><em>ping</em> - ICMP echo requests<br><img src="https://i.imgur.com/RcrCjea.jpg" alt="ping -I eth1 192.168.10.12"></li>
<li><em>traceroute</em> and <em>tracepath</em> - Trace the path taken to a given host</li>
<li><em>netcat</em> - Arbitrary TCP and UDP network communication<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">stan@stan-virtual-machine:~$ ifconfig</span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 00:0c:29:a2:c2:5d  </span><br><span class="line">          inet addr:192.168.199.107  Bcast:192.168.199.255  Mask:255.255.255.0</span><br><span class="line">          inet6 addr: fe80::20c:29ff:fea2:c25d/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:109798 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:34545 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:53893408 (53.8 MB)  TX bytes:15357635 (15.3 MB)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          inet6 addr: ::1/128 Scope:Host</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:5917 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:5917 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:1699426 (1.6 MB)  TX bytes:1699426 (1.6 MB)</span><br><span class="line"></span><br><span class="line">stan@stan-virtual-machine:~$ nc -l 8000</span><br><span class="line">nc -v -z 192.168.199.107 8000</span><br><span class="line">Connection to 192.168.199.107 8000 port [tcp/*] succeeded!</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="https://i.imgur.com/60o3bav.png" alt="nc"></p>
<ul>
<li><em>tcpdump</em> and <em>wireshark</em> - Packet captures for network analysis<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"> nc -l 8000 &amp;</span><br><span class="line">[1] 20393</span><br><span class="line">➜  ~ sudo tcpdump -i enp2s0 port 8000</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on enp2s0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">Hi</span><br><span class="line">[1]  + 20393 done       nc -l 8000</span><br><span class="line">09:52:41.674092 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [S], seq 3581133462, win 29200, options [mss 1460,sackOK,TS val 12349350 ecr 0,nop,wscale 7], length 0</span><br><span class="line">09:52:41.674180 IP stan-OptiPlex-380.lan.8000 &gt; stan-virtual-machine.lan.57089: Flags [S.], seq 2419171515, ack 3581133463, win 28960, options [mss 1460,sackOK,TS val 2113949133 ecr 12349350,nop,wscale 7], length 0</span><br><span class="line">09:52:41.674412 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [.], ack 1, win 229, options [nop,nop,TS val 12349351 ecr 2113949133], length 0</span><br><span class="line">09:52:41.674518 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [P.], seq 1:4, ack 1, win 229, options [nop,nop,TS val 12349351 ecr 2113949133], length 3</span><br><span class="line">09:52:41.674541 IP stan-OptiPlex-380.lan.8000 &gt; stan-virtual-machine.lan.57089: Flags [.], ack 4, win 227, options [nop,nop,TS val 2113949133 ecr 12349351], length 0</span><br><span class="line">09:52:41.674582 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [F.], seq 4, ack 1, win 229, options [nop,nop,TS val 12349351 ecr 2113949133], length 0</span><br><span class="line">09:52:41.674718 IP stan-OptiPlex-380.lan.8000 &gt; stan-virtual-machine.lan.57089: Flags [F.], seq 1, ack 5, win 227, options [nop,nop,TS val 2113949133 ecr 12349351], length 0</span><br><span class="line">^C</span><br><span class="line">7 packets captured</span><br><span class="line">8 packets received by filter</span><br><span class="line">1 packet dropped by kernel</span><br><span class="line"></span><br><span class="line">stan@stan-virtual-machine:~$ echo Hi| nc 192.168.199.178 8000</span><br><span class="line">tcpdump -i eth1 port 8000 and not port 22 and not icmp</span><br><span class="line">tcpdump -i eth1 not udp 53</span><br><span class="line">tcpdump -nX -i eth1 port 8000</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="https://i.imgur.com/D7Vewu7.jpg" alt="tcpdump"><br><img src="https://i.imgur.com/4WIQHtZ.png" alt="tcp three-way handshake"></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Linux/">Linux</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/19/programming4sysadmins/" title="programming4sysadmins" itemprop="url">programming4sysadmins</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-19T06:10:53.000Z" itemprop="datePublished"> Published 2019-07-19</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="python"><a href="#python" class="headerlink" title="python"></a>python</h1><h2 id="What-can-you-do-with-python"><a href="#What-can-you-do-with-python" class="headerlink" title="What can you do with python?"></a>What can you do with python?</h2><ul>
<li>Versatile language, can use it across a lot of different domains</li>
<li>really fast to learn and fast to develop in<h2 id="Environment-Setup"><a href="#Environment-Setup" class="headerlink" title="Environment Setup"></a>Environment Setup</h2><a href="https://wiki.openhatch.org/wiki/O%27Reilly_Introduction_to_Python">link</a><h2 id="Python-basic-data-types"><a href="#Python-basic-data-types" class="headerlink" title="Python basic data types"></a>Python basic data types</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; type(1)</span><br><span class="line">&lt;type &apos;int&apos;&gt;</span><br><span class="line">&gt;&gt;&gt; type(1.0)</span><br><span class="line">&lt;type &apos;float&apos;&gt;</span><br><span class="line">Type is a functions that takes input and spits out output.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>a function</strong> is just the name and then input inside parentheses, and it’ll spit out output.</p>
<p>If you need to include the string delimiter inside the string just precede it with a backslash, as in ‘It\’s a wrap’<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; &quot;Hello &quot; + str(1)</span><br><span class="line">&apos;Hello 1&apos;</span><br></pre></td></tr></table></figure></p>
<h2 id="Making-choices-boolean-if-eif-else-compound-conditionals"><a href="#Making-choices-boolean-if-eif-else-compound-conditionals" class="headerlink" title="Making choices: boolean, if/eif/else, compound conditionals"></a>Making choices: boolean, if/eif/else, compound conditionals</h2><p>Boolean:</p>
<ul>
<li>True</li>
<li>False<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = 1</span><br><span class="line">&gt;&gt;&gt; x &gt; 0 and x &lt; 2</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; &quot;a&quot; in &quot;hello&quot; or &quot;e&quot; in &quot;hello&quot;</span><br><span class="line">True</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; temp = 32</span><br><span class="line">&gt;&gt;&gt; if temp &gt; 60 and temp &lt; 75:</span><br><span class="line">...     print(&quot;Nice and cozy&quot;)</span><br><span class="line">... else:</span><br><span class="line">...     print(&quot;Too extreme for me&quot;)</span><br><span class="line">...</span><br><span class="line">Too extreme for me</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; sister = 15</span><br><span class="line">&gt;&gt;&gt; brother =15</span><br><span class="line">&gt;&gt;&gt; if sister &gt; brother:</span><br><span class="line">...     print(&quot;Sister is older&quot;)</span><br><span class="line">... elif sister == brother:</span><br><span class="line">...     print(&quot;Same age!&quot;)</span><br><span class="line">... else:</span><br><span class="line">...     print(&quot;Brother is older&quot;)</span><br><span class="line">...</span><br><span class="line">Same age!</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Lists"><a href="#Lists" class="headerlink" title="Lists"></a>Lists</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; names = [&quot;Alice&quot;, &quot;Amy&quot;]</span><br><span class="line">&gt;&gt;&gt; names.append(&quot;Adam&quot;)</span><br><span class="line">&gt;&gt;&gt; names</span><br><span class="line">[&apos;Alice&apos;, &apos;Amy&apos;, &apos;Adam&apos;]</span><br><span class="line">&gt;&gt;&gt; names[len(names)-1]</span><br><span class="line">&apos;Adam&apos;</span><br><span class="line">&gt;&gt;&gt; names[-1]</span><br><span class="line">&apos;Adam&apos;</span><br></pre></td></tr></table></figure>
<p>The real superpower when using lists is actually to be able to loop over them.</p>
<h2 id="Loops"><a href="#Loops" class="headerlink" title="Loops"></a>Loops</h2><h1 id="Great-Bash"><a href="#Great-Bash" class="headerlink" title="Great Bash"></a>Great Bash</h1><ul>
<li><p>Redirect the output of commands</p>
<ul>
<li>Standard error is file descriptor “2” <code>ls -l myscript not.here &gt; lsout 2&gt; lserr</code></li>
<li>Out and error can be redirected separately or together <code>ls -l myscript not.here &amp;&gt; lsboth</code></li>
<li>The order of redirection is important<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ls -l myscript not.here &gt; lsout 2&gt;&amp;1</span><br><span class="line">## Redirectin error output to standard output</span><br><span class="line">## Standard output is already being re-directed to file &gt; dirlist</span><br><span class="line">## Hence, both error and standard output are written to file lsout</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Redirecting and piping input and output</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls &gt; /tmp/lsout</span><br><span class="line">wc &lt; /tmp/lsout</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Use the vertical bar character | to create a pipe: <code>ls|wc</code></p>
<p>Connect a series of commands with | symbols to make a pipeline.</p>
<ul>
<li>Create input with here documents</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/programming/">programming</a><a href="/tags/systemadmin/">systemadmin</a><a href="/tags/python/">python</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/17/devops/" title="DevOps" itemprop="url">DevOps</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-17T11:23:02.000Z" itemprop="datePublished"> Published 2019-07-17</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><strong>What is DevOps?</strong></p>
<ul>
<li>Speed and agility enable organizations to better serve their customers and compete more effectively in the market</li>
<li>Combination of cultural philosophies, practices, and tools</li>
<li>Increases an organization’s ability to deliver applications and services at high velocity</li>
<li>Evolves and imprvoes products faster</li>
</ul>
<p><strong>Why DevOps?</strong></p>
<ul>
<li>Antomate manual tasks, help teams manage complex environments at scale, and keep engineers in control of the velocity that is enabled by DevOps:<ul>
<li>Speed</li>
<li>Rapid delivery</li>
<li>Reliability</li>
<li>Scale</li>
<li>Improved collaboration</li>
<li>Security</li>
</ul>
</li>
</ul>
<p>Standard Continuous delivery (CD) techniques</p>
<ul>
<li>Blue/Green deployment (where “live” and “last” deployments are maintained on live)<br>Blue-green deployment is a technique that reduces downtime and risk by running two identical production environments called Blue and Green.</li>
</ul>
<p>At any time, only one of the environments is live, with the live environment serving all production traffic. For this example, Blue is currently live and Green is idle.</p>
<p>As you prepare a new version of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.</p>
<p>This technique can eliminate downtime due to app deployment. In addition, blue-green deployment reduces risk: if something unexpected happens with your new version on Green, you can immediately roll back to the last version by switching back to Blue.</p>
<ul>
<li>Phoenix deployment (where whole system are rebuilt on each release).<br><img src="https://i.imgur.com/DXtJZOm.png" alt="devops tools"></li>
</ul>
<p><strong>Goals</strong></p>
<ul>
<li>Culture for collaboration<blockquote>
<p>lack of collaboration is one of the root causes of the issues</p>
</blockquote>
</li>
<li>Automate<blockquote>
<p>Manual tests that consume resources are better left to machines. This frees time that is better spent elsewhere, and provides a better environment by relinquishing mundane tasks</p>
</blockquote>
</li>
<li>Optimize and reduce issue in SDLC(software development life cycle)<blockquote>
<p>The processes being comprised in a logical order allows for optimizations to be made from recorded metrics.</p>
</blockquote>
</li>
<li>Consistency in process<blockquote>
<p>This stems mostly from automation, and provides the foundation to ensure quality. It also provides a certain level of peace of mind, having confidence that the same process that successfully ran last time will run the same the next.</p>
</blockquote>
</li>
<li>Improve quality and security<blockquote>
<p>Automation combined with consistency in process, along with the tools and practices in place to perform the necessary testing and scans, removes the possibility of human error from subsequent processes</p>
</blockquote>
</li>
<li>Improve deployment frequency<blockquote>
<p>Agile methodologies proved effective for development, and sparked the idea to apply similar principles to other areas. Deployment frequency has always been a target for efficiency, as shown by the migration to waterfall, where deployments were seldom; to hybrid methodologies that produced releases four or five times per month; to agile, where deployments are dependent upon sprint links. With DevOps, there’s a potential to release multiple times per day.</p>
</blockquote>
</li>
</ul>
<p><strong>DevOps Methodologies and Concepts</strong></p>
<ul>
<li>Automation<ul>
<li>Not duplicate of goals</li>
<li>Automation in context of applying automation to deveopment, integration, and deployment process</li>
</ul>
</li>
<li>CI/CD/CD<ul>
<li>CI: continuous integration<ul>
<li>Focusses on sub process of SDLC to build features and fixes perform preliminary testing then merge to master if successful</li>
</ul>
</li>
<li>CD: continuous delivery<ul>
<li>tail end of CI</li>
<li>refers to archiving build artifacts</li>
</ul>
</li>
<li>CD: continous deployment<ul>
<li>deploy all necessary artifacts and perform any configuration</li>
</ul>
</li>
</ul>
</li>
<li>Infrastructure as code, configuration as code: fail fast<ul>
<li>Don’t waste resources on something that will fail</li>
<li>Organize and optimize for efficiency</li>
</ul>
</li>
<li>Frequent feedback<ul>
<li>Compilation of a series of small and frequent feedback loops</li>
</ul>
</li>
</ul>
<p><strong>DevOps engineer’s role within a devops organization</strong></p>
<ul>
<li>Continually research, refine, and create conceopts, methodologies, practices, and tools in order to optimize the SDLC.</li>
<li>Implement core standards, plicies, and tools based on the previous</li>
<li>Asses infrastructure requirements”<ul>
<li>Global and application sacle</li>
</ul>
</li>
<li>Crate and manage infrastructure</li>
<li>Coordinate with other teams</li>
<li>Troubleshoot issues with code and infrastructure</li>
<li>Work with one or more teams to:<ul>
<li>Assess their current state</li>
<li>Formulate end goals</li>
<li>Adapt to requirements</li>
<li>Develop a plan of implementation</li>
<li>Formulate milestones</li>
<li>Provide instruction on the core standards, policies, and tools</li>
<li>Develop a pipeline</li>
<li>Help to change their code and processes to work with the plan</li>
</ul>
</li>
</ul>
<p><strong>philosophy</strong><br>DevOps is not something you do. It is something you are. </p>
<p>Devops culture is the one based on a set of principles, hierarchy of rules, by which each person operates.<br>A DevOps culture is one that allows more freedom but more responsibility.</p>
<p><strong>Devops lifecycle</strong></p>
<ul>
<li><p>Continuous integration</p>
<ul>
<li>Central repository</li>
<li>Continuous compiling, testing</li>
<li>Code verification</li>
<li>Identifying bugs early</li>
<li>Software in smaller chunks</li>
<li>Easy integration<br>Continuous integration (CI) requires developers to integrate code into a centralized repository as they finish coding and successfully pass unit testing, several times per day. The end goal is to create small workable chunks of code that are validated and integrated back into the code repository as frequently as possible. </li>
</ul>
</li>
<li><p>Configuration management</p>
<ul>
<li>System changes</li>
<li>Multiple servers</li>
<li>Tracking changes</li>
<li>Types of CM tools</li>
<li>Scripted builds</li>
<li>Identical development and production environments</li>
</ul>
</li>
<li><p>Continous delivery</p>
<ul>
<li>Deploying the application</li>
<li>Incremental or small changes</li>
<li>Compatible with schedule releases</li>
<li>Every change-ready to deploy<br>Continuous delivery simply means that every change is ready to be deployed to production as soon as automated testing validates it.<br>Note there are two manual checkpoints in this example. One is for a technical decision to approve the code before initiating activities in the CI environment. The second is a business decision to accept the changes and continue with the automated steps to production deployment.<br><img src="https://i.imgur.com/XzLyd0g.png" alt="reference pipeline-continous delivery"><br><strong>Deploying to production</strong></li>
</ul>
</li>
<li><p>Canary releases</p>
<blockquote>
<p>Continuous delivery deploys many builds to production. In a canary deployment, the new code is delivered only to a percentage of the existing infrastructure. For example, if the system is running on 10 load-balanced virtual servers, you can define a canary cluster of one or two servers. This way, if the deployment is not successful due to an escaped defect, it can be caught before the build is deployed to all of the servers. Canary releases are also used for pilot features to determine performance and acceptance prior to a full rollout.</p>
</blockquote>
</li>
<li><p>Blue/green deployment</p>
<blockquote>
<p>This is a zero-downtime deployment technique that involves a gradual release to ensure uninterrupted service. The blue/green approach is effective in virtualized environments, especially if IaaS is used. Although a blue/green deployment is a deep topic that deserves an entire chapter on its own, simply put, it includes maintaining two identical development environments—Blue and Green. One is a live environment for production traffic, whereas the other is used to deploy the new release. In our example, let’s say that Green is the current live production environment and Blue is the idle identical production environment. After the code is deployed and tested in the Blue environment, we can begin directing traffic of incoming requests from Green (current production) to Blue. You can do this gradually until the traffic redirect is 100 percent to the Blue environment. If unexpected issues occur during this gradual release, we can roll back. When it is completed, the Green environment becomes idle and the Blue environment is now the live production environment.</p>
</blockquote>
</li>
<li><p>Continous monitoring<br>Continous monitoring is the practice that connects operations back to development,providing visibility and relevant data throughout the development lifecycle including production monitoring. continuous monitoring aims to reduce the time between identification of a problem and deployment of the fix.<br>Monitoring begins with <strong>Sprint 1</strong> and should be integrated into the development work. As the system is built, monitoring solutions are also designed. </p>
</li>
</ul>
<p><strong>four different types of continuous monitoring</strong></p>
<ul>
<li>Infrastructure monitoring<blockquote>
<p>Visualize infrastructure events coming from all computing resources, storage and network, and measure the usage and health of infrastructure resources. <strong>AWS CloudWatch</strong> and <strong>CloudTrail</strong> are examples of infrastructure monitoring tools.</p>
</blockquote>
</li>
<li>Application performance monitoring (APM)<blockquote>
<p>Target bottlenecks in the application’s framework. <strong>Appdynamics</strong> and <strong>New Relic</strong> are industry-leading APM tools.</p>
</blockquote>
</li>
<li>Log management monitoring<blockquote>
<p>Collect performance logs in a standardized way and use analytics to identify application and system problems. <strong>Splunk</strong> and <strong>ELK</strong> are two leading products in this area.</p>
</blockquote>
</li>
<li>Security monitoring<blockquote>
<p>Reduce security and compliance risk through automation. Security configuration management, vulnerability management, and intelligence to detect attacks and breaches before they do serious damage are achieved through continuous monitoring. For example, <strong>Netflix’s Security Monkey</strong> is a tool that checks the security configuration of your cloud implementation on AWS.</p>
</blockquote>
</li>
</ul>
<p><strong>three major setps</strong></p>
<ol>
<li>monitoring</li>
<li>an alert system to warn the team about a problem</li>
<li>actions to take when an alert occurs</li>
</ol>
<ul>
<li>Continous testing<ul>
<li>Speed and quality</li>
<li>Testing incremental changes</li>
<li>Automated tests</li>
<li>Tests to be atomic: small test<ul>
<li>Continous testing during development (e.g. use open source tools like Selenium for testing)</li>
<li>Confidence to release</li>
<li>Integration with CI</li>
</ul>
</li>
</ul>
</li>
<li>Continous deployment<ul>
<li>Superset of Continuous Delivery</li>
<li>Deploying to production</li>
<li>Automates the deployment pipeline<br>Unlike continuous delivery, which means that every change is deployable but might be held back because of business considerations or other manual steps, continuous deployment strives to automate production deployment end to end. With this practice, confidence in the automated tests is extremely high, and as long as the code has passed all the tests, it will be deployed.<br><img src="https://i.imgur.com/Aq1VaJb.png" alt="cd"></li>
</ul>
</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Devops/">Devops</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/17/aws-admin/" title="aws administration" itemprop="url">aws administration</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-17T08:02:52.000Z" itemprop="datePublished"> Published 2019-07-17</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="CodeCommit"><a href="#CodeCommit" class="headerlink" title="CodeCommit"></a>CodeCommit</h1><p>Codecommit is a source control service provided by aws(hosts private git repositories)<br><strong>why choose CodeCommit</strong></p>
<ul>
<li>Easy integration with other AWS services like CodePipeline</li>
<li>Repositories are private by default</li>
<li>Can use IAM for fine-graned authorization</li>
</ul>
<p><strong>Creating a private code repo on CodeCommit</strong><br>IAM-&gt; HTTPS Git credentials for AWS CodeCommit</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git clone https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/SampleRepo</span><br><span class="line">cd SampleRepo</span><br><span class="line">wget https://s3.amazonaws.com/aws-codedeploy-us-east-1/samples/latest/SampleApp_Linux.zip</span><br><span class="line">unzip SampleApp_Linux.zip</span><br><span class="line">rm SampleApp_Linux.zip</span><br><span class="line">git add -A</span><br><span class="line">git commit -m &quot;Initial commit&quot;</span><br><span class="line">git push</span><br></pre></td></tr></table></figure>
<p><strong>Migrating your project to CodeCommit</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">### - - mirror here means that we are not interested in cloning the application, however we are interested in downloading the Git binary files that make up the repository in the first place. </span><br><span class="line">git clone --mirror https://github.com/awslabs/aws-demo-php-simple-app.git aws-codecommit-demo</span><br><span class="line">git push https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/myrepo</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;initial commit to demp rep&quot;</span><br><span class="line">git remote add demo https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/demo</span><br><span class="line">git remote -v</span><br><span class="line">git push demo master</span><br></pre></td></tr></table></figure>
<p><a href="https://docs.aws.amazon.com/codecommit/latest/userguide/getting-started-cc.html">CodeCommit tutorials</a><br><a href="https://docs.aws.amazon.com/codecommit/latest/userguide/auth-and-access-control-iam-identity-based-access-control.html">Using IAM policies with CodeCommit</a><br><a href="https://aws.amazon.com/blogs/devops/using-aws-codecommit-pull-requests-to-request-code-reviews-and-discuss-code/">Using AWS CodeCommit Pull Requests</a><br><a href="https://datasift.github.io/gitflow/IntroducingGitFlow.html">GitFlow development release model</a></p>
<h1 id="Deploying-Jenkins"><a href="#Deploying-Jenkins" class="headerlink" title="Deploying Jenkins"></a>Deploying Jenkins</h1><p>Amazon linux 2 AMI<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y update</span><br><span class="line">sudo yum -y install java-1.8.0</span><br><span class="line"># remove java 7</span><br><span class="line">sudo yum remove java-1.7.0-openjdk</span><br><span class="line">java -version</span><br><span class="line">sudo wget -O /etc/yum.repos.d/jenkins.repo https:/pkg.jenkins-ci.org/redhat/jenkins.repo </span><br><span class="line">sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key</span><br><span class="line">sudo yum -y install jenkins</span><br><span class="line">sudo service jenkins start</span><br></pre></td></tr></table></figure></p>
<h1 id="CodeDeploy"><a href="#CodeDeploy" class="headerlink" title="CodeDeploy"></a>CodeDeploy</h1><p><img src="https://i.imgur.com/ZRCFrZP.png" alt="codedeploy ec2"></p>
<h1 id="Cloud9"><a href="#Cloud9" class="headerlink" title="Cloud9"></a>Cloud9</h1><p><strong>What is Cloud9</strong></p>
<ul>
<li>Cloud9 integrates with other AWS DevOps tools such as CodeCommit, CodePipeline, and CodeStar to enable a rich development pipeline with continuous delivery</li>
<li>AWS Cloud9 contains a collection of tools that you use to code, build, run, test, debug, and release software on the cloud</li>
<li>Use the AWS Cloud9 Integrated Development Environment (IDE) to work with these tools<br><strong>What can i do with aws Cloud 9</strong></li>
<li>Supported languages:<ul>
<li>C++</li>
<li>Java</li>
<li>Python</li>
<li>.NET</li>
<li>Node.js</li>
<li>PHP</li>
<li>Pearl</li>
<li>Ruby</li>
<li>Go</li>
<li>JavaScript</li>
<li>CoffeeScript</li>
</ul>
</li>
<li>Supported integrations:<ul>
<li>CodeCommit</li>
<li>CodePipeline</li>
<li>CodeStar</li>
<li>API gateway</li>
<li>Lambda</li>
<li>Lightsail</li>
<li>DynamoDB</li>
<li>RDS</li>
<li>AWS CLI</li>
<li>Docker</li>
<li>GitHub</li>
</ul>
</li>
<li>Supported environments<ul>
<li>EC2</li>
<li>SSH</li>
<li>Single-user environment</li>
<li>Shared team environment</li>
<li>virtualenv<h1 id="CodeBuild"><a href="#CodeBuild" class="headerlink" title="CodeBuild"></a>CodeBuild</h1><h1 id="CodePipeline"><a href="#CodePipeline" class="headerlink" title="CodePipeline"></a>CodePipeline</h1><h1 id="CodeStart"><a href="#CodeStart" class="headerlink" title="CodeStart"></a>CodeStart</h1></li>
</ul>
</li>
</ul>
<h1 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h1><ul>
<li><a href="https://aws.amazon.com/devops/what-is-devops/">What is DevOps</a></li>
<li><a href="https://aws.amazon.com/pricing/">AWS pricing</a></li>
<li><a href="https://docs.aws.amazon.com/codepiepline/latest/userguide/tutorials-simple-codecommit.html">TUtorial-create a simple pipeline</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/aws/">aws</a><a href="/tags/Codecommit/">Codecommit</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/15/devops-with-aws/" title="devops-with-aws" itemprop="url">devops-with-aws</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-15T13:44:53.000Z" itemprop="datePublished"> Published 2019-07-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="Project-setup"><a href="#Project-setup" class="headerlink" title="Project setup"></a>Project setup</h1><p><a href="https://github.com/espiderinc/hapi-rest-demo">code</a></p>
<h2 id="Importance-of-automated-test-in-CI-CD"><a href="#Importance-of-automated-test-in-CI-CD" class="headerlink" title="Importance of automated test in CI,CD"></a>Importance of automated test in CI,CD</h2><ul>
<li>Automated tests<ul>
<li>Unit tests</li>
<li>Integration tests</li>
<li>UAT tests</li>
</ul>
</li>
<li>Code coverage</li>
<li>Notifications<h2 id="CI-CD-with-relational-databases"><a href="#CI-CD-with-relational-databases" class="headerlink" title="CI/CD with relational databases"></a>CI/CD with relational databases</h2></li>
<li>Managing the version of database schema<br>There is no easy way to control the version of relational database schema</li>
<li>Database schema migrations</li>
<li>DellStore2 sample database<ul>
<li>Products table</li>
</ul>
</li>
<li>Sqitch change management system<h2 id="Project-component-setup"><a href="#Project-component-setup" class="headerlink" title="Project component setup"></a>Project component setup</h2></li>
<li>PostgreSQL database on AWS RDS</li>
<li>Node.JS HAPI RESTful API project</li>
<li>Sqitch database mangement framework<h2 id="Setup-PostreSQL-database-instance-in-AWS-RDS"><a href="#Setup-PostreSQL-database-instance-in-AWS-RDS" class="headerlink" title="Setup PostreSQL database instance in AWS RDS"></a>Setup PostreSQL database instance in AWS RDS</h2></li>
</ul>
<ol>
<li>Create a rds in aws with postgresql engine version 9.4.7.</li>
<li>Connect to aws rds use pgAdmin 3.</li>
<li>Download sample schema dellstore2 from <a href="http://pgfoundry.org/projects/dbsamples/">link</a></li>
<li>In pgAdmin3 click Plugins-&gt; PSQL console-&gt; run command <code>\i /tmp/dellstore2.sql</code> to create a new schema.<h2 id="Setup-Node-JS-HAPI-ReSTful-API-project"><a href="#Setup-Node-JS-HAPI-ReSTful-API-project" class="headerlink" title="Setup Node.JS HAPI ReSTful API project"></a>Setup Node.JS HAPI ReSTful API project</h2><strong>HAPI</strong> is a rich application framework for building applications and RESTful APIs with Node.JS</li>
</ol>
<p>Official website for HAPI framework is HAPIJS.com</p>
<ol>
<li>install node and npm<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br><span class="line">mkdir myfirsthapiproject</span><br><span class="line">cd myfirsthapiproject</span><br><span class="line">npm init</span><br><span class="line">npm install --save hapi</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>2.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/espiderinc/hapi-rest-demo.git</span><br><span class="line">cd hapi-rest-demo</span><br><span class="line">npm install</span><br><span class="line">sudo npm install -g istanbul mocha</span><br><span class="line">node index.js</span><br></pre></td></tr></table></figure></p>
<ol start="3">
<li><p><img src="https://i.imgur.com/rCcEgzW.png" alt="access by">)<br><img src="https://i.imgur.com/VdGe8f3.png" alt="Imgur"></p>
</li>
<li><p>test</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">hapi-rest-demo git:(master) ✗ npm test</span><br><span class="line"></span><br><span class="line">&gt; hapi-rest-demo@1.0.0 test /home/stan/workspace/hapi-rest-demo</span><br><span class="line">&gt; istanbul cover _mocha test/**/*.js</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(node:20777) [DEP0022] DeprecationWarning: os.tmpDir() is deprecated. Use os.tmpdir() instead.</span><br><span class="line">  Task routes</span><br><span class="line">    GET /products</span><br><span class="line">      ✓ should return statusCode 200 (381ms)</span><br><span class="line">      ✓ should return product [ACADEMY BROOKLYN] </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  2 passing (416ms)</span><br><span class="line"></span><br><span class="line">=============================================================================</span><br><span class="line">Writing coverage object [/home/stan/workspace/hapi-rest-demo/coverage/coverage.json]</span><br><span class="line">Writing coverage reports at [/home/stan/workspace/hapi-rest-demo/coverage]</span><br><span class="line">=============================================================================</span><br><span class="line"></span><br><span class="line">=============================== Coverage summary ===============================</span><br><span class="line">Statements   : 56.31% ( 58/103 )</span><br><span class="line">Branches     : 39.29% ( 11/28 )</span><br><span class="line">Functions    : 47.83% ( 11/23 )</span><br><span class="line">Lines        : 57% ( 57/100 )</span><br><span class="line">================================================================================</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>report generated workspace/hapi-rest-demo/coverage/lcov-report/index.html</p>
<h2 id="Setup-swtich-database-schema-framework"><a href="#Setup-swtich-database-schema-framework" class="headerlink" title="Setup swtich (database schema framework)"></a>Setup swtich (database schema framework)</h2><p>Managin database schema for relational databaes (with Sqitch)<br><strong>Sqitch</strong> is a standalone system without any dependency on frameworks or ORMs.</p>
<ul>
<li>handels dependencies between scripts</li>
<li><a href="http://sqitch.org">project site</a><br><strong>install sqitch</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker pull sqitch/sqitch</span><br><span class="line">curl -L https://git.io/fAX6Z -o sqitch &amp;&amp; chmod +x sqitch</span><br><span class="line">mv sqitch /usr/bin/</span><br><span class="line">sudo apt-get install -y libdbd-pg-perl postgresql-client</span><br><span class="line">sqitch --version</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>use sqitch</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">mkdir stantutorial</span><br><span class="line">cd stantutorial</span><br><span class="line">sqitch init stantutorial --uri http://github.com/espiderinc/hapi-rest-demo.git</span><br><span class="line">cat sqitch.conf</span><br><span class="line"> [core]</span><br><span class="line">         engine = pg</span><br><span class="line">        # plan_file = sqitch.plan</span><br><span class="line">        # top_dir = .</span><br><span class="line">sqitch config --user user.name &apos;StanTutorial&apos;</span><br><span class="line">sqitch config --user user.email &apos;devops@cwzhou.win&apos;</span><br><span class="line">sqitch add schema -n &apos;Add schema for tutorial objects.&apos;</span><br><span class="line">Created deploy/schema.sql</span><br><span class="line">Created revert/schema.sql</span><br><span class="line">Created verify/schema.sql</span><br><span class="line">Added &quot;schema&quot; to sqitch.plan</span><br><span class="line"></span><br><span class="line"> cat deploy/schema.sql</span><br><span class="line">-- Deploy stantutorial:schema to pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">CREATE SCHEMA tutorial;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">cat revert/schema.sql</span><br><span class="line">-- Revert stantutorial:schema from pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">DROP SCHEMA tutorial;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line"> cat verify/schema.sql</span><br><span class="line">-- Verify stantutorial:schema on pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add verifications here.</span><br><span class="line"></span><br><span class="line">select 1/count(*) from information_schema.schemata where schema_name=&apos;tutorial&apos;;</span><br><span class="line"></span><br><span class="line">ROLLBACK;</span><br><span class="line"></span><br><span class="line"> sqitch add video --requires schema -n &apos;add video table to schema tutorial&apos;</span><br><span class="line"></span><br><span class="line"> cat deploy/video.sql</span><br><span class="line">-- Deploy stantutorial:video to pg</span><br><span class="line">-- requires: schema</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">SET client_min_messages = &apos;warning&apos;;</span><br><span class="line">CREATE TABLE tutorial.video(</span><br><span class="line">        subject TEXT    PRIMARY KEY,</span><br><span class="line">        comment TEXT,</span><br><span class="line">        timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW()</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">cat revert/video.sql</span><br><span class="line">-- Revert stantutorial:video from pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">DROP TABLE tutorial.video;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">cat verify/video.sql</span><br><span class="line">-- Verify stantutorial:video on pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add verifications here.</span><br><span class="line">select subject, comment, timestamp</span><br><span class="line">from tutorial.video</span><br><span class="line">where false;</span><br><span class="line"></span><br><span class="line">ROLLBACK;</span><br><span class="line">sqitch deploy db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch status db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch verify db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch revert db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch status db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br></pre></td></tr></table></figure></p>
<h1 id="CI-and-CD-pipeline-deep-dive"><a href="#CI-and-CD-pipeline-deep-dive" class="headerlink" title="CI and CD pipeline deep dive"></a>CI and CD pipeline deep dive</h1><h2 id="AWS-prerequisites"><a href="#AWS-prerequisites" class="headerlink" title="AWS prerequisites"></a>AWS prerequisites</h2><ul>
<li>IAM instance profile</li>
</ul>
<ol>
<li><p>Create a policy, name: CodeDeploy-EC2-Permissions, json</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class="line">    &quot;Statement&quot;: [</span><br><span class="line">     &#123;</span><br><span class="line">        &quot;Action&quot;:[</span><br><span class="line">           &quot;s3:Get*&quot;,</span><br><span class="line">           &quot;s3:List*&quot;  </span><br><span class="line">        ],</span><br><span class="line">        &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">        &quot;Resource&quot;: &quot;*&quot;</span><br><span class="line">     &#125;    </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Create a role, named CodeDeploy-EC2 -&gt; Choose role type ec2-&gt;Attach permissions policies “CodeDeploy-EC2-Permissions”</p>
</li>
</ol>
<ul>
<li>IAM service role</li>
</ul>
<ol>
<li>Create a role named stantutorialRole -&gt; select role type CodeDeploy</li>
</ol>
<h2 id="Jenkins-installation"><a href="#Jenkins-installation" class="headerlink" title="Jenkins installation"></a>Jenkins installation</h2><p>Ubuntu-&gt; Configure Instance Details, IAM role, select CodeDeploy-EC2 (this will allow jenkins connect to s3 buckets)-&gt;<br>Tag instance: Key group Value hapi-demo<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget -q -O - http://pkg.jenkins-ci.org/debian/jenkins-ci.org.key| sudo apt-key add -</span><br><span class="line">sudo vim /etc/apt/sources.list # add following line</span><br><span class="line">deb http://pkg.jenkins-ci.org/debian-stable binary/</span><br><span class="line">sudo apt-get install default-jdk</span><br><span class="line">sudo apt-get install jenkins</span><br><span class="line">sudo service jenkins start</span><br></pre></td></tr></table></figure></p>
<p>Install plugin AWS CodePipeline<br>Install node.js:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -</span><br><span class="line">apt-get install -y nodejs</span><br><span class="line">sudo npm install -g npm</span><br><span class="line">node -v</span><br></pre></td></tr></table></figure></p>
<p>Install sqitch<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install build-essential cpanminus perl perl-doc</span><br><span class="line">cpanm --quiet --notest App::Sqitch</span><br><span class="line">sqitch --version</span><br><span class="line">apt-get install -y postgresql libdbd-pg-perl</span><br></pre></td></tr></table></figure></p>
<p>Create a new instance hapi-demo install node.js and<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python3-pip</span><br><span class="line">sudo apt install ruby-full</span><br><span class="line">sudo apt install wget</span><br><span class="line">wget https://aws-codedeploy-ap-southeast-2.s3.amazonaws.com/latest/install</span><br><span class="line">chmod +x install</span><br><span class="line">sudo ./install auto</span><br></pre></td></tr></table></figure></p>
<h2 id="CodeDeploy-application"><a href="#CodeDeploy-application" class="headerlink" title="CodeDeploy application"></a>CodeDeploy application</h2><p>Create a new Codedeploy application, choose compute type ec2/on-premises, Service role-&gt; statutorialRole; Environment configuration tick Amazon EC2 instances, Key-&gt; Name, Value-&gt; hapi-demo; Deployment setting-&gt; CodeDeployDefault.OneAtATime</p>
<h2 id="Review-appSpec-yml-file"><a href="#Review-appSpec-yml-file" class="headerlink" title="Review appSpec.yml file"></a>Review appSpec.yml file</h2><p>appspec.yml file is an application specification file for aws codedeploy</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat appspec.yml</span><br><span class="line">version: 0.0</span><br><span class="line">os: linux</span><br><span class="line">files:</span><br><span class="line">  - source: /</span><br><span class="line">    destination: /myapp</span><br><span class="line">permissions:</span><br><span class="line">  - object: /myapp/startApp.sh</span><br><span class="line">    mode: 777</span><br><span class="line">hooks:</span><br><span class="line">  ApplicationStart:</span><br><span class="line">    - location: startApp.sh</span><br><span class="line">      timeout: 10</span><br></pre></td></tr></table></figure>
<h2 id="Setup-Jenkins-job"><a href="#Setup-Jenkins-job" class="headerlink" title="Setup Jenkins job"></a>Setup Jenkins job</h2><p>Create a freestyle jenkins job, configurat as following screenshots:<br><img src="https://i.imgur.com/yb9AZch.png" alt="screenshot01"><br><img src="https://i.imgur.com/jxkg9xA.png" alt="screenshot02"><br><img src="https://i.imgur.com/ghjvXwd.png" alt="screenshot03"></p>
<h2 id="Build-AWS-CodePieline"><a href="#Build-AWS-CodePieline" class="headerlink" title="Build AWS CodePieline"></a>Build AWS CodePieline</h2><ol>
<li>Source provider <a href="https://github.com/stanosaka/hapi-rest-demo">GitHub</a></li>
<li>Build provider: Add Jenkins; Prvider name must match the name in jenkin’s job</li>
<li>Deployment provider: aws codedeploy<br><img src="https://i.imgur.com/Zcps1fo.png" alt="aws codedeploy"><br><img src="https://i.imgur.com/e2nGdbj.png" alt="deployed pages"><br><img src="https://i.imgur.com/eJAhUJH.png" alt="api"><br><img src="https://i.imgur.com/MJs6nKN.png" alt="lcov-report"></li>
</ol>
<h1 id="Next-Steps"><a href="#Next-Steps" class="headerlink" title="Next Steps"></a>Next Steps</h1><h2 id="Notifications"><a href="#Notifications" class="headerlink" title="Notifications"></a>Notifications</h2><p>AWS SNS notifications for build and deployment status</p>
<ol>
<li>Create a policy named: notification-policy<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class="line">    &quot;Statement&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">            &quot;Action&quot;: &quot;sns:Publish&quot;,</span><br><span class="line">            &quot;Resource&quot;: &quot;*&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>Attach notification-policy to Role CodeDeploy-EC2</p>
<ol start="2">
<li>in CodeDeploy edit deployment group;<br><img src="https://i.imgur.com/Lx8Kxdw.png" alt="create deployment trigger"><br><img src="https://i.imgur.com/Xl4OvF8.png" alt="notification"></li>
</ol>
<h2 id="Code-changes"><a href="#Code-changes" class="headerlink" title="Code changes"></a>Code changes</h2><p>Automatically and continuously deploy code without any downtime</p>
<h2 id="Database-schema-changes"><a href="#Database-schema-changes" class="headerlink" title="Database schema changes"></a>Database schema changes</h2><p>Consistently and automatically deploy relational database schema changes<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sqitch add product-add-comments</span><br><span class="line">cat /db/deploy/product-add-comments.sql</span><br><span class="line">-- Deploy spidertutorial:product-add-comments to pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">alter table products add comments varchar(100) default &apos;default comments&apos;;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line">git commit -a -m &quot;add new column to products&quot;</span><br><span class="line">git push origin master:master</span><br></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Jenkins/">Jenkins</a><a href="/tags/Devops/">Devops</a><a href="/tags/CD-CI/">CD/CI</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/15/splunk/" title="splunk" itemprop="url">splunk</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-15T00:40:04.000Z" itemprop="datePublished"> Published 2019-07-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><a href="https://github.com/PacktPublishing/Splunk-7.x-Quick-Start-Guide">code</a></p>
<h1 id="What-is-Splunk"><a href="#What-is-Splunk" class="headerlink" title="What is Splunk?"></a>What is Splunk?</h1><p>Splunk is a software platform that collects and stores all this machine data in one place.<br><img src="https://i.imgur.com/wObsIBw.png" alt="splunk data sources and use cases"></p>
<h2 id="Splunk-products"><a href="#Splunk-products" class="headerlink" title="Splunk products"></a>Splunk products</h2><ul>
<li><strong>Splunk Enterprise</strong>: designed for on-premise deployments</li>
<li><strong>Splunk Cloud</strong>: a cloud-based <strong>software as a service (SaaS)</strong> version of Splunk Enterprise.</li>
<li><strong>Splunk Light</strong>: is designed to be a small-scale solution.</li>
<li><strong>Splunk Free</strong>: is a free version of the core Splunk Enterprise product that has limits on users(one user), ingestion volume (500 MB/day), and other features.</li>
</ul>
<p><strong>Splunk components</strong></p>
<ul>
<li>Universal forwarder</li>
<li>Indexer and indexer clusters</li>
<li>Search head and search head clusters</li>
<li>Deployment server</li>
<li>Deployer</li>
<li>Cluster master</li>
<li>License master</li>
<li>Heavy forwarder<br>Universal forwarders, indexers, and search heads constitute the majority of Splunk functionality; the other components provide supporting roles for larger clustered/distributed environments.<br><img src="https://i.imgur.com/sqJ8esH.png" alt="Splunk components in a distributed deployment"></li>
</ul>
<p>The <strong>universal forwarder (UF)</strong> is a free small-footprint version of Splunk Enterprise that is installed on each application, web, or other type of server to collect data from specified log files and forward this data to Splunk for indexing(storage). In A large Splunk deployment, you may have hundreds or thousands of forwards that consume and forward data for indexing.</p>
<p>An <strong>indexer</strong> is the Splunk component that creates and manages indexes, which is where machine data is stored. Indexers perform two main functions: parsing and storing data, which has been received from forwarders or other data sources into indexes, and searching and returning the indexed data in response to search requests.</p>
<p>An indexing cluster is a group of indexers that have been configured to work together to handle higher volumes of both incmoing data to be indexed and search requests to be serviced, as well as providing redundancy by keeping duplicate copies of indexed data spread across the cluster members.</p>
<p>A <strong>search head</strong> is an instance of Splunk Enterprise that handles search management functions. This includes providing a web-based user interface called Splunk Web, from which users issue search requests in what is called <strong>Search Processing Language (SPL)</strong>. Search reqeusts initiated by a user ( or a report or dashboard) are sent to one or more indexers to locate and return the requested data; the search head then formates the returned data for presentation to the user.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index=_internal | stats count by source, sourcetype</span><br></pre></td></tr></table></figure>
<p>an example of executing a simple search in Splunk Web. The SPL specifies searching in the <code>_internal</code> index, which is where Splunk saves data about its internal operations, and provides a count of the number of events in each log for Today. The SPL command specified an <code>index</code>, and then pipes the returned results to the <code>stats</code> command to return a <code>count</code> of all the events by their <code>source</code> and `sourcetype<br><img src="https://i.imgur.com/exMXaN5.jpg" alt="Simple search in Splunk Web"></p>
<p>A <strong>deployment server</strong> is a Splunk Enterprise instance that acts as a centralized configuration manager ofr a number of Splunk components, but which in practice is used to manage UFs.</p>
<p>A <strong>deployer</strong> is a Splunk Enterprise instance that is ued to distribute Splunk apps and certain other configuration updates to search head cluster memebers.</p>
<p>A <strong>cluster master</strong> is a Splunk Enterprise instance that coordinates the activities of an indexing cluster.</p>
<p>A <strong>license master</strong> is a single Splunk Enterprise instance that provides a licensing service for the multiple instances of Splunk that have been deployed in a distributed environment.</p>
<p>A <strong>heavy forwarder</strong> is an instance of Splunk Enterprise that can receive data from other forwarders or data sources and parse, index, and/or send data to another Splunk instance for indexing. </p>
<p>Splunk Enterprise also has a monitoring tool function called the <strong>monitoring console</strong>, which lets you view detailed topology and performance information about your entire distributed deployment from one interface. </p>
<p><img src="https://i.imgur.com/ElU7rTv.png" alt="Splunk data pipeline"></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/splunk/">splunk</a><a href="/tags/monitoring/">monitoring</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/13/terraform/" title="terraform" itemprop="url">terraform</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-13T03:29:54.000Z" itemprop="datePublished"> Published 2019-07-13</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><a href="https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS">Supplemental content</a></p>
<h1 id="Install-Terraform-and-Tools-on-linux"><a href="#Install-Terraform-and-Tools-on-linux" class="headerlink" title="Install Terraform and Tools on linux"></a>Install Terraform and Tools on linux</h1><h2 id="Terraform-development-environment"><a href="#Terraform-development-environment" class="headerlink" title="Terraform development environment"></a>Terraform development environment</h2><ul>
<li>Terraform</li>
<li>aws account</li>
<li>aws cli with credentials configured</li>
<li>git</li>
<li>shell (bash, pwoershell, cmd, git-bash)</li>
<li>Text editor (visual studio code with Extensions terraform)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://releases.hashicorp.com/terraform/0.12.4/terraform_0.12.4_linux_amd64.zip</span><br><span class="line">unzip terraform_0.12.4_linux_amd64.zip</span><br><span class="line">sudo mv terraform /usr/local/bin</span><br><span class="line">terraform version</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="First-deployment-with-Terraform"><a href="#First-deployment-with-Terraform" class="headerlink" title="First deployment with Terraform"></a>First deployment with Terraform</h1><h2 id="Configuration-language-basics"><a href="#Configuration-language-basics" class="headerlink" title="Configuration language basics"></a>Configuration language basics</h2><p>Terraform uses HCL (Hashicorp configuration language)</p>
<ul>
<li>human friendliness</li>
<li>JSON is quite verbose and doesn’t support comments, is machine readable</li>
<li>YAML is quite easy to mess up indentation and it’s not always clear whether you should use a colon or hyphen(specially when you using nested maps and lists)- machine-friendly, which is designed to be written and modified by humans</li>
<li>can sue JSON as input to Terraform</li>
</ul>
<p><strong>main features of HCL</strong></p>
<ul>
<li>can have single-line comments, start with a double slash or a number sign</li>
<li>multi-line comments are wrapped in /*</li>
<li>Values assign syntax key = vaule</li>
<li>Strings are double bolded</li>
<li>Numbers, booleans, arrays, lists, objects, named maps or dictonaries</li>
<li>Interpolations, conditionals, and various build-in functions</li>
</ul>
<h2 id="Set-up-aws-provider"><a href="#Set-up-aws-provider" class="headerlink" title="Set up aws provider"></a>Set up aws provider</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir s3_backbone &amp;&amp; cd s3_backbone</span><br><span class="line">git init</span><br><span class="line">terraform init</span><br></pre></td></tr></table></figure>
<p>Provide: Terraform object that is responsible for managing the lifecycle of a resouce:</p>
<ul>
<li>Create, REad, Update, and Delete operations (CRUD)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat providers.tf</span><br><span class="line">provider &quot;aws&quot;&#123;</span><br><span class="line">  region = &quot;ap-southeast-2&quot;</span><br><span class="line">&#125;</span><br><span class="line">git add -A</span><br><span class="line">git commit -m &quot;Add aws provider&quot;</span><br><span class="line">terraform init</span><br><span class="line">git status</span><br><span class="line">echo &quot;.terraform&quot; &gt;&gt; .gitignore</span><br><span class="line">git status</span><br><span class="line">git add .gitignore&amp;&amp; git commit -m &quot;Add .gitignore&quot;</span><br><span class="line">terraform plan # creates an execution plan</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Deploy-an-s3-bucket-into-aws"><a href="#Deploy-an-s3-bucket-into-aws" class="headerlink" title="Deploy an s3 bucket into aws"></a>Deploy an s3 bucket into aws</h2><p>google terraform s3 bucket<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat s3.tf</span><br><span class="line">resource &quot;aws_s3_bucket&quot; &quot;main&quot; &#123;</span><br><span class="line">  bucket = &quot;packt-terraform-section2-bucket-stan&quot;</span><br><span class="line">  acl    = &quot;private&quot;</span><br><span class="line">&#125;</span><br><span class="line">git add . &amp;&amp; git commit -m &quot;Add S3 bucket&quot;</span><br><span class="line">terraform plan</span><br><span class="line"># The output of this command is similar to what we get when we run the diff command on Linux: resources with a plus sign are going to be created, resources with the minus sign are going to be deleted, and resources with a tilde sign are going to be modified</span><br><span class="line">terraform apply</span><br><span class="line">git status</span><br><span class="line"># notice that Terraform also created a new file, terraform.tfstate</span><br><span class="line"># it&apos;s a JSON file, which contains some information about the bucket we just created. Terraform uses the state file to map real-world resources to your configuration, and keep track of metadata</span><br></pre></td></tr></table></figure></p>
<p><strong>What is state?</strong></p>
<ul>
<li>Desired state</li>
<li>Actual state</li>
<li>Known state<br>When we write our configuration files, we describe the desired state. This is how we want our infrastructure to be. Then there’s the actual state: this is how our infrastructure looks like, right now. You can get this actual state by exploring your infrastructure in the web console, or running some describe commands against the API. And to bridge these two states, there is the known state, which is stored in the state file. Terraform uses it to keep track of all resources it already created for this set of templates. In general, this known state should be the same as the actual state. When we run the plan command, Terraform performs a refresh, and then determines what actions are necessary to achieve the desired state specified in the configuration files. When you run the apply command, Terraform executes the planned actions, and then stores the updated actual state in the state file.</li>
</ul>
<p>for example, you went to the web console and manually changed something - Terraform will detect such changes, and unless they also exist in the desired state, it will revert them. So, if we are going to treat our <strong>infrastructure as code</strong>, we should get into the mindset of not changing our sources manually.</p>
<p>Make sure the state file is ignored by Git<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> cat .gitignore</span><br><span class="line">.terraform</span><br><span class="line"></span><br><span class="line">*.tfstate*</span><br><span class="line">git add -A &amp;&amp; git commit -m &quot;Ignore TF state&quot;</span><br></pre></td></tr></table></figure></p>
<h2 id="Structuring-the-project"><a href="#Structuring-the-project" class="headerlink" title="Structuring the project"></a>Structuring the project</h2><p>Typical project structure<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">|-main.tf</span><br><span class="line">|-outputs.tf</span><br><span class="line">|-variables.tf</span><br></pre></td></tr></table></figure></p>
<p>group related resources together, and keep the configuration files to a manageable size - ideally, not longer than 200 lines of code.</p>
<h1 id="Modifying-resoureces"><a href="#Modifying-resoureces" class="headerlink" title="Modifying resoureces"></a>Modifying resoureces</h1><h2 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h2><p>Keep the code DRY- Don’t Repeat Yourself-SOFTWARE ENGINEERING PRICIPLE aimed at reducing interpretation of the same data</p>
<p>Terraform performs automatic conversion from string values to numeric and boolean values, based on context.</p>
<p>Maps are useful for selecting a value based on some other provided value.</p>
<p>A list value is an ordered sequence of strings, indexed by integers starting with 0.</p>
<p>Several ways to set variables:</p>
<ol>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">cat variables.tf</span><br><span class="line">variable &quot;s3_bucket_name&quot; &#123;</span><br><span class="line">        #default = &quot;packt-terraform-section2-bucket-stan&quot;</span><br><span class="line">        description = &quot;Name of the S3 bucket&quot;</span><br><span class="line">        type = &quot;string&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">variable &quot;s3_tags&quot; &#123;</span><br><span class="line">        type = &quot;map&quot;</span><br><span class="line"></span><br><span class="line">        default = &#123;</span><br><span class="line">                created_by = &quot;terraform&quot;</span><br><span class="line">                environment = &quot;test&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">variable &quot;s3_regions&quot; &#123;</span><br><span class="line">        type = &quot;list&quot;</span><br><span class="line">        default = [&quot;ap-southeast-2&quot;, &quot;us-west-2&quot;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">terraform plan</span><br><span class="line">var.s3_bucket_name</span><br><span class="line">  Name of the S3 bucket</span><br><span class="line"></span><br><span class="line">  Enter a value: packt-terraform-section2-bucket-stan</span><br><span class="line"></span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">terraform plan -var &apos;s3_bucket_name=&quot;packt-terraform-section2-bucket-stan&quot;&apos;</span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>3.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TF_VAR_s3_bucket_name=&quot;packt-terraform-section2-bucket-stan&quot; terraform plan</span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure></p>
<p><strong>Variable definition files</strong></p>
<ul>
<li>We can also have multiple tfvars files, and pass them explicitly to Terraform using the var file flag. If we pass several files, Terraform will merge their values - and if a particular variable is defined in more than one variable file, the last value that is filed wins. </li>
<li>Terraform automatically loads all files which match terraform.tfvars or *.auto.tfvars from the current directory</li>
<li>Other files can be passed explicitly using -var-file flag<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat terraform.tfvars</span><br><span class="line">s3_bucket_name = &quot;packt-terraform-section2-bucket-stan&quot;</span><br><span class="line">terraform plan</span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>String Interpolation</strong></p>
<ul>
<li>The process of evaluating a string expression and replacing all paceholders with their values<br><code>&quot;${var.s3_bucket_name}&quot;</code><br><strong>First-Class Expressions</strong><br><code>var.s3_bucket_name</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> cat s3.tf</span><br><span class="line">resource &quot;aws_s3_bucket&quot; &quot;main&quot; &#123;</span><br><span class="line">  bucket = &quot;$&#123;var.s3_bucket_name&#125;&quot;</span><br><span class="line">  acl    = &quot;private&quot;</span><br><span class="line"></span><br><span class="line">  tags   = &#123;</span><br><span class="line">    env = &quot;$&#123;lookup(var.s3_tags, &quot;environment&quot;)&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  region =&quot;$&#123;var.s3_regions[0]&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line">#Terraform console is a useful tool for automation scripts, as it allows you to access arbitrary attributes from a Terraform configuration.</span><br><span class="line">terraform console</span><br><span class="line">&gt; var.s3_tags</span><br><span class="line">&#123;</span><br><span class="line">  &quot;created_by&quot; = &quot;terraform&quot;</span><br><span class="line">  &quot;environment&quot; = &quot;test&quot;</span><br><span class="line">&#125;</span><br><span class="line">&gt; var.s3_tags[&quot;environment&quot;]</span><br><span class="line">test</span><br><span class="line">&gt; exit</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Local-development-workflow"><a href="#Local-development-workflow" class="headerlink" title="Local development workflow"></a>Local development workflow</h2><p><strong>Using git to store state is a bad idea</strong></p>
<ul>
<li>maintenance overhead</li>
<li>secrets in plain text</li>
</ul>
<p><strong>State</strong></p>
<ul>
<li>Local state</li>
<li>Version Control</li>
<li>Remote state</li>
<li>Backends<ul>
<li>Terraform enterprise</li>
<li>S3</li>
<li>Consul: a service networking solution to connect and secure services across any runtime platform and public or private cloud.</li>
<li>Etcd</li>
<li>HTTP</li>
</ul>
</li>
</ul>
<p>Recommend using S3<br><strong>Local Values</strong></p>
<ul>
<li><strong>Input variables</strong> are similar to arguments of a function</li>
<li><strong>Local values</strong> are analogous to local variables within the function’s scope</li>
</ul>
<p>edit variables.tf file:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">locals &#123;</span><br><span class="line">        s3_tags= &#123;</span><br><span class="line">                created_by = &quot;terraform&quot;</span><br><span class="line">                environment = &quot;$&#123;var.environment&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>we can skip refreshing it again to save a couple of seconds, here. I will pass a flag, -refresh=false.<br>The state filei(terraform.tfstate) is also used to store some metadata, such as resource dependencies, or a pointer to the provider configuration in situations where multiple AWS providers are present. Another use is to store a cache of the attribute values for all the resources in the state. When we run terraform plan, Terraform must know the current state of resources, and by default it will query the providers and sync the latest attributes from all our resources. For large infrastructure, this can be too slow, and we may get throttled at the API level - so, as a performance improvement, there is an option to disable this behavior by passing refresh=false flag.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">terraform plan -refresh=false</span><br><span class="line"></span><br><span class="line">An execution plan has been generated and is shown below.</span><br><span class="line">Resource actions are indicated with the following symbols:</span><br><span class="line">-/+ destroy and then create replacement</span><br><span class="line"></span><br><span class="line">Terraform will perform the following actions:</span><br><span class="line"></span><br><span class="line">terraform apply -auto-approve  ##skip answer yes</span><br><span class="line"></span><br><span class="line">export TF_CLI_ARGS_apply=&quot;-auto-approve&quot;</span><br></pre></td></tr></table></figure></p>
<p><strong>Common Workflow</strong></p>
<ul>
<li>validate</li>
<li>plan</li>
<li>apply</li>
<li>fmt<br><a href="https://github.com/antonbabenko/pre-commit-terraform">Pre-Commit Hooks</a><h2 id="Deleting-Resources"><a href="#Deleting-Resources" class="headerlink" title="Deleting Resources"></a>Deleting Resources</h2>1.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">terraform plan -destroy</span><br><span class="line">terraform destroy</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ol start="2">
<li>remove a resource from configuration and then run terraform plan &amp;&amp; terraform apply</li>
</ol>
<p>the 2nd one is more suted to CI/CD systems. You will most likely have some pipeline for provisioning your resources, but you may not necessarily have any automated way of destroying them, because this doesn’t happen that often. Another point is that, this way, you can destroy specific resources without having to pass special flags, which would require changes to automation scripts.</p>
<p><strong>Protect a resoure from deletion</strong><br>Use the life cycle meta-parameter.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lifecycle &#123;</span><br><span class="line">  prevent_destory = &quot;true&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Only protects against terraform destory.</p>
<h2 id="Managing-state"><a href="#Managing-state" class="headerlink" title="Managing state **"></a>Managing state <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em>**</em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h2><p><a href="https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS/tree/master/Section_3">code</a></p>
<p><strong>set up the remote state backend</strong></p>
<ol>
<li>Create the Terraform configuration section</li>
</ol>
<p>This block is special, as it configures the behavior of Terraform itself, such as setting up a backend or requiring a minimum Terraform version to execute a configuration.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  required_version = &quot;&gt; 0.11.7&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>if we have some configuration which we can’t migrate to the latest version, for some reason, we can pin it to an older version in this block. Let’s set the current version.</p>
<p><strong>Manage terraform versions for each project by Terraform switcher</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># MacOS with brew</span><br><span class="line">brew install warrensbox/tap/tfswitch</span><br><span class="line"># Linux</span><br><span class="line">curl -L https://raw.githubusercontent.com/warrensbox/terraform-switcher/release/install.sh | bash</span><br><span class="line">tfswitch</span><br></pre></td></tr></table></figure></p>
<ol start="2">
<li><p>Add a backend</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">backend &quot;s3&quot; &#123;</span><br><span class="line">    bucket = &quot;packt-terraform-bucket-stan-test-ap-southeast-2&quot;</span><br><span class="line">    key = &quot;test/backbone&quot;</span><br><span class="line">    region = &quot;ap-southeast-2&quot;</span><br><span class="line">    encrypt = &quot;true&quot;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Apply</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m &quot;Configure remote state&quot;</span><br><span class="line">git clean -fdx #clean the repository of all unchecked files</span><br><span class="line">Removing .terraform/</span><br><span class="line">Removing terraform.tfstate</span><br><span class="line">Removing terraform.tfstate.backup</span><br><span class="line">terraform init</span><br><span class="line">terraform plan #there is no more local state file anymore</span><br></pre></td></tr></table></figure>
</li>
<li><p>configuration todo</p>
</li>
</ol>
<ul>
<li><p>enforce encryption by default (here use the default one, you can use KMS instead)<br>by edit s3.tf:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server_side_encryption_configuration &#123;</span><br><span class="line">  rule &#123;</span><br><span class="line">    apply_server_side_encryption_by_default &#123;</span><br><span class="line">       sse_algorithm = &quot;AES256&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>versioning: alwasy have a way back</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">versioning &#123;</span><br><span class="line">   enabled = true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>lifecycle policy: Versioning will store all previous versions of the file, which will eventually bloat the bucket size. To reverse this, we can set a lifecycle policy. Remove all the version after 90 days. In your particular case, you might want to use a different value, or maybe move them to <strong>glacier storage</strong> instead of deleting the old files.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">lifecycle_rule &#123;</span><br><span class="line">   id      = &quot;state&quot;</span><br><span class="line">   prefix  = &quot;state/&quot;</span><br><span class="line">   enabled = true</span><br><span class="line"></span><br><span class="line">   noncurrent_version_expiration &#123;</span><br><span class="line">      days = 90</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Best Practices</strong></p>
<ul>
<li>Do not store state locally</li>
<li>Do not commit state to version control</li>
<li>If using S3:<ul>
<li>Enable versioning</li>
<li>Enforce encryption</li>
<li>Store state close to the infrastructure</li>
<li>Limit access to the bucket, consider enabling log in</li>
</ul>
</li>
</ul>
<h1 id="Building-a-multi-tier-environment"><a href="#Building-a-multi-tier-environment" class="headerlink" title="Building a multi-tier environment"></a>Building a multi-tier environment</h1><p><strong>What we will build?</strong></p>
<ul>
<li>Network layer-Virtual Private Cloud (VPC), internet gateway, public and private subnets, NAT gateway, and a bastion host)</li>
<li>Relational Database Service (RDS) instance running PostgreSQL</li>
<li>Elastic Container Service (ECS) cluster to host a dockerised app<br><strong>Provider Caching</strong></li>
<li><strong>terraform init</strong> downloads providers separately for each project</li>
<li>We can cache them by setting an environment variable<br>  export TF_PLUGIN_VACHE_DIR=”$HOME/.terraform.d/plugin-cache”<br><a href="https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS/tree/master/Section_4/vpc">code</a><br><img src="https://i.imgur.com/Rzhlc11.png" alt="AWS VPC"><br><strong>Count Meta-Parameter</strong></li>
<li>Available to all resources</li>
<li>Allows creating multiple copies of a resouce without repeating its configuration</li>
<li>Helps keep your infrastructure code <strong>DRY</strong><br><strong>Splat Expression</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;aws_nat_gateway&quot; &quot;main&quot; &#123;</span><br><span class="line">  count         = &quot;$&#123;length(var.availability_zones)&#125;&quot;</span><br><span class="line">  subnet_id     = &quot;$&#123;element(aws_subnet.public.*.id, count.index)&#125;&quot;</span><br><span class="line">  allocation_id = &quot;$&#123;element(aws_eip.nat.*.id, count.index)&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>The challenge, here, is that the gateways need to reference the subnets and the IPS that we created, but because we used count, we don’t have a direct reference to each resource. We can resolve this by using a splat expression, which you can see in action where we reference the subnet ID and the allocation ID. A splat expression allows to obtain a list of attribute values from a set of resources created using the count argument. Notice this asterisk, which represents all values in the generated list.</p>
<h2 id="Organizing-data-with-output-variables"><a href="#Organizing-data-with-output-variables" class="headerlink" title="Organizing data with output variables"></a>Organizing data with output variables</h2><p><strong>Resources and data sources</strong></p>
<ul>
<li>Resources provide <strong>Create, Read, Update</strong>,and <strong>Delete</strong> functionality (CRUD)</li>
<li>Data srouces support <strong>read</strong> operations only<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data &quot;aws_ami&quot; &quot;amazon_linux&quot; &#123;</span><br><span class="line">  most_recent = true</span><br><span class="line">  filter &#123;</span><br><span class="line">    name   = &quot;name&quot;</span><br><span class="line">    values = [&quot;amzn-ami-*-x86_64-gp2&quot;]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Output Variables</strong></p>
<ul>
<li>Expose important resource attributes and make tme easier to query</li>
<li>Outputs are exposed to the user and stored in the state file during terraform apply</li>
<li>A single output block configures a single variable<br><strong>Example Output</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output &quot;vpc_id&quot; &#123;</span><br><span class="line">   value = &quot;$&#123;aws_vpc.main.id&#125;&quot;</span><br><span class="line">   description = &quot;VPC id&quot;</span><br><span class="line">   sensitive = false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>After we run the apply once, the outputs are stored in the state file - so, the next time we need to get them, we can use <code>terraform output</code>.<br>or<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">terraform output public_subnets</span><br></pre></td></tr></table></figure></p>
<p><strong>provider version</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> terraform providers</span><br><span class="line">.</span><br><span class="line">├── provider.aws 1.31</span><br><span class="line">└── provider.template</span><br><span class="line">ls -l ~/.terraform.d/plugin-cache/linux_amd64</span><br></pre></td></tr></table></figure></p>
<h2 id="Integrating-components-in-a-complex-environment"><a href="#Integrating-components-in-a-complex-environment" class="headerlink" title="Integrating components in a complex environment"></a>Integrating components in a complex environment</h2><p><img src="https://i.imgur.com/LcsUUkG.png" alt="Adding a database server"><br><strong>Steps to add a DB server</strong></p>
<ol>
<li>Create a VPC (done)</li>
<li>Add Subnets to the VPC (done)</li>
<li>Create a DB Subnet Group</li>
<li>Create a VPC Secruity Group</li>
<li>Create a DB Instance in the VPC</li>
</ol>
<p>Integrate separate Terraform configurations while keeping them in different projects</p>
<p>Remote state serves as a centralized source of truth:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> cat data_sources.tf</span><br><span class="line"># Remote state</span><br><span class="line">data &quot;terraform_remote_state&quot; &quot;vpc&quot; &#123;</span><br><span class="line">  backend = &quot;s3&quot;</span><br><span class="line"></span><br><span class="line">  config &#123;</span><br><span class="line">    bucket = &quot;packt-terraform-bucket-stan-test-$&#123;var.region&#125;&quot;</span><br><span class="line">    key    = &quot;test/vpc&quot;</span><br><span class="line">    region = &quot;$&#123;var.region&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Remote state allows us to share information between current projects, and to build our infrastructures in small atomic configurations focused on one thing.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db_subnet_group.tf</span><br><span class="line">subnet_ids = [&quot;$&#123;data.terraform_remote_state.vpc.private_subnets&#125;&quot;]</span><br></pre></td></tr></table></figure></p>
<p>Notice the interpolation syntax that we use.first, specify that it’s a data source - then its type, terraform remote state. Then comes the name of particular remote state, VPC, and lastly the attribute that we are interested in. </p>
<h2 id="Using-templates"><a href="#Using-templates" class="headerlink" title="Using templates"></a>Using templates</h2><p><img src="https://i.imgur.com/IjCKZfO.png" alt="Application tier"><br>deploy a small but realistic web application into our VPC. Our app runs in Docker, so we will provision an LST container service cluster - <strong>ECS</strong> - to host it in our private subnets. We will use <strong>Fargate</strong>, which is a managed compute and orchestration engine, so we won’t need to maintain EC2 instances that run our containers. </p>
<p><strong>Use Terraform templates to compose complex string inputs</strong><br>App: a REST API for a todo applicaton, written in Go. It uses Postgres scale database as its backend.</p>
<p><a href="https://hub.docker.com/r/endofcake/go-todo-rest-api-example/">public image on Docker hub</a></p>
<ol>
<li>provision an ECS cluster<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat ecs_cluster.tf</span><br><span class="line">resource &quot;aws_ecs_cluster&quot; &quot;main&quot; &#123;</span><br><span class="line">  name = &quot;$&#123;var.ecs_cluster_name&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>Partitioning Infrastructure</strong></p>
<ul>
<li>If the resources are likely to be created and destryoed together, they belong together</li>
<li>If some resource can be used by multiple other resources, it’s better to keep it sparate (VPC,RDS, and ECS cluster)</li>
</ul>
<p>template eg.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">bastion.tf</span><br><span class="line"># User data</span><br><span class="line">data &quot;template_file&quot; &quot;user_data&quot; &#123;</span><br><span class="line">  template = &quot;$&#123;file(&quot;$&#123;path.module&#125;/templates/user_data.sh&quot;)&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/tmplates/user_data.sh</span><br><span class="line">#!/bin/env bash</span><br><span class="line"></span><br><span class="line">set -euo pipefail</span><br><span class="line">exec &gt; &gt;(tee /var/log/user-data.log|logger -t user-data -s 2&gt;/dev/console) 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line">echo &quot;Starting user data...&quot;</span><br><span class="line">yum update -y</span><br><span class="line">yum install -y postgresql96.x86_64</span><br><span class="line">touch /home/ec2-user/success</span><br><span class="line">echo &quot;All done&quot;</span><br></pre></td></tr></table></figure></p>
<p>Next, I create template_cloudinit_config data source, and pull in the rendered template file. cloudinit_config allows us to compose multi-part user data scripts.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data &quot;template_cloudinit_config&quot; &quot;user_data&quot; &#123;</span><br><span class="line">  gzip          = true</span><br><span class="line">  base64_encode = true</span><br><span class="line"></span><br><span class="line">  part &#123;</span><br><span class="line">    content_type = &quot;text/x-shellscript&quot;</span><br><span class="line">    content      = &quot;$&#123;data.template_file.user_data.rendered&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>If we run terraform apply with this configuration on Windows, it most likely wouldn’t work - the problem is that Windows use a different line break tag, which is not valid on Linux. Windows use both carriage return and line feed, while Linux only uses line feed. The easiest way to check the line break tag is to look at the bottom right corner of the editor. Anyway, long story short, we want to make sure that this script is valid, even if we deploy our configuration from a Windows machine. This is probably the only case where there is any difference between running Terraform on Linux and on Windows. There are two changes that you should make to resolve this.</p>
<ol>
<li><p>add a gitattributes file</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat .gitattributes</span><br><span class="line"># Always LF</span><br><span class="line">*.sh text eol=lf</span><br></pre></td></tr></table></figure>
</li>
<li><p>use EditorConfig plugin to define how our text editor displays and saves our code<br><img src="https://i.imgur.com/55JD2B3.png" alt="editorconfig plugin"> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat .editorconfig</span><br><span class="line">[*.sh]</span><br><span class="line">end_of_line = lf</span><br><span class="line">indent_size = 2</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><a href="https://github.com/stanosaka/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS/tree/master/Section_4/ecs_app_todo">ecs app todo code</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">~/terraform/ecs_app_todo|</span><br><span class="line">⇒  tree</span><br><span class="line">.</span><br><span class="line">├── cloudwatch.tf</span><br><span class="line">├── data_sources.tf</span><br><span class="line">├── ecs_task.tf</span><br><span class="line">├── graph.png</span><br><span class="line">├── iam.tf</span><br><span class="line">├── lb.tf</span><br><span class="line">├── outputs.tf</span><br><span class="line">├── providers.tf</span><br><span class="line">├── templates</span><br><span class="line">│   └── ecs_task.tpl</span><br><span class="line">├── terraform.tfvars</span><br><span class="line">└── variables.tf</span><br></pre></td></tr></table></figure></p>
<p>templates/ecs_task.tpl file: ECS task definition. It describes which Docker images to use, the required resources, and other configurations necessary to launch the containers. As you can see, it’s a JSON block, which I’ve extracted into a template. It requires a few parameters, mostly to set up the connection to the database. </p>
<p>ecs_task.tf file: This is the Terraform configuration of our ECS task. I’m using the familiar template file data source, and I’m passing the required variables using the vars parameter, which accepts a map of variables. Some of the variables come from the tfvars file, but many are imported from the remote state. </p>
<p>data_sources.tf file: If we check out our data sources, we see that we’re pulling in remote state from all three projects that we created earlier. </p>
<p>lb.tf file: another important resource that we are creating is the load balancer, which distributes income and application traffic across multiple targets, for high availability. It will also allow us to connect to our service from the public internet, and here is the security group which allows public access</p>
<p><strong>confirm it’s working</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">curl -d &apos;&#123;&quot;title&quot;:&quot;sample project&quot;&#125;&apos; -H &quot;Content-Type: application/json&quot; -X POST todoapp-alb-91218331.ap-southeast-2.elb.amazonaws.com/projects</span><br><span class="line">&#123;&quot;ID&quot;:1,&quot;CreatedAt&quot;:&quot;2019-07-21T12:20:38.881103057Z&quot;,&quot;UpdatedAt&quot;:&quot;2019-07-21T12:20:38.881103057Z&quot;,&quot;DeletedAt&quot;:null,&quot;title&quot;:&quot;sample project&quot;,&quot;archived&quot;:false,&quot;tasks&quot;:null&#125;</span><br><span class="line"></span><br><span class="line">curl todoapp-alb-91218331.ap-southeast-2.elb.amazonaws.com/projects</span><br><span class="line">[&#123;&quot;ID&quot;:1,&quot;CreatedAt&quot;:&quot;2019-07-21T12:20:38.881103Z&quot;,&quot;UpdatedAt&quot;:&quot;2019-07-21T12:20:38.881103Z&quot;,&quot;DeletedAt&quot;:null,&quot;title&quot;:&quot;sample project&quot;,&quot;archived&quot;:false,&quot;tasks&quot;:null&#125;]</span><br><span class="line"></span><br><span class="line">ssh bastion</span><br><span class="line">export PGPASSWORD=foobar</span><br><span class="line">export PGHOST=todoapp.foobar.ap-southeast-2.rds.amazonaws.com</span><br><span class="line">psql -U terraform -d todoapp</span><br><span class="line">todoapp=&gt; \d+</span><br><span class="line">                             List of relations</span><br><span class="line"> Schema |      Name       |   Type   |   Owner   |    Size    | Description</span><br><span class="line">--------+-----------------+----------+-----------+------------+-------------</span><br><span class="line"> public | projects        | table    | terraform | 16 kB      |</span><br><span class="line"> public | projects_id_seq | sequence | terraform | 8192 bytes |</span><br><span class="line"> public | tasks           | table    | terraform | 8192 bytes |</span><br><span class="line"> public | tasks_id_seq    | sequence | terraform | 8192 bytes |</span><br><span class="line">(4 rows)</span><br><span class="line">todoapp=&gt; select * from projects;</span><br><span class="line"> id |          created_at           |          updated_at           | deleted_at |     title      | archived</span><br><span class="line">----+-------------------------------+-------------------------------+------------+----------------+----------</span><br><span class="line">  1 | 2019-07-21 12:20:38.881103+00 | 2019-07-21 12:20:38.881103+00 |            | sample project | f</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure></p>
<h2 id="Working-with-dependency-graph"><a href="#Working-with-dependency-graph" class="headerlink" title="Working with dependency graph"></a>Working with dependency graph</h2><p><strong>Dependency graph</strong></p>
<ul>
<li>All resources in the configuration are organized into a graph</li>
<li>The graph is used to determine the order in which the resources are created<br><img src="https://i.imgur.com/9swFk8u.png" alt="Directed acyclic graph"><br>Terraform organizes all resources in a configuration in a directed acyclic graph. What this means in plain English is that the dependencies between the resources go in one direction, and there can be no cycles. So, no circular dependencies. When we run the plan command, Terraform builds this graph, checks whether there are any cycles, and then determines which operations can be run in parallel. By default, up to ten nodes in the graph can be processed concurrently. We can control this setting using the parallelism flag on the plan, apply, and destroy commands, but in most cases this is not required.<br><strong>Parallelism</strong></li>
<li>Up to 10 nodes can be processed concurrently by default</li>
<li>Conifgurable with <strong>-parallemism</strong> flag for plan, apply, and destroy commands (advanced setting)<br><strong>Dependencies</strong></li>
<li><p>Implicit-one resource references another resource using the interpolation syntax</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;aws_lb&quot; &quot;todo_app&quot; &#123;</span><br><span class="line">    security_groups = [&quot;$&#123;aws_security_group.lb.id&#125;&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Explicit-using depends_on metaparameter<br> <code>depends_on = [&quot;aws_security_group.lb&quot;]</code></p>
</li>
</ul>
<p>Use explicit dependencies to resolve race conditions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Have to set an explicit dependency here to avoid</span><br><span class="line">  # race condition with LB creation</span><br><span class="line">depends_on = [&quot;aws_lb_listener.todo_app&quot;]</span><br></pre></td></tr></table></figure></p>
<p><strong>tools</strong></p>
<ol>
<li><p><a href="http://graphviz.gitlab.io/download/">Graphviz</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">terraform graph|dot -Tpng &gt; graph.png</span><br><span class="line">terraform plan</span><br><span class="line">terraform graph -draw-cycles|dot -Tpng &gt; graph.png</span><br></pre></td></tr></table></figure>
</li>
<li><p><a href="https://github.com/28mm/blast-radius">blast radius</a></p>
</li>
</ol>
<h2 id="Main-takeaways"><a href="#Main-takeaways" class="headerlink" title="Main takeaways"></a>Main takeaways</h2><ul>
<li>Use outputs and remote state data source to integrate stacks of resources in a complex environment</li>
<li>Keep your code DRY by using <em>count</em> parameter and splat expressions</li>
<li>Use <strong>templates</strong> to generate complex string inputs, such as user data scripts or ECS task definitions</li>
</ul>
<h1 id="Creating-reusable-components-with-moduels"><a href="#Creating-reusable-components-with-moduels" class="headerlink" title="Creating reusable components with moduels"></a>Creating reusable components with moduels</h1><h2 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h2><ul>
<li>Self-contained packages of Terraform configurations that are managed as a group<br>When we want to avoid writing duplicate code in a general-purpose programming language, we usually write a library. In, Terraform, we can put our code in a <strong>module</strong>.</li>
<li>Improve code resue</li>
<li>Provide an abstration layer<br>for example, you may need to add a vault cluster to your environment, and the vault is another great Hashicorp tool which is used for managing secrets, which requires dozens of components - but instead of thinking about individual security groups or EC2 instances, you can treat all these resources as a single group which requires some parameters, and gives you a ready-to-use vault cluster. </li>
<li>Can be teated as blackbox</li>
<li>Share best practices within an organization</li>
<li>Versioned artifacts</li>
</ul>
<h2 id="Creating-the-first-module"><a href="#Creating-the-first-module" class="headerlink" title="Creating the first module"></a>Creating the first module</h2><ul>
<li>Root module:<ul>
<li>The current working dirctory holding Terraform files</li>
</ul>
</li>
<li>Child modules:<ul>
<li>All modules sourced by the root (parent) module<br><strong>Delaring Modules</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">module &quot;child&quot; &#123;</span><br><span class="line">source = &quot;./child&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ol>
<li>rename ecs app project to module.ecs_app_web<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat main.tf</span><br><span class="line">module &quot;child&quot; &#123;</span><br><span class="line">    source = &quot;../module.ecs_app_web&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>terraform get</strong></p>
<ul>
<li>terraform get: Download modules referenced in the root module</li>
<li>terraform get -update: Check the downloaded modules for updates and download the new versions. if present<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> terraform get -update</span><br><span class="line">- module.child</span><br><span class="line">  Updating source &quot;../module.ecs_app_web&quot;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>When you run terraform get, the local modules will be simlinked into .terraform directory, so you can inspect what’s there if you notice some unexpected behavior.</p>
<ol start="2">
<li>copy terraform.tfvars and variables.tf, modify main.tf file, add<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">region = &quot;$&#123;var.region&#125;&quot; </span><br><span class="line">app_image_version = &quot;$&#123;var.app_image_version&#125;&quot; </span><br><span class="line">app_image_repository = &quot;$&#123;var.app_image_repository&#125;&quot; </span><br><span class="line">app_name = &quot;$&#123;var.app_name&#125;&quot; </span><br><span class="line">container_port = &quot;$&#123;var.container_port&#125;&quot; </span><br><span class="line">desired_count = &quot;$&#123;var.desired_count&#125;&quot; </span><br><span class="line">pgsslmode = &quot;$&#123;var.pgsslmode&#125;&quot; </span><br><span class="line">network_mode = &quot;$&#123;var.network_mode&#125;&quot; </span><br><span class="line">requires_compatibilities = &quot;$&#123;var.requires_compatibilities&#125;&quot; </span><br><span class="line">launch_type = &quot;$&#123;var.launch_type&#125;&quot; </span><br><span class="line">health_check_path = &quot;$&#123;var.health_check_path&#125;&quot;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>terraform providers</strong></p>
<ul>
<li>terraform providers:<ul>
<li>Print information about the providers used in the currrent configuration</li>
</ul>
</li>
<li>terraform providers [config-path]:<ul>
<li>Pass an explicit path to the configuration instead of using the current working directory by default<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> terraform providers</span><br><span class="line">.</span><br><span class="line">└── module.child</span><br><span class="line">    ├── provider.aws 1.31</span><br><span class="line">    ├── provider.template 1.0.0</span><br><span class="line">    └── provider.terraform</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>There is only one module, and it uses two providers - AWS and Template, plus a special provider called Terraform, which is responsible for working with the remote state backend.</p>
<p><strong>best practices</strong>: Keep explicit provider configurations only in the root module, and pass them down to descendant modules.</p>
<p><strong>Two wasy pass providers</strong></p>
<ul>
<li>the most common approach: let the descendant modules inherit the providers implicitly - that is, automatically</li>
<li>have several providers of the same type, and then pass them explicitly by alias; this can be useful if we need to create resources in different AWS regions, for example</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">root@stan-OptiPlex-380:~stan/Doc/Terraform/ecs_app_todo|master⚡</span><br><span class="line">⇒  mv ../module.ecs_app_web/providers.tf ./</span><br><span class="line">root@stan-OptiPlex-380:~stan/Doc/Terraform/ecs_app_todo|master⚡</span><br><span class="line">⇒  terraform init</span><br><span class="line">Initializing modules...</span><br><span class="line">- module.child</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line"></span><br><span class="line">Successfully configured the backend &quot;s3&quot;! Terraform will automatically</span><br><span class="line">use this backend unless the backend configuration changes.</span><br><span class="line"></span><br><span class="line">Initializing provider plugins...</span><br><span class="line">- Checking for available provider plugins on https://releases.hashicorp.com...</span><br><span class="line">- Downloading plugin for provider &quot;aws&quot; (1.31.0)...</span><br><span class="line">- Downloading plugin for provider &quot;template&quot; (1.0.0)...</span><br><span class="line"></span><br><span class="line">Terraform has been successfully initialized!</span><br><span class="line"></span><br><span class="line">You may now begin working with Terraform. Try running &quot;terraform plan&quot; to see</span><br><span class="line">any changes that are required for your infrastructure. All Terraform commands</span><br><span class="line">should now work.</span><br><span class="line"></span><br><span class="line">If you ever set or change modules or backend configuration for Terraform,</span><br><span class="line">rerun this command to reinitialize your working directory. If you forget, other</span><br><span class="line">commands will detect it and remind you to do so if necessary.</span><br><span class="line">root@stan-OptiPlex-380:~stan/Doc/Terraform/ecs_app_todo|master⚡</span><br><span class="line">⇒  terraform providers</span><br><span class="line">.</span><br><span class="line">├── provider.aws 1.31</span><br><span class="line">├── provider.template 1.0.0</span><br><span class="line">├── provider.terraform (from state)</span><br><span class="line">└── module.child</span><br><span class="line">    ├── provider.aws (inherited)</span><br><span class="line">    ├── provider.template (inherited)</span><br><span class="line">    └── provider.terraform</span><br></pre></td></tr></table></figure>
<p><strong>Use module-relative path for embedded files (${path.module})</strong></p>
<p><strong>Encapsulation</strong></p>
<ul>
<li>A language mechanism for restricting direct access to some of the object’s components</li>
</ul>
<p>we can choose to make the module as transparent as possible - and in this case, it would inject all dependencies from the root module, and keep no data sources in the child module</p>
<h1 id="Error-and-debug"><a href="#Error-and-debug" class="headerlink" title="Error and debug"></a>Error and debug</h1><ol>
<li>Error 1:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">terraform init</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line">Backend configuration changed!</span><br><span class="line"></span><br><span class="line">Terraform has detected that the configuration specified for the backend</span><br><span class="line">has changed. Terraform will now check for existing state in the backends.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Error inspecting states in the &quot;s3&quot; backend:</span><br><span class="line">    NoSuchBucket: The specified bucket does not exist</span><br><span class="line">        status code: 404, request id: E51C641611FF2763, host id: 9AN52en4R7RaZueavAicV5/N01SahL+Y1TZBT8TGnYBYYD5ywWxPKgkiiqDx8+FsgkwNNyadfSU=</span><br><span class="line"></span><br><span class="line">Prior to changing backends, Terraform inspects the source and destination</span><br><span class="line">states to determine what kind of migration steps need to be taken, if any.</span><br><span class="line">Terraform failed to load the states. The data in both the source and the</span><br><span class="line">destination remain unmodified. Please resolve the above error and try again.</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>Debug mode:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> TF_LOG=trace terraform init</span><br><span class="line">2019/07/21 11:50:39 [INFO] Terraform version: 0.11.7  41e50bd32a8825a84535e353c3674af8ce799161</span><br><span class="line">2019/07/21 11:50:39 [INFO] Go runtime version: go1.10.1</span><br><span class="line">2019/07/21 11:50:39 [INFO] CLI args: []string&#123;&quot;/root/.terraform.versions/terraform_0.11.7&quot;, &quot;init&quot;&#125;</span><br><span class="line">2019/07/21 11:50:39 [DEBUG] Attempting to open CLI config file: /root/.terraformrc</span><br><span class="line">2019/07/21 11:50:39 [DEBUG] File doesn&apos;t exist, but doesn&apos;t need to. Ignoring.</span><br><span class="line">2019/07/21 11:50:39 [INFO] CLI command args: []string&#123;&quot;init&quot;&#125;</span><br><span class="line">2019/07/21 11:50:39 [DEBUG] command: loading backend config file: /root/terraform/vpc</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line">2019/07/21 11:50:39 [TRACE] Preserving existing state linea</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<ol start="2">
<li>Error2:<br><img src="https://i.imgur.com/NvWneaV.png" alt="error2"><br>if ecs try to connect to localhost as rds, and couldnot connect sucessfully</li>
</ol>
<p>Debug:<br>ecs_task.tpl pg environment vars are all missing</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/aws/">aws</a><a href="/tags/terraform/">terraform</a><a href="/tags/automation/">automation</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>







  <nav id="page-nav" class="clearfix">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  
<div class="github-card">
<p class="asidetitle">Github Card</p>
<div class="github-card" data-github="stanosaka" data-width="220" data-height="119" data-theme="medium">
<script type="text/javascript" src="//cdn.jsdelivr.net/github-cards/latest/widget.js" ></script>
</div>
  </div>



  

  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Devops/" title="Devops">Devops<sup>7</sup></a></li>
			
		
			
				<li><a href="/tags/aws/" title="aws">aws<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/centos/" title="centos">centos<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/Jenkins/" title="Jenkins">Jenkins<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/CD-CI/" title="CD/CI">CD/CI<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/git/" title="git">git<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/tomcat/" title="tomcat">tomcat<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/saltstack/" title="saltstack">saltstack<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/zabbix/" title="zabbix">zabbix<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/docker/" title="docker">docker<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/ec2/" title="ec2">ec2<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/backup/" title="backup">backup<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/github/" title="github">github<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/nginx/" title="nginx">nginx<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Pipeline/" title="Pipeline">Pipeline<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Linux/" title="Linux">Linux<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/agile/" title="agile">agile<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/software-development/" title="software development">software development<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/agile-development/" title="agile development">agile development<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://zety.com/mycv/00root" target="_blank" title="Stan&#39;s resume">Stan&#39;s resume</a>
            
          </li>
        
          <li>
            
            	<a href="https://cloud.ibm.com/docs/tutorials?topic=solution-tutorials-tutorials" target="_blank" title="IBM cloud solution tutorial">IBM cloud solution tutorial</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/aws-samples" target="_blank" title="AWS Samples">AWS Samples</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/bikrambora/devlab-launchpad" target="_blank" title="Welcome to Dev Labs">Dev Labs</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/ansible/ansible-examples" target="_blank" title="Ansible GitHub repo">Ansible GitHub repo</a>
            
          </li>
        
          <li>
            
            	<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html" target="_blank" title="Ansible Best Practices">Ansible Best Practices</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.python.org/" target="_blank" title="Python doc">Python doc</a>
            
          </li>
        
          <li>
            
            	<a href="http://rogerdudler.github.io/git-guide" target="_blank" title="Git commands">Git commands</a>
            
          </li>
        
          <li>
            
            	<a href="https://docs.docker.com/engine/reference/builder/" target="_blank" title="Dockerfile reference">Dockerfile reference</a>
            
          </li>
        
          <li>
            
            	<a href="http://bit.ly/2mTQr8l" target="_blank" title="Linux Command line cheat sheet">Linux Command line cheat sheet</a>
            
          </li>
        
          <li>
            
            	<a href="http://bit.ly/2EPHxze" target="_blank" title="PowerShell Basic Cheat Sheet">PowerShell Basic Cheat Sheet</a>
            
          </li>
        
          <li>
            
            	<a href="http://sed.sourceforge.net/sed1line_zh-CN.html" target="_blank" title="sed cheatsheet">sed cheatsheet</a>
            
          </li>
        
          <li>
            
            	<a href="http://obsavus1p.bkt.clouddn.com/vim_cheat_sheet_for_programmers_print.png" target="_blank" title="vim cheatsheet">vim cheatsheet</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.gitbook.com/book/yeasy/docker_practice/details" target="_blank" title="Learn Docker">Learn Docker</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.unixhot.com/page/ops" target="_blank" title="运维知识体系">运维知识体系</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.tecmint.com/" target="_blank" title="tecmint">tecmint</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.lib.uts.edu.au" target="_blank" title="shoujin.wang@student.uts.edu.au">UTS Library</a>
            
          </li>
        
          <li>
            
            	<a href="https://7esl.com" target="_blank" title="ESL">ESL</a>
            
          </li>
        
          <li>
            
            	<a href="https://stanchou.wordpress.com" target="_blank" title="Stan&#39;s wordpress">Stan&#39;s wordpress</a>
            
          </li>
        
          <li>
            
            	<a href="https://docs.00root.com" target="_blank" title="Stan&#39;s gitbook">Stan&#39;s gitbook</a>
            
          </li>
        
          <li>
            
            	<a href="https://api.ipify.org" target="_blank" title="Your IP address">Your IP address</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/stanosaka/oreilly_sql_fundamentals_for_data/blob/master/notes_and_slides/sql_fundamentals_notes.md" target="_blank" title="sql fundamentials">sql fundamentials</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Stan live in Sydney. <br/>
			I am a lifelong technology learner.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		<a href="https://github.com/stanosaka" target="_blank" class="icon-github" title="github"></a>
		
		
		<a href="http://stackoverflow.com/users/6724938" target="_blank" class="icon-stack-overflow" title="stackoverflow"></a>
		
		
		<a href="https://twitter.com/stanosaka" target="_blank" class="icon-twitter" title="twitter"></a>
		
		
		<a href="https://www.facebook.com/stan.osaka" target="_blank" class="icon-facebook" title="facebook"></a>
		
		
		<a href="https://www.linkedin.com/in/00root" target="_blank" class="icon-linkedin" title="linkedin"></a>
		
		
		<a href="https://www.douban.com/people/btw01v" target="_blank" class="icon-douban" title="豆瓣"></a>
		
		
		<a href="http://www.zhihu.com/people/stan-22-82" target="_blank" class="icon-zhihu" title="知乎"></a>
		
		
		
		<a href="mailto:devops@cwzhou.win" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2019 
		
		<a href="/about" target="_blank" title="Stan Zhou">Stan Zhou</a>
		
		
		</p>
</div>
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>


        
  	    <script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script>
            <script>
               if (window.mermaid) {
                  mermaid.initialize({theme: 'forest'});
               }
            </script>
        












<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
