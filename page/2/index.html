
 <!DOCTYPE HTML>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  
    <title>Stan Zhou&#39;s Hexo Technical Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Stan Zhou">
    

    
    <meta name="description" content="Infrastructure as code">
<meta property="og:type" content="website">
<meta property="og:title" content="Stan Zhou&#39;s Hexo Technical Blog">
<meta property="og:url" content="http://223.95.78.227/page/2/index.html">
<meta property="og:site_name" content="Stan Zhou&#39;s Hexo Technical Blog">
<meta property="og:description" content="Infrastructure as code">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Stan Zhou&#39;s Hexo Technical Blog">
<meta name="twitter:description" content="Infrastructure as code">
<meta name="twitter:creator" content="@stanosaka">

    
    <link rel="alternative" href="/atom.xml" title="Stan Zhou&#39;s Hexo Technical Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/toad.ico">
    
    
    <link rel="apple-touch-icon" href="/img/toadman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/toadman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>
</html>
  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/toadman.png" alt="Stan Zhou&#39;s Hexo Technical Blog" title="Stan Zhou&#39;s Hexo Technical Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Stan Zhou&#39;s Hexo Technical Blog">Stan Zhou&#39;s Hexo Technical Blog</a></h1>
				<h2 class="blog-motto">Innovation Evangelist</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:223.95.78.227">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/29/jenkins-blue-ocean/" title="Jenkins Pipeline" itemprop="url">Jenkins Pipeline</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-29T01:00:54.000Z" itemprop="datePublished"> Published 2019-07-29</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="An-Example-of-Declarative-Pipeline"><a href="#An-Example-of-Declarative-Pipeline" class="headerlink" title="An Example of Declarative Pipeline:"></a>An Example of Declarative Pipeline:</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">       node &#123;</span><br><span class="line">           label <span class="string">'master'</span></span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(<span class="string">'Build'</span>) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh <span class="string">'mvn clean verify -DskipITs=true'</span></span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage (<span class="string">'Static Code Analysis'</span>) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               sh <span class="string">'mvn clean verify sonar:sonar'</span></span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       stage (<span class="string">'Publish to Artifactory'</span>) &#123;</span><br><span class="line">           steps &#123;</span><br><span class="line">               script &#123;</span><br><span class="line">                   def server = Artifactory.server <span class="string">'Default Artifactory'</span></span><br><span class="line">                   def uploadSpec = <span class="string">""</span><span class="string">"&#123;</span></span><br><span class="line"><span class="string">                       "</span>files<span class="string">": [</span></span><br><span class="line"><span class="string">                           &#123;</span></span><br><span class="line"><span class="string">                               "</span>pattern<span class="string">": "</span>target/*.war<span class="string">",</span></span><br><span class="line"><span class="string">                               "</span>target<span class="string">": "</span>helloworld/<span class="variable">$&#123;BUILD_NUMBER&#125;</span>/<span class="string">",</span></span><br><span class="line"><span class="string">                               "</span>pattern<span class="string">": "</span>Unit-Tested=Yes<span class="string">",</span></span><br><span class="line"><span class="string">                           &#125;</span></span><br><span class="line"><span class="string">                        ]</span></span><br><span class="line"><span class="string">                    &#125;"</span><span class="string">""</span></span><br><span class="line">                    server.upload(uploadSpec)</span><br><span class="line">		&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Jenkinsfile</strong><br>A Jenkinsfile is a file that contains Pipeline code.</p>
<h1 id="Shared-Library"><a href="#Shared-Library" class="headerlink" title="Shared Library"></a>Shared Library</h1><p>A Jenkins Shared Library is an external source control repository containing your complex Groovy code. It acts like a function that could be used on-demand inside your Declarative Pipeline.</p>
<p><em>A Groovy Script (example.groovy)Inside Jenkins Shared Library Repository:</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def greet(message) &#123;</span><br><span class="line">   echo &quot;Hello $&#123;message&#125;, welcome to Jenkins Blue Ocean.&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>Jenkins Declarative Pipeline Utilizing the Shared Library:</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@Library(&apos;Example_shared_Library&apos;) _</span><br><span class="line"></span><br><span class="line">pipeline &#123;</span><br><span class="line">  agent none</span><br><span class="line">  stage (&apos;Example&apos;) &#123;</span><br><span class="line">     steps &#123;</span><br><span class="line">        script &#123;</span><br><span class="line">           example.greet &apos;Readers&apos;</span><br><span class="line">        &#125;</span><br><span class="line">     &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Setting-up-Jenkins-Blue-Ocean"><a href="#Setting-up-Jenkins-Blue-Ocean" class="headerlink" title="Setting up Jenkins Blue Ocean"></a>Setting up Jenkins Blue Ocean</h1><h2 id="Setting-up-Blue-Ocean-using-docker"><a href="#Setting-up-Blue-Ocean-using-docker" class="headerlink" title="Setting up Blue Ocean using docker"></a>Setting up Blue Ocean using docker</h2><p><strong>Downloading the latest Jenkins Blue Ocean</strong></p>
<ol>
<li><p>docker pull jenkinsci/blueocean</p>
</li>
<li><p>To list the downloaded docker image: docker images</p>
</li>
</ol>
<p>Docker containers generate and use data. When a container gets deleted, its relevant data also gets lost.<br>To make the data persistent, we use docker volumes.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker volume create jenkins_home</span><br><span class="line">docker volume ls</span><br><span class="line">docker volume inspect jenkins_home <span class="comment">#get detailed info about docker volume</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Run-Jenkins-blue-ocrean-behind-a-reverse-proxy"><a href="#Run-Jenkins-blue-ocrean-behind-a-reverse-proxy" class="headerlink" title="Run Jenkins blue ocrean behind a reverse proxy"></a>Run Jenkins blue ocrean behind a reverse proxy</h2><ol>
<li><p>Run a Jenkins container</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name jenkins -v jenkins_home:/var/jenkins_home jenkinsci/blueocean</span><br></pre></td></tr></table></figure>
</li>
<li><p>Download the docker image for Nginx</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p>Spawn a Dockr container for Nginx. Also, link the nginx container to the jenkins container using the <em>–link</em> option.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name ngingx -p 80:80 --link jenkins nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p>Get inside the Ningx container using the <em>docker exec</em> command</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it ningx /bin/bash</span><br></pre></td></tr></table></figure>
</li>
<li><p>Update the Ubuntu package lists<br><code>apt-get update</code></p>
</li>
<li>Install vim text editor<br><code>apt-get install vim</code></li>
<li><p>Take the backup of the default.conf file inside /etc/nginx/conf.d/</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp etc/ningx/conf.d/default.conf etc/nginx/conf.d/default.conf.backup</span><br></pre></td></tr></table></figure>
</li>
<li><p>Next, replace the content of the default.conf file with the following:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">upstream jenkins &#123;</span><br><span class="line">  server jenkins:8080;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">  listen 80;</span><br><span class="line">  server_name jenkins.example.com;</span><br><span class="line">  </span><br><span class="line">  location / &#123;</span><br><span class="line">     proxy_pass         http://jenkins;</span><br><span class="line">     proxy_set_header   Host <span class="variable">$host</span>;</span><br><span class="line">     proxy_set_header   X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">     proxy_set_header   X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">     proxy_set_header   X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Exit the Nginx container.<br><code>exit</code></p>
</li>
<li>Restart the Nginx container.<br><code>docker restart nginx</code></li>
<li>Run the following docker command to fetch the content of initialAdminPassword file.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it jenkins /bin/bash -c \ <span class="string">"cat /var/jenkins_home/secrets/initialAdminPassword"</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Creating-Pipeline"><a href="#Creating-Pipeline" class="headerlink" title="Creating Pipeline"></a>Creating Pipeline</h1><p><strong>Prerequisites</strong>     </p>
<ol>
<li>fork <a href="https://github.com/Apress/beginning-jenkins-blue-ocean/tree/master/Ch03/example-maven-project">example maven project</a></li>
<li>pulling the docker image for jenkins agent<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nikhilpathania/jenkins_ssh_agent</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The docker image is based on Ubuntu and comes with Git,Java JDK, Maven, and sshd installed.<br>The image also contains a user account named <em>jenkins</em>.</p>
<p><strong>Creating credentials for the docker image in Jenkins</strong><br>Add credentials inside Jenkins that allow it to interact with the docker image nikhilpathania/jenkins_ssh_agent</p>
<ol>
<li>Classic Jenkins dashboard -&gt; Credentials-&gt; System-&gt; Global credential (unrestricted).</li>
<li>Add Credentials</li>
<li>Options<ol>
<li>Kind: Username with password</li>
<li>Username: the username to interact with the docker image: jenkins</li>
<li>Password: the password to interact with the docker image: jenkins</li>
<li>ID: add a meaningful name to recognize these credentials.</li>
<li>Descritpion: Add a meaningful description for these credentials.<br><img src="https://i.imgur.com/pFaHQuZ.png" alt="configuring the credential"><br><strong>Installing the docker plugin</strong><br>To spawn on-demand docker containers serving as Jenkins agents, need to install the docker plugin<br><img src="https://i.imgur.com/nUi1uKk.png" alt="Installing the Docker Plugin for Jenkins">   </li>
</ol>
</li>
</ol>
<p><strong>Configuring the docker plugin</strong><br>Manage Jenkins-&gt; Configure System-&gt; Cloud-&gt; Add a new cloud-&gt; Docker</p>
<p>Options to configure:</p>
<ol>
<li>Docker Host URI: This is the URL used by Jenkins to talk to the docker host.</li>
</ol>
<hr>
<p><strong>ENABLING DOCKER REMOTE API (CRITICAL)</strong><br>The Docker remote API allows external applications to communicate with the Docker server using REST APIs . Jenkins (through the Docker Plugin) uses the docker remote API to communicate with a docker host.</p>
<p>To enable the Docker remote API on your Docker host, you’ll need to modify Docker’s configuration file. Depending on your OS version and the way you have installed Docker on your machine, you might need to choose the right configuration file to modify. Shown here are two methods that work on Ubuntu. Try them one by one.</p>
<p><strong>Modifying the docker.conf File</strong><br>Follow these steps to modify the docker.conf file :</p>
<ol>
<li>Log in to your docker server; make sure you have sudo privileges.</li>
</ol>
<ol start="2">
<li>Execute the following command to edit the file docker.conf :</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /etc/init/docker.conf</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>Inside the docker.conf file, go to the line containing “DOCKER_OPTS=” .</li>
</ol>
<p>You’ll find “DOCKER_OPTS=” variable at multiple places inside the docker.conf file. Use the DOCKER_OPTS= that is available under the pre-start script or script section.</p>
<ol start="4">
<li>Set the value of DOCKER_OPTS as shown here. Do not copy and paste; type it all in a single line.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DOCKER_OPTS=&apos;-H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock&apos;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The above setting binds the Docker server to the UNIX socket as well on TCP port 4243.</p>
<p>“0.0.0.0” makes Docker engine accept connections from anywhere. If you would like your Docker server to accept connections only from your Jenkins server, then replace “0.0.0.0” with your Jenkins Server IP.</p>
<ol start="5">
<li>Restart the Docker server using the following command:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="6">
<li>To check if the configuration has worked, execute the following command. It lists all the images currently present on your Docker server.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X GET http://&lt;Docker Server IP&gt;:4243/images/json</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="7">
<li>If this command does not return a meaningful output, try the next method.</li>
</ol>
<p><strong>Modifying the docker.service File</strong><br>Follow these steps to modify the docker.service file :</p>
<ol>
<li>Execute the following command to edit the docker.service file.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /lib/systemd/system/docker.service</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="2">
<li>Inside the docker.service file, go to the line containing ExecStart= and set its value as shown here. Do not copy and paste; type it all in a single line.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ExecStart=/usr/bin/dockerd -H fd:// -H tcp://0.0.0.0:4243</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The above setting binds the docker server to the UNIX socket as well on TCP port 4243.</p>
<p>“0.0.0.0” makes the Docker engine accept connections from anywhere. If you would like your Docker server to accept connections only from your Jenkins server, then replace “0.0.0.0” with your Jenkins Server IP.</p>
<ol start="3">
<li>Execute the following command to make the Docker demon notice the modified configuration:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="4">
<li>Restart the Docker server using the below command:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="5">
<li>To check if the configuration has worked, execute the following command. It lists all the images currently present on your Docker server.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X GET http://&lt;Docker Server IP&gt;:4243/images/json</span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<ol start="2">
<li>Server Credentials: If your docker host requireds a login, you need to add the credentials to Jenkins using the <strong>Add</strong> button. However, do nothing if you are using a docker host that’s running your Jenkins server container.</li>
<li>Test Connection: Click on this to test the communication between your Jenkins server and the docker host. You should see the docker version and the API version [4] if the connection is successful.</li>
<li>Enabled: A checkbox to enable/disable the current configuration.<br><img src="https://i.imgur.com/RKOm2V2.png" alt="Configuring the Docker host URI and testing the connection"></li>
</ol>
<p><strong>Add Docker Template</strong> button. Click on it to configure the docker image that Jenkins shoudl use to spawn container.<br><img src="https://i.imgur.com/6NOb5kY.png" alt="docker template figure"></p>
<ol>
<li>Labels: The label that you type in under the Labels field gets used inside your Pipeline to define agents for your stages. In this way, Jenkins knows that it has to use docker to spawn agents. </li>
<li>Enabled: This checkbox is used to enable/disable the current configuration. </li>
<li>Docker Image: Add the name of the docker image that should be used to spawn agents containers. </li>
<li>Remote File System Root: This is the directory inside the container that holds the workspace of the Pipeline that runs inside it. </li>
<li>Usage: We would like only to build pipelines that have the right agent label, in our case it is docker.</li>
<li>Connect method : Choose to Connect with SSH option to allow Jenkins to connect with the container using the SSH protocol.</li>
<li>SSH Key: Choose use configured SSH credentials from the options to use the SSH credentials as the preferred mode of authentication.</li>
<li>SSH Credentials: From the list of options choose the credentials that you have created earlier, in the section: Creating Credentials for the Docker Image in Jenkins.</li>
<li>Host Key Verification Strategy: Choose Non verifying Verification Strategy to keep things simple. However, this is not the recommended setting for a production Jenkins server.<h1 id="Using-the-pipeline-creation-wizard-configure-Jenkins-Blue-Ocean-with-various-types-of-source-code-repositories"><a href="#Using-the-pipeline-creation-wizard-configure-Jenkins-Blue-Ocean-with-various-types-of-source-code-repositories" class="headerlink" title="Using the pipeline creation wizard, configure Jenkins Blue Ocean with various types of source code repositories."></a>Using the pipeline creation wizard, configure Jenkins Blue Ocean with various types of source code repositories.</h1><h1 id="Using-the-Visual-Pipeline-Editor-to-design-Pipeline"><a href="#Using-the-Visual-Pipeline-Editor-to-design-Pipeline" class="headerlink" title="Using the Visual Pipeline Editor to design Pipeline."></a>Using the Visual Pipeline Editor to design Pipeline.</h1></li>
</ol>
<ul>
<li>Downloads the source code from the Github repository</li>
<li>Performs a build and some testing</li>
<li>Publishes the testing results under the Pipeline’s Test page</li>
<li>Uploads the built artifact to Henkins Blue Ocean</li>
</ul>
<p><strong>Assigning a global agent</strong><br>The pipeline that you are going to create should have two stages, and each stage is supposed to run inside a docker<br>container. You’ll define the agents for each stage sparately in the stage’s settings.<br>Therefore, let’s keep the Pipeline’s global agent setting to none.<br><img src="https://i.imgur.com/fBKsY4k.png" alt="Assigning a global agent"></p>
<p><strong>Creating a build &amp; test stage</strong><br>Type in the name <strong>Build &amp; Test</strong> for your stage.<br><img src="https://i.imgur.com/SOXKlCZ.png" alt="Naming your stage"></p>
<p><strong>Adding steps</strong><br>Let’s add some steps to our <strong>Build &amp; Test</strong> stage.<br><img src="https://i.imgur.com/FR5koOy.png" alt="Adding a new step"><br><strong>Adding a shell script setp</strong><br>Our source code is a Maven project, and we would like to build and test it using an mvn command, which eventually<br>gets executed inside a shell on the Jenkins agent.<br><img src="https://i.imgur.com/zdRO91W.png" alt="Adding a shell script step"><br>Paste the below code which is a maven command to build, test, and create a package out of your source code.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn -Dmaven.test,failure,ignore clean package</span><br></pre></td></tr></table></figure></p>
<p><strong>Adding a stash step to pass artifact between stages</strong><br>Add another step to stash the build package and the testing report generated by the maven command.<br>Look for the step <strong>Stash some files to be used later in the build</strong><br><img src="https://i.imgur.com/yguB0hB.png" alt="Adding a Stash step"></p>
<p>Add the name “build-test-artifacts” fro your stash using the Name<em> field, which is mandatory.<br>Add the following to the Included field: **/target/surefire-reports/TEST-</em>.xml,target/*.jar</p>
<p>With this configuration you are telling Jenkins to stash any .jar file (build package) from the target directory,<br>and the TEST-*.xml file(test report) from the <code>**/target/surefire-reports/</code> directory on the build agent.<br><img src="https://i.imgur.com/ZtwyY00.png" alt="configuring a Stash step"></p>
<p>piple line code so far:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent none</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(&apos;Build &amp; Test&apos;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &apos;mvn -Dmaven.test.failure.ignore clean package&apos;</span><br><span class="line">                stash(name: &apos;build-test-artifacts&apos;, \</span><br><span class="line">                includes: &apos;**/target/surefire-reports/TEST-*.xml,target/*.jar&apos;)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>Assigning an agent for the build &amp; test stage</strong><br>You’ll assign a build agent for your <strong>Build &amp; Test</strong> stage. The agent is going to be a docker container that will be spawn automatically by Jenkins. ONce the stage is complete, Jenkins will destroy the container.<br><img src="https://i.imgur.com/8QGv9eH.png" alt="assigning an agent to a stage"><br>With the following configuration, Jenkins looks for an agent with the label <strong>docker</strong>. Remember the section, wherein you configured the docker plugin in Jenkins. You specified the label <strong>docker</strong> while configure the <strong>Docker Agent<br>Template</strong>.</p>
<p><strong>Creating a report &amp; publish stage</strong><br>Add another stage named <strong>Report &amp; Publish</strong> that will publish the testing results on the <strong>Test</strong> page of the Pipeline and that will publish the build package on the <strong>Artifacts</strong> page of the pipeline.<br><img src="https://i.imgur.com/1wyyhNT.png" alt="Naming your stage"></p>
<p><strong>Adding an un-stash step</strong><br>Before we do anything in the <strong>Report &amp; Publish</strong> stage. it is first crucial to un-stash the files that were stashed<br>in the previous stage. So let’s add step to un-stash a stash from the previous stage.<br><img src="https://i.imgur.com/e0XDMmW.png" alt="Adding a restore files previously stashed step"><br>You’ll see a text field Name* where you should paste the name of your stash precisely as it was defined during its<br>creation.<br><img src="https://i.imgur.com/O5Do1D7.png" alt="Configuring the Restore files previously stashed step"></p>
<p><strong>Report testing results</strong><br>The stash contains a JUnit test results .xml file that you’ll publish on the pipeline’s Test page. For this, we need<br>to add a step named <strong>Archive Junit-formatted test results</strong></p>
<p>Use the TestResults<em> field to provide Jenkins with the path to your JUnit test result file. In our case, it is<br>`**/target/surefire-reports/TEST-</em>.xml`</p>
<p><img src="https://i.imgur.com/Skz6Yg7.png" alt="Configuring an Archive Junit-formatted test results step"></p>
<p><strong>Upload artifacts to blue ocean</strong><br>Add a step that will upload the build package to the Pipleine’s Artifacts page. From the un-stashed files, you also<br>have a .jar file that is the build package.</p>
<p>To upload it to the Pipeline Artifacts page, use the <strong>Archive the artifacts</strong> step.<br>Use the Artifacts<em> filed to provide Jenkins with the path to your build package file. In our case, it is target/</em>.jar.Also, tick the option OnlyIfSuccessful to upload the artifacts only if the Pipeline status is green or yellow.<br><img src="https://i.imgur.com/X1ogakY.png" alt="Configuring the Archive the Artifacts step"> </p>
<p><strong>Assigning an aget for the report &amp; publish stage</strong><br>you’ll assign a build agent for your Report &amp; Publish stage. The agent is going to be a docker container that will be spawn automatically by Jenkins. Once the stage is complete, Jenkins will destroy the container.</p>
<p><img src="https://i.imgur.com/zg4Jc5G.png" alt="Assigning an agent to a stage"></p>
<p>You are new done with creating the pipeline. To save the changes, click on the Save button.</p>
<p>When you click on the <strong>Save</strong> button, Jenkins in the back end converts your UI configurations into a Jenkinsfile that follows the Declarative Pipeline Syntax.</p>
<p><img src="https://i.imgur.com/2HYkBP5.png" alt="Committing your pipeline configurations changes"></p>
<p><strong>Run an artifactory server</strong><br>To spawn an Artifactory server with docker. Artifactory is a popular tool to manage and version control software build artifacts. </p>
<ol>
<li>Log in to your docker host</li>
<li>docker volume create –name artifactory_data</li>
<li>docker pull docker.bintray.io/jfrog/artifactory-oss:latest  # downloading the latest version of Artifactory community edition</li>
<li>docker run –name artifactory -d -v artifactory_data:/var/opt/jfrog/ -p 8081:8081 docker.bintray.io/jfrog/artifactory-oss:latest</li>
<li>access your Artifactory server: http://&lt;Docker_host_ip&gt;:8081/artifactory/webapp/#/home</li>
<li>using the admin credentials (username: admin, and password as password). Note the default example repository in Artifactory named example-repo-local.</li>
</ol>
<p><strong>Installing the artifactory plugin for jenkins</strong><br>Manage Jenkins-&gt; Manage Plugins-&gt; Artifactory</p>
<p><strong>Configuring the artifactory plugin in jenkins</strong><br><img src="https://i.imgur.com/2HYkBP5.png" alt="configuring the artifactory plugin"></p>
<p><strong>Creating a Publish to Artifactory Stage (Parallel Stage)</strong><br>Add a stage in parallel to existing <strong>Report &amp; Publish</strong> stage.<br><img src="https://i.imgur.com/HAq6sYq.png" alt="creating a new stage"><br><img src="https://i.imgur.com/vXUpngZ.png" alt="naming your stage"><br>Your new stage first downloads the stash files from the previous stage, and then it publishes the built artifacts to<br>the Artifactory server.</p>
<p><strong>Adding a scripted pipeline step</strong><br>does two things</p>
<ol>
<li>it fetches the stash files from the previous stage.</li>
<li>it runs a filespec that uploads the build package to the Artifactory server.<br><img src="https://i.imgur.com/9W9fTUQ.png" alt="add a scripted pipeline step"><br>Script to Un-Stash Built Artifacts and Upload Them to the Artifactory Server<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">unstash &apos;build-test-artifacts&apos;</span><br><span class="line">def server = Artifactory.server &apos;Artifactory&apos;</span><br><span class="line">def uploadSpec = &quot;&quot;&quot;&#123;</span><br><span class="line">  &quot;files&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;pattern&quot;: &quot;target/*.jar&quot;,</span><br><span class="line">      &quot;target&quot;: &quot;example-repo-local/$&#123;BRANCH_NAME&#125;/$&#123;BUILD_NUMBER&#125;/&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;&quot;&quot;&quot;</span><br><span class="line">server.upload(uploadSpec)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">███████╗██╗  ██╗██████╗ ██╗      █████╗ ██╗███╗   ██╗</span><br><span class="line">██╔════╝╚██╗██╔╝██╔══██╗██║     ██╔══██╗██║████╗  ██║</span><br><span class="line">█████╗   ╚███╔╝ ██████╔╝██║     ███████║██║██╔██╗ ██║</span><br><span class="line">██╔══╝   ██╔██╗ ██╔═══╝ ██║     ██╔══██║██║██║╚██╗██║</span><br><span class="line">███████╗██╔╝ ██╗██║     ███████╗██║  ██║██║██║ ╚████║</span><br><span class="line">╚══════╝╚═╝  ╚═╝╚═╝     ╚══════╝╚═╝  ╚═╝╚═╝╚═╝  ╚═══╝</span><br></pre></td></tr></table></figure>
<p>The code line unstash ‘build-test-artifacts’ downloads the previously stashed package. The rest of the code is a Filespec that uploads the target/*jar file, which is our built package file, to the Artifactory server on the repository example-repo-local.</p>
<p>Notice that the target path contains Jenkins Global variables, ${BRANCH_NAME} and ${BUILD_NUMBER}, representing the branch name and build number, respectively. Doing so uploads the built artifacts to a unique path on Artifactory every single time a pipeline runs.</p>
<p><strong>Assigning an Agent for the Publish to Artifactory Stage</strong><br>you’ll assign a build agent for your Publish to Artifactory stage. The agent is going to be the docker container that gets spawned automatically by Jenkins. Once the stage is complete, Jenkins destroys the container.<br><img src="https://i.imgur.com/l3VMpHu.png" alt="Assigning an agent to a stage"></p>
<p>Final pipeline code:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  agent none</span><br><span class="line">  stages &#123;</span><br><span class="line">    stage(&apos;Build &amp; Test&apos;) &#123;</span><br><span class="line">      agent &#123;</span><br><span class="line">        node &#123;</span><br><span class="line">          label &apos;docker&apos;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">      steps &#123;</span><br><span class="line">        sh &apos;mvn -Dmaven.test.failure.ignore clean package&apos;</span><br><span class="line">        stash(name: &apos;build-test-artifacts&apos;, includes: &apos;**/target/surefire-reports/TEST-*.xml,target/*.jar&apos;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(&apos;Report &amp; Publish&apos;) &#123;</span><br><span class="line">      parallel &#123;</span><br><span class="line">        stage(&apos;Report &amp; Publish&apos;) &#123;</span><br><span class="line">          agent &#123;</span><br><span class="line">            node &#123;</span><br><span class="line">              label &apos;docker&apos;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">          steps &#123;</span><br><span class="line">            unstash &apos;build-test-artifacts&apos;</span><br><span class="line">            junit &apos;**/target/surefire-reports/TEST-*.xml&apos;</span><br><span class="line">            archiveArtifacts(artifacts: &apos;target/*.jar&apos;, onlyIfSuccessful: true)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&apos;Publish to Artifactory&apos;) &#123;</span><br><span class="line">          agent &#123;</span><br><span class="line">            node &#123;</span><br><span class="line">              label &apos;docker&apos;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">          steps &#123;</span><br><span class="line">            script &#123;</span><br><span class="line">              unstash &apos;build-test-artifacts&apos;</span><br><span class="line"></span><br><span class="line">              def server = Artifactory.server &apos;Artifactory&apos;</span><br><span class="line">              def uploadSpec = &quot;&quot;&quot;&#123;</span><br><span class="line">                &quot;files&quot;: [</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;pattern&quot;: &quot;target/*.jar&quot;,</span><br><span class="line">                    &quot;target&quot;: &quot;example-repo-local/$&#123;BRANCH_NAME&#125;/$&#123;BUILD_NUMBER&#125;/&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                ]</span><br><span class="line">              &#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">              server.upload(uploadSpec)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><img src="https://i.imgur.com/id9vL50.png" alt="Committing your pipeline configurations changes"><br><img src="https://i.imgur.com/Ec4LinF.png" alt="build artifact uploaded to Artifactory"></p>
<p><strong>Running a pipeline for a pull requrest</strong><br>Jenkins Blue Ocean can detect pull requests on your Github repositories and run a pipeline with it for you. The<br>pipeline run result (fail/pass/canceled) gets reported back to your source code repository.</p>
<p>The person who is reponsible for accepting the pull request can then decide based on the pipeline run result whether<br>he should merge the new changes into the destination branch or not.<br><img src="https://i.imgur.com/kUvGGZM.jpg" alt="pull request"></p>
<h2 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h2><p>pull requests not showing<br>fix by: <img src="https://i.imgur.com/63ETSbk.png" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Jenkins/">Jenkins</a><a href="/tags/Devops/">Devops</a><a href="/tags/CD-CI/">CD/CI</a><a href="/tags/Pipeline/">Pipeline</a><a href="/tags/Blue-Ocean/">Blue Ocean</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/23/LinuxSystemAdmin/" title="LinuxSystemAdmin" itemprop="url">LinuxSystemAdmin</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-22T23:00:22.000Z" itemprop="datePublished"> Published 2019-07-23</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="TCP-IP-networking"><a href="#TCP-IP-networking" class="headerlink" title="TCP/IP networking"></a>TCP/IP networking</h1><h2 id="Troubleshoot-networking"><a href="#Troubleshoot-networking" class="headerlink" title="Troubleshoot networking"></a>Troubleshoot networking</h2><p><strong>Tools for troubleshooting the network</strong></p>
<ul>
<li><em>ping</em> - ICMP echo requests<br><img src="https://i.imgur.com/RcrCjea.jpg" alt="ping -I eth1 192.168.10.12"></li>
<li><em>traceroute</em> and <em>tracepath</em> - Trace the path taken to a given host</li>
<li><em>netcat</em> - Arbitrary TCP and UDP network communication<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">stan@stan-virtual-machine:~$ ifconfig</span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 00:0c:29:a2:c2:5d  </span><br><span class="line">          inet addr:192.168.199.107  Bcast:192.168.199.255  Mask:255.255.255.0</span><br><span class="line">          inet6 addr: fe80::20c:29ff:fea2:c25d/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:109798 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:34545 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:53893408 (53.8 MB)  TX bytes:15357635 (15.3 MB)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          inet6 addr: ::1/128 Scope:Host</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:5917 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:5917 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:1699426 (1.6 MB)  TX bytes:1699426 (1.6 MB)</span><br><span class="line"></span><br><span class="line">stan@stan-virtual-machine:~$ nc -l 8000</span><br><span class="line">nc -v -z 192.168.199.107 8000</span><br><span class="line">Connection to 192.168.199.107 8000 port [tcp/*] succeeded!</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="https://i.imgur.com/60o3bav.png" alt="nc"></p>
<ul>
<li><em>tcpdump</em> and <em>wireshark</em> - Packet captures for network analysis<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"> nc -l 8000 &amp;</span><br><span class="line">[1] 20393</span><br><span class="line">➜  ~ sudo tcpdump -i enp2s0 port 8000</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on enp2s0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">Hi</span><br><span class="line">[1]  + 20393 done       nc -l 8000</span><br><span class="line">09:52:41.674092 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [S], seq 3581133462, win 29200, options [mss 1460,sackOK,TS val 12349350 ecr 0,nop,wscale 7], length 0</span><br><span class="line">09:52:41.674180 IP stan-OptiPlex-380.lan.8000 &gt; stan-virtual-machine.lan.57089: Flags [S.], seq 2419171515, ack 3581133463, win 28960, options [mss 1460,sackOK,TS val 2113949133 ecr 12349350,nop,wscale 7], length 0</span><br><span class="line">09:52:41.674412 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [.], ack 1, win 229, options [nop,nop,TS val 12349351 ecr 2113949133], length 0</span><br><span class="line">09:52:41.674518 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [P.], seq 1:4, ack 1, win 229, options [nop,nop,TS val 12349351 ecr 2113949133], length 3</span><br><span class="line">09:52:41.674541 IP stan-OptiPlex-380.lan.8000 &gt; stan-virtual-machine.lan.57089: Flags [.], ack 4, win 227, options [nop,nop,TS val 2113949133 ecr 12349351], length 0</span><br><span class="line">09:52:41.674582 IP stan-virtual-machine.lan.57089 &gt; stan-OptiPlex-380.lan.8000: Flags [F.], seq 4, ack 1, win 229, options [nop,nop,TS val 12349351 ecr 2113949133], length 0</span><br><span class="line">09:52:41.674718 IP stan-OptiPlex-380.lan.8000 &gt; stan-virtual-machine.lan.57089: Flags [F.], seq 1, ack 5, win 227, options [nop,nop,TS val 2113949133 ecr 12349351], length 0</span><br><span class="line">^C</span><br><span class="line">7 packets captured</span><br><span class="line">8 packets received by filter</span><br><span class="line">1 packet dropped by kernel</span><br><span class="line"></span><br><span class="line">stan@stan-virtual-machine:~$ echo Hi| nc 192.168.199.178 8000</span><br><span class="line">tcpdump -i eth1 port 8000 and not port 22 and not icmp</span><br><span class="line">tcpdump -i eth1 not udp 53</span><br><span class="line">tcpdump -nX -i eth1 port 8000</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="https://i.imgur.com/D7Vewu7.jpg" alt="tcpdump"><br><img src="https://i.imgur.com/4WIQHtZ.png" alt="tcp three-way handshake"></p>
<h2 id="Backup-and-streaming"><a href="#Backup-and-streaming" class="headerlink" title="Backup and streaming"></a>Backup and streaming</h2><p><strong>What to expect from a backup tool?</strong></p>
<ul>
<li>Any backup solution should -roughly- provide the following:</li>
<li>Full and incrementail backups</li>
<li>File permissions and ownership preservation</li>
<li>The ability to be automated</li>
</ul>
<p><strong>Introducing rsync</strong></p>
<ul>
<li>Rsync is native Linux tool that can be deployed from the official repositories</li>
<li>It supports incremental and full backups- It transfers files over SSH</li>
<li>It can be automated via cron jobs to run in unattended mode.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type rsync</span><br><span class="line">rsync -zvr simple-php-website/ ~/backup/</span><br><span class="line">sudo rsync -azv simple-php-website/ ~/backup/ # backup with file created time stampe and ownership</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>using rsync over the network</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rsync -azv simple-php-website/ pi@rpi-01:~/backup/</span><br><span class="line">rsync -azv  pi@rpi-01:~/backup/ simple-php-website</span><br></pre></td></tr></table></figure></p>
<p><strong>advanced ssh options with rsync</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">ssh-copy-id pi@rpi-01 </span><br><span class="line">rsync -avz -e &quot;ssh -p 2222&quot; simple-php-website/ pi@rpi-01:~/backup/ # specify the ssh port</span><br><span class="line">rsync -azv --existing simple-php-website/ pi@rpi-01:~/backup/ ## only sync the file existing in destnation</span><br><span class="line">rsync -avzi simple-php-website/ pi@rpi-01:~/backup/ # i show what has been changed in source and destnation</span><br><span class="line">dd if=/dev/zero of=data.bin bs=102400 count=10240</span><br><span class="line">rsync -azv --progress simple-php-website/ pi@rpi-01:~/backup/ #show the transfers info</span><br><span class="line">rsync -azv --include &apos;*.php&apos; --exclude &apos;*.jpg&apos; simple-php-website/ pi@rpi-01:~/backup/</span><br><span class="line"></span><br><span class="line">```  </span><br><span class="line">## Performance Analysis</span><br><span class="line">**How to improve performance?**</span><br><span class="line">- The following are general guidelines for achieving a higher performance level on a typical Linux box:</span><br><span class="line">  - Make sure that you have enough memory to serve the running applications</span><br><span class="line">  - Use softwre or hardware load balancing systems. They not only provide faster responses from network applications, but they also provide redundancy should one of the servers go down undexpectedly.</span><br><span class="line">  - Review the application specific documentation and configuration files. Some settings may dramatically boost application performance like turning on caching in webservers or unning multiple instances of a network application.</span><br><span class="line">  - Avoid storage I/O bottlnecks by installing faster disks like SSD&apos;s, which do not depend on mechanically moving parts to offer much higher read/write speed than their old counterparts.</span><br><span class="line">  - Use technologies like RAID to distribute I/O evenly on disks (like striping). However, not all applications/databases benefit from striping and RAID and sometimes this my lead to negative results. Application and database vendor and/or documentation should be consulted before moving to RAID.</span><br><span class="line">  - Keep an eye on the network bandwidth and errors to ensure that the bandwidth is not saturated and that the error rate is at the minimum</span><br><span class="line">**Possible causes of bottlenecks**</span><br><span class="line">- Hardware-wise, performance is affected mainly by one or more of the following system components: CPU, memory, and disk and network I/O.</span><br><span class="line">- Processes running on the system must access the above components. They compete to have, for example a CPU cycle or an I/O from the disk to read to write data. If the component is busy, the process will have to wait for its trun to be served. This wait time means that the sytem will run slower and implies that are have a performance issue.</span><br><span class="line">**Check your resources**</span><br><span class="line">- Before addressing a performance degradation problem, you must first check your assets to have an estimate of the upper bound for system&apos;s general performance level</span><br><span class="line">- The following files provide hardware information:</span><br><span class="line">  - /proc/cpuinfo: take note of the vendor ID, cpu family, model and model name. Each processor core will have a stanza of its own. Useful information can be extracted from the CPU flags like ht which means that the CPU is using the hyper threading technology.</span><br><span class="line">  - /proc/meminfo: details on total, used, and free memeory</span><br><span class="line">  - /proc/diskstats: disk devices statistics</span><br><span class="line">- Another useful command for this purpose if dmidecode. This will print a lot of hardware information about the machine like the mothermoard type, BIOS version, installed memory amont many other information.</span><br><span class="line">**Using vmstat to measure CPU utilization**</span><br><span class="line">- When meansuring CPU performance, you may want to determine the overall CPU utilization to know whether or not the overall clock speed is the problem, load averages may also aid you in this. In addition, you may want to check perprocess CPU consumption to know which process really hogging the CPU</span><br><span class="line">- Running vmstat gives you the information you need. It takes the number of seconds and the number of reports as the first and second arguments to determine the number of seconds for which the tool will calculate the averages. The first line of output represents the averages since the systems boot time. The subsequent line present the average per n seconds.</span><br><span class="line">- The right most column is for CPU readings. Us, sy,id, and wa represent the user, system, idle time, and wait time for CPU.</span><br><span class="line">- A high us means that the system is busy doing computational tasks, while a high **sy** time means the system is making a lot of system calls and/or making a lot of I/O requests. A system-typically-should be using no more than 50% in user time, no more than 50% in system time, and have a non-zero idle time.</span><br><span class="line">- The **cs** is short for context switches per interval. That is how many times the kernel switched the running process per interval. The **in** is short for interrupts, it shows the number of interrupts per interval. A high **cs** or **in** rate may be an indication to a malunctioning hardware device.</span><br><span class="line"></span><br><span class="line">**CPU load average and per-process**</span><br><span class="line">- Using the **uptime** command, it essentially provides the total time spent since the system was booted, but it also offers a CPU load average for the same period.</span><br><span class="line">- The load average consists of three vlues that represent 5,10, and 15 minutes averages.</span><br><span class="line">- A load average that stays the same on a &quot;good performance&quot; and on a &quot;performance degraded&quot; one is an indication that you have to look elsewhere,perhaps at the network bandwidth, disk I/O, or the intalled memroy.</span><br><span class="line">- Other commands that offer real time view of the CPU per-process load is **ps -aux** and **top**. You may find a single process using more than 50% of the available CPU time. Using **nice** to decrease the execution prioroty of this process may help boost performance.</span><br><span class="line"></span><br><span class="line">**Memeory management**</span><br><span class="line">- When an application requests memeory to operate, the kernel offers this memeory in the form of &quot;pages&quot;. In linux, a page size is 4KiB.</span><br><span class="line">- The kernel serves those pages from physical storage hardware (either RAM or SWAP space on the disk).</span><br><span class="line">- The kernel shuffles pages between the SWAP space together with RAM. Memroy that is not accessed for a specific period of time is moved into SWAP space (paged) to free more space for rather more frequently accessed memory.</span><br><span class="line">- As more and more processes demand memroy, the kernel tries to fulfil the reqeusts by paging in and out memory pages from and to the SWAP space. And because the disk is the slowest coponent of the system, as the paging rate increates, performance is degraded as processes will have to wait longer before they can have their requested memory and things start to get slower.</span><br><span class="line">- Fainlly, if the system runs out of both physical memory and SWAP space, the kernel resorts to more drastic measures: it kills the least important process with an out-of-memory killer function, a situation that should be avoided at all costs by anticipating the need to install more memroy early enough.</span><br><span class="line"></span><br><span class="line">**Using vmstat to measure memory utilization**</span><br><span class="line">- **vmstat** is used the same way it was used to measure CPU utilization.</span><br><span class="line">- The swap in (si) and swap out (so) columns in the SWAP area of the output are of the most importance here. Pages that are read from disk into memory are &quot;swapped in&quot; while those which are ejected by the kernel into the disk are &quot;swapped out&quot;. A high rate of si and so may be an indication that the system is using SWAP sapce extensively and that it might need more physical memeory to be installed.</span><br><span class="line">- Such a decision should not be reached by the **si** and **so** rates alone as the system normally does page in and page out operations. Only if is accompanied by slow system response and user complaints.</span><br></pre></td></tr></table></figure></p>
<p>iostat -dx 5 5<br><code>`</code><br><strong>A slow system quick diagnosis and remedy</strong></p>
<ul>
<li>If you find that the system is suddenly running slower than before and users start complaining, you can examine the resources discussed in this section for bottlenecks.</li>
<li><p>For example, running <strong>ps -auxww</strong> will show you the CPU utilization per process. If you find that a single process is using more than 50% of the CPU ofr a long time, this might be an indication of fault in the process itself. Also check the load average with uptime to determine whether or not the CPU is contended.</p>
</li>
<li><p>Check the paging activity with vmstat. If there are a lot of page-outs this means the physical memeory is overloaded. Additionalyy, if there is a lot of disk activity without paging this means the a process is extensively using the disk for read and write requests. If this is not the normal behavior (e.g. a database), the process activity should be further examined.</p>
</li>
<li>It is difficult to know exactly which process is using the disk I/O the most, but using kill -STOP to temporarily suspend the susceptiable process can narrow down the possibilities.</li>
<li>If a process is identified as resource intensive, a number of actions can be taken: if it is CPU intensive you can use the renice command to descrease its priority. You can also ask the user to run it later. I the process is hogging the disk and/or then network, renice will not solve the problem, but you can tune the process itself to optimize its behavior (for example web servers).</li>
</ul>
<h1 id="Linux-troubleshooting"><a href="#Linux-troubleshooting" class="headerlink" title="Linux troubleshooting"></a>Linux troubleshooting</h1><h2 id="System-access-troubleshooting"><a href="#System-access-troubleshooting" class="headerlink" title="System access troubleshooting"></a>System access troubleshooting</h2><p><strong>Server is not reachable</strong></p>
<ul>
<li>Ping the destination server name<ul>
<li>if server name is not pingable</li>
</ul>
</li>
<li>Ping the destination server yb IP<ul>
<li>if IP is pingable = Name resolution issue<ul>
<li>Check /etc/hosts file</li>
<li>Check /etc/resolv.conf</li>
<li>Check /etc/nsswitch.conf</li>
</ul>
</li>
<li>If IP is NOT pingable<ul>
<li>Ping another server by name and then by IP</li>
<li>Checking if your server has an IP address</li>
<li>Ping your gateway (netstat -rnv)/modem IP</li>
<li>Check physical cable connection</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Cannot connect to a website or an application</strong><br>Troubleshoting Steps: ping server by hostname and IP<br>if NOT pinable= go back to <strong>Server is not reachable</strong></p>
<p>if pingable = Connect to service </p>
<h1 id="telnet-192-168-1-5-80-http"><a href="#telnet-192-168-1-5-80-http" class="headerlink" title="telnet 192.168.1.5 80 (http)"></a>telnet 192.168.1.5 80 (http)</h1><p>Verify the installation:</p>
<h1 id="rpm-q-haproxy"><a href="#rpm-q-haproxy" class="headerlink" title="rpm -q haproxy"></a>rpm -q haproxy</h1>
        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Linux/">Linux</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/19/programming4sysadmins/" title="programming4sysadmins" itemprop="url">programming4sysadmins</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-19T06:10:53.000Z" itemprop="datePublished"> Published 2019-07-19</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="python"><a href="#python" class="headerlink" title="python"></a>python</h1><h2 id="What-can-you-do-with-python"><a href="#What-can-you-do-with-python" class="headerlink" title="What can you do with python?"></a>What can you do with python?</h2><ul>
<li>Versatile language, can use it across a lot of different domains</li>
<li>really fast to learn and fast to develop in<h2 id="Environment-Setup"><a href="#Environment-Setup" class="headerlink" title="Environment Setup"></a>Environment Setup</h2><a href="https://wiki.openhatch.org/wiki/O%27Reilly_Introduction_to_Python">link</a><h2 id="Python-basic-data-types"><a href="#Python-basic-data-types" class="headerlink" title="Python basic data types"></a>Python basic data types</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; type(1)</span><br><span class="line">&lt;type &apos;int&apos;&gt;</span><br><span class="line">&gt;&gt;&gt; type(1.0)</span><br><span class="line">&lt;type &apos;float&apos;&gt;</span><br><span class="line">Type is a functions that takes input and spits out output.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>a function</strong> is just the name and then input inside parentheses, and it’ll spit out output.</p>
<p>If you need to include the string delimiter inside the string just precede it with a backslash, as in ‘It\’s a wrap’<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; &quot;Hello &quot; + str(1)</span><br><span class="line">&apos;Hello 1&apos;</span><br></pre></td></tr></table></figure></p>
<h2 id="Making-choices-boolean-if-eif-else-compound-conditionals"><a href="#Making-choices-boolean-if-eif-else-compound-conditionals" class="headerlink" title="Making choices: boolean, if/eif/else, compound conditionals"></a>Making choices: boolean, if/eif/else, compound conditionals</h2><p>Boolean:</p>
<ul>
<li>True</li>
<li>False<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = 1</span><br><span class="line">&gt;&gt;&gt; x &gt; 0 and x &lt; 2</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; &quot;a&quot; in &quot;hello&quot; or &quot;e&quot; in &quot;hello&quot;</span><br><span class="line">True</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; temp = 32</span><br><span class="line">&gt;&gt;&gt; if temp &gt; 60 and temp &lt; 75:</span><br><span class="line">...     print(&quot;Nice and cozy&quot;)</span><br><span class="line">... else:</span><br><span class="line">...     print(&quot;Too extreme for me&quot;)</span><br><span class="line">...</span><br><span class="line">Too extreme for me</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; sister = 15</span><br><span class="line">&gt;&gt;&gt; brother =15</span><br><span class="line">&gt;&gt;&gt; if sister &gt; brother:</span><br><span class="line">...     print(&quot;Sister is older&quot;)</span><br><span class="line">... elif sister == brother:</span><br><span class="line">...     print(&quot;Same age!&quot;)</span><br><span class="line">... else:</span><br><span class="line">...     print(&quot;Brother is older&quot;)</span><br><span class="line">...</span><br><span class="line">Same age!</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Lists"><a href="#Lists" class="headerlink" title="Lists"></a>Lists</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; names = [&quot;Alice&quot;, &quot;Amy&quot;]</span><br><span class="line">&gt;&gt;&gt; names.append(&quot;Adam&quot;)</span><br><span class="line">&gt;&gt;&gt; names</span><br><span class="line">[&apos;Alice&apos;, &apos;Amy&apos;, &apos;Adam&apos;]</span><br><span class="line">&gt;&gt;&gt; names[len(names)-1]</span><br><span class="line">&apos;Adam&apos;</span><br><span class="line">&gt;&gt;&gt; names[-1]</span><br><span class="line">&apos;Adam&apos;</span><br></pre></td></tr></table></figure>
<p>The real superpower when using lists is actually to be able to loop over them.</p>
<h2 id="Loops"><a href="#Loops" class="headerlink" title="Loops"></a>Loops</h2><h1 id="Great-Bash"><a href="#Great-Bash" class="headerlink" title="Great Bash"></a>Great Bash</h1><ul>
<li><p>Redirect the output of commands</p>
<ul>
<li>Standard error is file descriptor “2” <code>ls -l myscript not.here &gt; lsout 2&gt; lserr</code></li>
<li>Out and error can be redirected separately or together <code>ls -l myscript not.here &amp;&gt; lsboth</code></li>
<li>The order of redirection is important<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ls -l myscript not.here &gt; lsout 2&gt;&amp;1</span><br><span class="line">## Redirectin error output to standard output</span><br><span class="line">## Standard output is already being re-directed to file &gt; dirlist</span><br><span class="line">## Hence, both error and standard output are written to file lsout</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Redirecting and piping input and output</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls &gt; /tmp/lsout</span><br><span class="line">wc &lt; /tmp/lsout</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Use the vertical bar character | to create a pipe: <code>ls|wc</code></p>
<p>Connect a series of commands with | symbols to make a pipeline.</p>
<ul>
<li>Create input with here documents</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/python/">python</a><a href="/tags/programming/">programming</a><a href="/tags/systemadmin/">systemadmin</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/17/devops/" title="DevOps" itemprop="url">DevOps</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-17T11:23:02.000Z" itemprop="datePublished"> Published 2019-07-17</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><strong>What is DevOps?</strong></p>
<ul>
<li>Speed and agility enable organizations to better serve their customers and compete more effectively in the market</li>
<li>Combination of cultural philosophies, practices, and tools</li>
<li>Increases an organization’s ability to deliver applications and services at high velocity</li>
<li>Evolves and imprvoes products faster</li>
</ul>
<p><strong>Why DevOps?</strong></p>
<ul>
<li>Antomate manual tasks, help teams manage complex environments at scale, and keep engineers in control of the velocity that is enabled by DevOps:<ul>
<li>Speed</li>
<li>Rapid delivery</li>
<li>Reliability</li>
<li>Scale</li>
<li>Improved collaboration</li>
<li>Security</li>
</ul>
</li>
</ul>
<p>Standard Continuous delivery (CD) techniques</p>
<ul>
<li>Blue/Green deployment (where “live” and “last” deployments are maintained on live)<br>Blue-green deployment is a technique that reduces downtime and risk by running two identical production environments called Blue and Green.</li>
</ul>
<p>At any time, only one of the environments is live, with the live environment serving all production traffic. For this example, Blue is currently live and Green is idle.</p>
<p>As you prepare a new version of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.</p>
<p>This technique can eliminate downtime due to app deployment. In addition, blue-green deployment reduces risk: if something unexpected happens with your new version on Green, you can immediately roll back to the last version by switching back to Blue.</p>
<ul>
<li>Phoenix deployment (where whole system are rebuilt on each release).<br><img src="https://i.imgur.com/DXtJZOm.png" alt="devops tools"></li>
</ul>
<p><strong>Goals</strong></p>
<ul>
<li>Culture for collaboration<blockquote>
<p>lack of collaboration is one of the root causes of the issues</p>
</blockquote>
</li>
<li>Automate<blockquote>
<p>Manual tests that consume resources are better left to machines. This frees time that is better spent elsewhere, and provides a better environment by relinquishing mundane tasks</p>
</blockquote>
</li>
<li>Optimize and reduce issue in SDLC(software development life cycle)<blockquote>
<p>The processes being comprised in a logical order allows for optimizations to be made from recorded metrics.</p>
</blockquote>
</li>
<li>Consistency in process<blockquote>
<p>This stems mostly from automation, and provides the foundation to ensure quality. It also provides a certain level of peace of mind, having confidence that the same process that successfully ran last time will run the same the next.</p>
</blockquote>
</li>
<li>Improve quality and security<blockquote>
<p>Automation combined with consistency in process, along with the tools and practices in place to perform the necessary testing and scans, removes the possibility of human error from subsequent processes</p>
</blockquote>
</li>
<li>Improve deployment frequency<blockquote>
<p>Agile methodologies proved effective for development, and sparked the idea to apply similar principles to other areas. Deployment frequency has always been a target for efficiency, as shown by the migration to waterfall, where deployments were seldom; to hybrid methodologies that produced releases four or five times per month; to agile, where deployments are dependent upon sprint links. With DevOps, there’s a potential to release multiple times per day.</p>
</blockquote>
</li>
</ul>
<p><strong>DevOps Methodologies and Concepts</strong></p>
<ul>
<li>Automation<ul>
<li>Not duplicate of goals</li>
<li>Automation in context of applying automation to deveopment, integration, and deployment process</li>
</ul>
</li>
<li>CI/CD/CD<ul>
<li>CI: continuous integration<ul>
<li>Focusses on sub process of SDLC to build features and fixes perform preliminary testing then merge to master if successful</li>
</ul>
</li>
<li>CD: continuous delivery<ul>
<li>tail end of CI</li>
<li>refers to archiving build artifacts</li>
</ul>
</li>
<li>CD: continous deployment<ul>
<li>deploy all necessary artifacts and perform any configuration</li>
</ul>
</li>
</ul>
</li>
<li>Infrastructure as code, configuration as code: fail fast<ul>
<li>Don’t waste resources on something that will fail</li>
<li>Organize and optimize for efficiency</li>
</ul>
</li>
<li>Frequent feedback<ul>
<li>Compilation of a series of small and frequent feedback loops</li>
</ul>
</li>
</ul>
<p><strong>DevOps engineer’s role within a devops organization</strong></p>
<ul>
<li>Continually research, refine, and create conceopts, methodologies, practices, and tools in order to optimize the SDLC.</li>
<li>Implement core standards, plicies, and tools based on the previous</li>
<li>Asses infrastructure requirements”<ul>
<li>Global and application sacle</li>
</ul>
</li>
<li>Crate and manage infrastructure</li>
<li>Coordinate with other teams</li>
<li>Troubleshoot issues with code and infrastructure</li>
<li>Work with one or more teams to:<ul>
<li>Assess their current state</li>
<li>Formulate end goals</li>
<li>Adapt to requirements</li>
<li>Develop a plan of implementation</li>
<li>Formulate milestones</li>
<li>Provide instruction on the core standards, policies, and tools</li>
<li>Develop a pipeline</li>
<li>Help to change their code and processes to work with the plan</li>
</ul>
</li>
</ul>
<p><strong>philosophy</strong><br>DevOps is not something you do. It is something you are. </p>
<p>Devops culture is the one based on a set of principles, hierarchy of rules, by which each person operates.<br>A DevOps culture is one that allows more freedom but more responsibility.</p>
<p><strong>Devops lifecycle</strong></p>
<ul>
<li><p>Continuous integration</p>
<ul>
<li>Central repository</li>
<li>Continuous compiling, testing</li>
<li>Code verification</li>
<li>Identifying bugs early</li>
<li>Software in smaller chunks</li>
<li>Easy integration<br>Continuous integration (CI) requires developers to integrate code into a centralized repository as they finish coding and successfully pass unit testing, several times per day. The end goal is to create small workable chunks of code that are validated and integrated back into the code repository as frequently as possible. </li>
</ul>
</li>
<li><p>Configuration management</p>
<ul>
<li>System changes</li>
<li>Multiple servers</li>
<li>Tracking changes</li>
<li>Types of CM tools</li>
<li>Scripted builds</li>
<li>Identical development and production environments</li>
</ul>
</li>
<li><p>Continous delivery</p>
<ul>
<li>Deploying the application</li>
<li>Incremental or small changes</li>
<li>Compatible with schedule releases</li>
<li>Every change-ready to deploy<br>Continuous delivery simply means that every change is ready to be deployed to production as soon as automated testing validates it.<br>Note there are two manual checkpoints in this example. One is for a technical decision to approve the code before initiating activities in the CI environment. The second is a business decision to accept the changes and continue with the automated steps to production deployment.<br><img src="https://i.imgur.com/XzLyd0g.png" alt="reference pipeline-continous delivery"><br><strong>Deploying to production</strong></li>
</ul>
</li>
<li><p>Canary releases</p>
<blockquote>
<p>Continuous delivery deploys many builds to production. In a canary deployment, the new code is delivered only to a percentage of the existing infrastructure. For example, if the system is running on 10 load-balanced virtual servers, you can define a canary cluster of one or two servers. This way, if the deployment is not successful due to an escaped defect, it can be caught before the build is deployed to all of the servers. Canary releases are also used for pilot features to determine performance and acceptance prior to a full rollout.</p>
</blockquote>
</li>
<li><p>Blue/green deployment</p>
<blockquote>
<p>This is a zero-downtime deployment technique that involves a gradual release to ensure uninterrupted service. The blue/green approach is effective in virtualized environments, especially if IaaS is used. Although a blue/green deployment is a deep topic that deserves an entire chapter on its own, simply put, it includes maintaining two identical development environments—Blue and Green. One is a live environment for production traffic, whereas the other is used to deploy the new release. In our example, let’s say that Green is the current live production environment and Blue is the idle identical production environment. After the code is deployed and tested in the Blue environment, we can begin directing traffic of incoming requests from Green (current production) to Blue. You can do this gradually until the traffic redirect is 100 percent to the Blue environment. If unexpected issues occur during this gradual release, we can roll back. When it is completed, the Green environment becomes idle and the Blue environment is now the live production environment.</p>
</blockquote>
</li>
<li><p>Continous monitoring<br>Continous monitoring is the practice that connects operations back to development,providing visibility and relevant data throughout the development lifecycle including production monitoring. continuous monitoring aims to reduce the time between identification of a problem and deployment of the fix.<br>Monitoring begins with <strong>Sprint 1</strong> and should be integrated into the development work. As the system is built, monitoring solutions are also designed. </p>
</li>
</ul>
<p><strong>four different types of continuous monitoring</strong></p>
<ul>
<li>Infrastructure monitoring<blockquote>
<p>Visualize infrastructure events coming from all computing resources, storage and network, and measure the usage and health of infrastructure resources. <strong>AWS CloudWatch</strong> and <strong>CloudTrail</strong> are examples of infrastructure monitoring tools.</p>
</blockquote>
</li>
<li>Application performance monitoring (APM)<blockquote>
<p>Target bottlenecks in the application’s framework. <strong>Appdynamics</strong> and <strong>New Relic</strong> are industry-leading APM tools.</p>
</blockquote>
</li>
<li>Log management monitoring<blockquote>
<p>Collect performance logs in a standardized way and use analytics to identify application and system problems. <strong>Splunk</strong> and <strong>ELK</strong> are two leading products in this area.</p>
</blockquote>
</li>
<li>Security monitoring<blockquote>
<p>Reduce security and compliance risk through automation. Security configuration management, vulnerability management, and intelligence to detect attacks and breaches before they do serious damage are achieved through continuous monitoring. For example, <strong>Netflix’s Security Monkey</strong> is a tool that checks the security configuration of your cloud implementation on AWS.</p>
</blockquote>
</li>
</ul>
<p><strong>three major setps</strong></p>
<ol>
<li>monitoring</li>
<li>an alert system to warn the team about a problem</li>
<li>actions to take when an alert occurs</li>
</ol>
<ul>
<li>Continous testing<ul>
<li>Speed and quality</li>
<li>Testing incremental changes</li>
<li>Automated tests</li>
<li>Tests to be atomic: small test<ul>
<li>Continous testing during development (e.g. use open source tools like Selenium for testing)</li>
<li>Confidence to release</li>
<li>Integration with CI</li>
</ul>
</li>
</ul>
</li>
<li>Continous deployment<ul>
<li>Superset of Continuous Delivery</li>
<li>Deploying to production</li>
<li>Automates the deployment pipeline<br>Unlike continuous delivery, which means that every change is deployable but might be held back because of business considerations or other manual steps, continuous deployment strives to automate production deployment end to end. With this practice, confidence in the automated tests is extremely high, and as long as the code has passed all the tests, it will be deployed.<br><img src="https://i.imgur.com/Aq1VaJb.png" alt="cd"></li>
</ul>
</li>
</ul>
<p>DevOps: culture, automation, measurement, and sharing (CAMS)</p>
<p><strong>DevOps architecutres and practics</strong><br>From the DevOps movement, a set of software architectural patterns and practices have become increasingly popular. The primary logic behind the development of these architectural patterns and practices is derived from the need for scalability, no-downtime deployments, and minimizing negative customer reactions to upgrades and releases. Some of these you may have heard of (microservices), while others may be a bit vague (blue-green deployments).</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Devops/">Devops</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/17/aws-admin/" title="aws administration" itemprop="url">aws administration</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-17T08:02:52.000Z" itemprop="datePublished"> Published 2019-07-17</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="CodeCommit"><a href="#CodeCommit" class="headerlink" title="CodeCommit"></a>CodeCommit</h1><p>Codecommit is a source control service provided by aws(hosts private git repositories)<br><strong>why choose CodeCommit</strong></p>
<ul>
<li>Easy integration with other AWS services like CodePipeline</li>
<li>Repositories are private by default</li>
<li>Can use IAM for fine-graned authorization</li>
</ul>
<p><strong>Creating a private code repo on CodeCommit</strong><br>IAM-&gt; HTTPS Git credentials for AWS CodeCommit</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git clone https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/SampleRepo</span><br><span class="line">cd SampleRepo</span><br><span class="line">wget https://s3.amazonaws.com/aws-codedeploy-us-east-1/samples/latest/SampleApp_Linux.zip</span><br><span class="line">unzip SampleApp_Linux.zip</span><br><span class="line">rm SampleApp_Linux.zip</span><br><span class="line">git add -A</span><br><span class="line">git commit -m &quot;Initial commit&quot;</span><br><span class="line">git push</span><br></pre></td></tr></table></figure>
<p><strong>Migrating your project to CodeCommit</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">### - - mirror here means that we are not interested in cloning the application, however we are interested in downloading the Git binary files that make up the repository in the first place. </span><br><span class="line">git clone --mirror https://github.com/awslabs/aws-demo-php-simple-app.git aws-codecommit-demo</span><br><span class="line">git push https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/myrepo</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;initial commit to demp rep&quot;</span><br><span class="line">git remote add demo https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/demo</span><br><span class="line">git remote -v</span><br><span class="line">git push demo master</span><br></pre></td></tr></table></figure>
<p><a href="https://docs.aws.amazon.com/codecommit/latest/userguide/getting-started-cc.html">CodeCommit tutorials</a><br><a href="https://docs.aws.amazon.com/codecommit/latest/userguide/auth-and-access-control-iam-identity-based-access-control.html">Using IAM policies with CodeCommit</a><br><a href="https://aws.amazon.com/blogs/devops/using-aws-codecommit-pull-requests-to-request-code-reviews-and-discuss-code/">Using AWS CodeCommit Pull Requests</a><br><a href="https://datasift.github.io/gitflow/IntroducingGitFlow.html">GitFlow development release model</a></p>
<h1 id="Deploying-Jenkins"><a href="#Deploying-Jenkins" class="headerlink" title="Deploying Jenkins"></a>Deploying Jenkins</h1><p>Amazon linux 2 AMI<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y update</span><br><span class="line">sudo yum -y install java-1.8.0</span><br><span class="line"># remove java 7</span><br><span class="line">sudo yum remove java-1.7.0-openjdk</span><br><span class="line">java -version</span><br><span class="line">sudo wget -O /etc/yum.repos.d/jenkins.repo https:/pkg.jenkins-ci.org/redhat/jenkins.repo </span><br><span class="line">sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key</span><br><span class="line">sudo yum -y install jenkins</span><br><span class="line">sudo service jenkins start</span><br></pre></td></tr></table></figure></p>
<h1 id="CodeDeploy"><a href="#CodeDeploy" class="headerlink" title="CodeDeploy"></a>CodeDeploy</h1><p><img src="https://i.imgur.com/ZRCFrZP.png" alt="codedeploy ec2"></p>
<h1 id="Cloud9"><a href="#Cloud9" class="headerlink" title="Cloud9"></a>Cloud9</h1><p><strong>What is Cloud9</strong></p>
<ul>
<li>Cloud9 integrates with other AWS DevOps tools such as CodeCommit, CodePipeline, and CodeStar to enable a rich development pipeline with continuous delivery</li>
<li>AWS Cloud9 contains a collection of tools that you use to code, build, run, test, debug, and release software on the cloud</li>
<li>Use the AWS Cloud9 Integrated Development Environment (IDE) to work with these tools<br><strong>What can i do with aws Cloud 9</strong></li>
<li>Supported languages:<ul>
<li>C++</li>
<li>Java</li>
<li>Python</li>
<li>.NET</li>
<li>Node.js</li>
<li>PHP</li>
<li>Pearl</li>
<li>Ruby</li>
<li>Go</li>
<li>JavaScript</li>
<li>CoffeeScript</li>
</ul>
</li>
<li>Supported integrations:<ul>
<li>CodeCommit</li>
<li>CodePipeline</li>
<li>CodeStar</li>
<li>API gateway</li>
<li>Lambda</li>
<li>Lightsail</li>
<li>DynamoDB</li>
<li>RDS</li>
<li>AWS CLI</li>
<li>Docker</li>
<li>GitHub</li>
</ul>
</li>
<li>Supported environments<ul>
<li>EC2</li>
<li>SSH</li>
<li>Single-user environment</li>
<li>Shared team environment</li>
<li>virtualenv<h1 id="CodeBuild"><a href="#CodeBuild" class="headerlink" title="CodeBuild"></a>CodeBuild</h1><h1 id="CodePipeline"><a href="#CodePipeline" class="headerlink" title="CodePipeline"></a>CodePipeline</h1><h1 id="CodeStart"><a href="#CodeStart" class="headerlink" title="CodeStart"></a>CodeStart</h1></li>
</ul>
</li>
</ul>
<h1 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h1><ul>
<li><a href="https://aws.amazon.com/devops/what-is-devops/">What is DevOps</a></li>
<li><a href="https://aws.amazon.com/pricing/">AWS pricing</a></li>
<li><a href="https://docs.aws.amazon.com/codepiepline/latest/userguide/tutorials-simple-codecommit.html">TUtorial-create a simple pipeline</a></li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/aws/">aws</a><a href="/tags/Codecommit/">Codecommit</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/15/devops-with-aws/" title="devops-with-aws" itemprop="url">devops-with-aws</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-15T13:44:53.000Z" itemprop="datePublished"> Published 2019-07-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="Project-setup"><a href="#Project-setup" class="headerlink" title="Project setup"></a>Project setup</h1><p><a href="https://github.com/espiderinc/hapi-rest-demo">code</a></p>
<h2 id="Importance-of-automated-test-in-CI-CD"><a href="#Importance-of-automated-test-in-CI-CD" class="headerlink" title="Importance of automated test in CI,CD"></a>Importance of automated test in CI,CD</h2><ul>
<li>Automated tests<ul>
<li>Unit tests</li>
<li>Integration tests</li>
<li>UAT tests</li>
</ul>
</li>
<li>Code coverage</li>
<li>Notifications<h2 id="CI-CD-with-relational-databases"><a href="#CI-CD-with-relational-databases" class="headerlink" title="CI/CD with relational databases"></a>CI/CD with relational databases</h2></li>
<li>Managing the version of database schema<br>There is no easy way to control the version of relational database schema</li>
<li>Database schema migrations</li>
<li>DellStore2 sample database<ul>
<li>Products table</li>
</ul>
</li>
<li>Sqitch change management system<h2 id="Project-component-setup"><a href="#Project-component-setup" class="headerlink" title="Project component setup"></a>Project component setup</h2></li>
<li>PostgreSQL database on AWS RDS</li>
<li>Node.JS HAPI RESTful API project</li>
<li>Sqitch database mangement framework<h2 id="Setup-PostreSQL-database-instance-in-AWS-RDS"><a href="#Setup-PostreSQL-database-instance-in-AWS-RDS" class="headerlink" title="Setup PostreSQL database instance in AWS RDS"></a>Setup PostreSQL database instance in AWS RDS</h2></li>
</ul>
<ol>
<li>Create a rds in aws with postgresql engine version 9.4.7.</li>
<li>Connect to aws rds use pgAdmin 3.</li>
<li>Download sample schema dellstore2 from <a href="http://pgfoundry.org/projects/dbsamples/">link</a></li>
<li>In pgAdmin3 click Plugins-&gt; PSQL console-&gt; run command <code>\i /tmp/dellstore2.sql</code> to create a new schema.<h2 id="Setup-Node-JS-HAPI-ReSTful-API-project"><a href="#Setup-Node-JS-HAPI-ReSTful-API-project" class="headerlink" title="Setup Node.JS HAPI ReSTful API project"></a>Setup Node.JS HAPI ReSTful API project</h2><strong>HAPI</strong> is a rich application framework for building applications and RESTful APIs with Node.JS</li>
</ol>
<p>Official website for HAPI framework is HAPIJS.com</p>
<ol>
<li>install node and npm<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br><span class="line">mkdir myfirsthapiproject</span><br><span class="line">cd myfirsthapiproject</span><br><span class="line">npm init</span><br><span class="line">npm install --save hapi</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>2.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/espiderinc/hapi-rest-demo.git</span><br><span class="line">cd hapi-rest-demo</span><br><span class="line">npm install</span><br><span class="line">sudo npm install -g istanbul mocha</span><br><span class="line">node index.js</span><br></pre></td></tr></table></figure></p>
<ol start="3">
<li><p><img src="https://i.imgur.com/rCcEgzW.png" alt="access by">)<br><img src="https://i.imgur.com/VdGe8f3.png" alt="Imgur"></p>
</li>
<li><p>test</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">hapi-rest-demo git:(master) ✗ npm test</span><br><span class="line"></span><br><span class="line">&gt; hapi-rest-demo@1.0.0 test /home/stan/workspace/hapi-rest-demo</span><br><span class="line">&gt; istanbul cover _mocha test/**/*.js</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(node:20777) [DEP0022] DeprecationWarning: os.tmpDir() is deprecated. Use os.tmpdir() instead.</span><br><span class="line">  Task routes</span><br><span class="line">    GET /products</span><br><span class="line">      ✓ should return statusCode 200 (381ms)</span><br><span class="line">      ✓ should return product [ACADEMY BROOKLYN] </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  2 passing (416ms)</span><br><span class="line"></span><br><span class="line">=============================================================================</span><br><span class="line">Writing coverage object [/home/stan/workspace/hapi-rest-demo/coverage/coverage.json]</span><br><span class="line">Writing coverage reports at [/home/stan/workspace/hapi-rest-demo/coverage]</span><br><span class="line">=============================================================================</span><br><span class="line"></span><br><span class="line">=============================== Coverage summary ===============================</span><br><span class="line">Statements   : 56.31% ( 58/103 )</span><br><span class="line">Branches     : 39.29% ( 11/28 )</span><br><span class="line">Functions    : 47.83% ( 11/23 )</span><br><span class="line">Lines        : 57% ( 57/100 )</span><br><span class="line">================================================================================</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>report generated workspace/hapi-rest-demo/coverage/lcov-report/index.html</p>
<h2 id="Setup-swtich-database-schema-framework"><a href="#Setup-swtich-database-schema-framework" class="headerlink" title="Setup swtich (database schema framework)"></a>Setup swtich (database schema framework)</h2><p>Managin database schema for relational databaes (with Sqitch)<br><strong>Sqitch</strong> is a standalone system without any dependency on frameworks or ORMs.</p>
<ul>
<li>handels dependencies between scripts</li>
<li><a href="http://sqitch.org">project site</a><br><strong>install sqitch</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker pull sqitch/sqitch</span><br><span class="line">curl -L https://git.io/fAX6Z -o sqitch &amp;&amp; chmod +x sqitch</span><br><span class="line">mv sqitch /usr/bin/</span><br><span class="line">sudo apt-get install -y libdbd-pg-perl postgresql-client</span><br><span class="line">sqitch --version</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>use sqitch</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">mkdir stantutorial</span><br><span class="line">cd stantutorial</span><br><span class="line">sqitch init stantutorial --uri http://github.com/espiderinc/hapi-rest-demo.git</span><br><span class="line">cat sqitch.conf</span><br><span class="line"> [core]</span><br><span class="line">         engine = pg</span><br><span class="line">        # plan_file = sqitch.plan</span><br><span class="line">        # top_dir = .</span><br><span class="line">sqitch config --user user.name &apos;StanTutorial&apos;</span><br><span class="line">sqitch config --user user.email &apos;devops@cwzhou.win&apos;</span><br><span class="line">sqitch add schema -n &apos;Add schema for tutorial objects.&apos;</span><br><span class="line">Created deploy/schema.sql</span><br><span class="line">Created revert/schema.sql</span><br><span class="line">Created verify/schema.sql</span><br><span class="line">Added &quot;schema&quot; to sqitch.plan</span><br><span class="line"></span><br><span class="line"> cat deploy/schema.sql</span><br><span class="line">-- Deploy stantutorial:schema to pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">CREATE SCHEMA tutorial;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">cat revert/schema.sql</span><br><span class="line">-- Revert stantutorial:schema from pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">DROP SCHEMA tutorial;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line"> cat verify/schema.sql</span><br><span class="line">-- Verify stantutorial:schema on pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add verifications here.</span><br><span class="line"></span><br><span class="line">select 1/count(*) from information_schema.schemata where schema_name=&apos;tutorial&apos;;</span><br><span class="line"></span><br><span class="line">ROLLBACK;</span><br><span class="line"></span><br><span class="line"> sqitch add video --requires schema -n &apos;add video table to schema tutorial&apos;</span><br><span class="line"></span><br><span class="line"> cat deploy/video.sql</span><br><span class="line">-- Deploy stantutorial:video to pg</span><br><span class="line">-- requires: schema</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">SET client_min_messages = &apos;warning&apos;;</span><br><span class="line">CREATE TABLE tutorial.video(</span><br><span class="line">        subject TEXT    PRIMARY KEY,</span><br><span class="line">        comment TEXT,</span><br><span class="line">        timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW()</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">cat revert/video.sql</span><br><span class="line">-- Revert stantutorial:video from pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">DROP TABLE tutorial.video;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line"></span><br><span class="line">cat verify/video.sql</span><br><span class="line">-- Verify stantutorial:video on pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add verifications here.</span><br><span class="line">select subject, comment, timestamp</span><br><span class="line">from tutorial.video</span><br><span class="line">where false;</span><br><span class="line"></span><br><span class="line">ROLLBACK;</span><br><span class="line">sqitch deploy db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch status db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch verify db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch revert db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br><span class="line">sqitch status db:pg://foo:bar@stantest-postgresql.c3mzoji03zxf.ap-southeast-2.rds.amazonaws.com:5432/postgres</span><br></pre></td></tr></table></figure></p>
<h1 id="CI-and-CD-pipeline-deep-dive"><a href="#CI-and-CD-pipeline-deep-dive" class="headerlink" title="CI and CD pipeline deep dive"></a>CI and CD pipeline deep dive</h1><h2 id="AWS-prerequisites"><a href="#AWS-prerequisites" class="headerlink" title="AWS prerequisites"></a>AWS prerequisites</h2><ul>
<li>IAM instance profile</li>
</ul>
<ol>
<li><p>Create a policy, name: CodeDeploy-EC2-Permissions, json</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class="line">    &quot;Statement&quot;: [</span><br><span class="line">     &#123;</span><br><span class="line">        &quot;Action&quot;:[</span><br><span class="line">           &quot;s3:Get*&quot;,</span><br><span class="line">           &quot;s3:List*&quot;  </span><br><span class="line">        ],</span><br><span class="line">        &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">        &quot;Resource&quot;: &quot;*&quot;</span><br><span class="line">     &#125;    </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Create a role, named CodeDeploy-EC2 -&gt; Choose role type ec2-&gt;Attach permissions policies “CodeDeploy-EC2-Permissions”</p>
</li>
</ol>
<ul>
<li>IAM service role</li>
</ul>
<ol>
<li>Create a role named stantutorialRole -&gt; select role type CodeDeploy</li>
</ol>
<h2 id="Jenkins-installation"><a href="#Jenkins-installation" class="headerlink" title="Jenkins installation"></a>Jenkins installation</h2><p>Ubuntu-&gt; Configure Instance Details, IAM role, select CodeDeploy-EC2 (this will allow jenkins connect to s3 buckets)-&gt;<br>Tag instance: Key group Value hapi-demo<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget -q -O - http://pkg.jenkins-ci.org/debian/jenkins-ci.org.key| sudo apt-key add -</span><br><span class="line">sudo vim /etc/apt/sources.list # add following line</span><br><span class="line">deb http://pkg.jenkins-ci.org/debian-stable binary/</span><br><span class="line">sudo apt-get install default-jdk</span><br><span class="line">sudo apt-get install jenkins</span><br><span class="line">sudo service jenkins start</span><br></pre></td></tr></table></figure></p>
<p>Install plugin AWS CodePipeline<br>Install node.js:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -</span><br><span class="line">apt-get install -y nodejs</span><br><span class="line">sudo npm install -g npm</span><br><span class="line">node -v</span><br></pre></td></tr></table></figure></p>
<p>Install sqitch<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install build-essential cpanminus perl perl-doc</span><br><span class="line">cpanm --quiet --notest App::Sqitch</span><br><span class="line">sqitch --version</span><br><span class="line">apt-get install -y postgresql libdbd-pg-perl</span><br></pre></td></tr></table></figure></p>
<p>Create a new instance hapi-demo install node.js and<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python3-pip</span><br><span class="line">sudo apt install ruby-full</span><br><span class="line">sudo apt install wget</span><br><span class="line">wget https://aws-codedeploy-ap-southeast-2.s3.amazonaws.com/latest/install</span><br><span class="line">chmod +x install</span><br><span class="line">sudo ./install auto</span><br></pre></td></tr></table></figure></p>
<h2 id="CodeDeploy-application"><a href="#CodeDeploy-application" class="headerlink" title="CodeDeploy application"></a>CodeDeploy application</h2><p>Create a new Codedeploy application, choose compute type ec2/on-premises, Service role-&gt; statutorialRole; Environment configuration tick Amazon EC2 instances, Key-&gt; Name, Value-&gt; hapi-demo; Deployment setting-&gt; CodeDeployDefault.OneAtATime</p>
<h2 id="Review-appSpec-yml-file"><a href="#Review-appSpec-yml-file" class="headerlink" title="Review appSpec.yml file"></a>Review appSpec.yml file</h2><p>appspec.yml file is an application specification file for aws codedeploy</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat appspec.yml</span><br><span class="line">version: 0.0</span><br><span class="line">os: linux</span><br><span class="line">files:</span><br><span class="line">  - source: /</span><br><span class="line">    destination: /myapp</span><br><span class="line">permissions:</span><br><span class="line">  - object: /myapp/startApp.sh</span><br><span class="line">    mode: 777</span><br><span class="line">hooks:</span><br><span class="line">  ApplicationStart:</span><br><span class="line">    - location: startApp.sh</span><br><span class="line">      timeout: 10</span><br></pre></td></tr></table></figure>
<h2 id="Setup-Jenkins-job"><a href="#Setup-Jenkins-job" class="headerlink" title="Setup Jenkins job"></a>Setup Jenkins job</h2><p>Create a freestyle jenkins job, configurat as following screenshots:<br><img src="https://i.imgur.com/yb9AZch.png" alt="screenshot01"><br><img src="https://i.imgur.com/jxkg9xA.png" alt="screenshot02"><br><img src="https://i.imgur.com/ghjvXwd.png" alt="screenshot03"></p>
<h2 id="Build-AWS-CodePieline"><a href="#Build-AWS-CodePieline" class="headerlink" title="Build AWS CodePieline"></a>Build AWS CodePieline</h2><ol>
<li>Source provider <a href="https://github.com/stanosaka/hapi-rest-demo">GitHub</a></li>
<li>Build provider: Add Jenkins; Prvider name must match the name in jenkin’s job</li>
<li>Deployment provider: aws codedeploy<br><img src="https://i.imgur.com/Zcps1fo.png" alt="aws codedeploy"><br><img src="https://i.imgur.com/e2nGdbj.png" alt="deployed pages"><br><img src="https://i.imgur.com/eJAhUJH.png" alt="api"><br><img src="https://i.imgur.com/MJs6nKN.png" alt="lcov-report"></li>
</ol>
<h1 id="Next-Steps"><a href="#Next-Steps" class="headerlink" title="Next Steps"></a>Next Steps</h1><h2 id="Notifications"><a href="#Notifications" class="headerlink" title="Notifications"></a>Notifications</h2><p>AWS SNS notifications for build and deployment status</p>
<ol>
<li>Create a policy named: notification-policy<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class="line">    &quot;Statement&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">            &quot;Action&quot;: &quot;sns:Publish&quot;,</span><br><span class="line">            &quot;Resource&quot;: &quot;*&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>Attach notification-policy to Role CodeDeploy-EC2</p>
<ol start="2">
<li>in CodeDeploy edit deployment group;<br><img src="https://i.imgur.com/Lx8Kxdw.png" alt="create deployment trigger"><br><img src="https://i.imgur.com/Xl4OvF8.png" alt="notification"></li>
</ol>
<h2 id="Code-changes"><a href="#Code-changes" class="headerlink" title="Code changes"></a>Code changes</h2><p>Automatically and continuously deploy code without any downtime</p>
<h2 id="Database-schema-changes"><a href="#Database-schema-changes" class="headerlink" title="Database schema changes"></a>Database schema changes</h2><p>Consistently and automatically deploy relational database schema changes<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sqitch add product-add-comments</span><br><span class="line">cat /db/deploy/product-add-comments.sql</span><br><span class="line">-- Deploy spidertutorial:product-add-comments to pg</span><br><span class="line"></span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">-- XXX Add DDLs here.</span><br><span class="line">alter table products add comments varchar(100) default &apos;default comments&apos;;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br><span class="line">git commit -a -m &quot;add new column to products&quot;</span><br><span class="line">git push origin master:master</span><br></pre></td></tr></table></figure></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Jenkins/">Jenkins</a><a href="/tags/Devops/">Devops</a><a href="/tags/CD-CI/">CD/CI</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/15/splunk/" title="splunk" itemprop="url">splunk</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-15T00:40:04.000Z" itemprop="datePublished"> Published 2019-07-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><a href="https://github.com/PacktPublishing/Splunk-7.x-Quick-Start-Guide">code</a></p>
<h1 id="What-is-Splunk"><a href="#What-is-Splunk" class="headerlink" title="What is Splunk?"></a>What is Splunk?</h1><p>Splunk is a software platform that collects and stores all this machine data in one place.<br><img src="https://i.imgur.com/wObsIBw.png" alt="splunk data sources and use cases"></p>
<h2 id="Splunk-products"><a href="#Splunk-products" class="headerlink" title="Splunk products"></a>Splunk products</h2><ul>
<li><strong>Splunk Enterprise</strong>: designed for on-premise deployments</li>
<li><strong>Splunk Cloud</strong>: a cloud-based <strong>software as a service (SaaS)</strong> version of Splunk Enterprise.</li>
<li><strong>Splunk Light</strong>: is designed to be a small-scale solution.</li>
<li><strong>Splunk Free</strong>: is a free version of the core Splunk Enterprise product that has limits on users(one user), ingestion volume (500 MB/day), and other features.</li>
</ul>
<p><strong>Splunk components</strong></p>
<ul>
<li>Universal forwarder</li>
<li>Indexer and indexer clusters</li>
<li>Search head and search head clusters</li>
<li>Deployment server</li>
<li>Deployer</li>
<li>Cluster master</li>
<li>License master</li>
<li>Heavy forwarder<br>Universal forwarders, indexers, and search heads constitute the majority of Splunk functionality; the other components provide supporting roles for larger clustered/distributed environments.<br><img src="https://i.imgur.com/sqJ8esH.png" alt="Splunk components in a distributed deployment"></li>
</ul>
<p>The <strong>universal forwarder (UF)</strong> is a free small-footprint version of Splunk Enterprise that is installed on each application, web, or other type of server to collect data from specified log files and forward this data to Splunk for indexing(storage). In A large Splunk deployment, you may have hundreds or thousands of forwards that consume and forward data for indexing.</p>
<p>An <strong>indexer</strong> is the Splunk component that creates and manages indexes, which is where machine data is stored. Indexers perform two main functions: parsing and storing data, which has been received from forwarders or other data sources into indexes, and searching and returning the indexed data in response to search requests.</p>
<p>An indexing cluster is a group of indexers that have been configured to work together to handle higher volumes of both incmoing data to be indexed and search requests to be serviced, as well as providing redundancy by keeping duplicate copies of indexed data spread across the cluster members.</p>
<p>A <strong>search head</strong> is an instance of Splunk Enterprise that handles search management functions. This includes providing a web-based user interface called Splunk Web, from which users issue search requests in what is called <strong>Search Processing Language (SPL)</strong>. Search reqeusts initiated by a user ( or a report or dashboard) are sent to one or more indexers to locate and return the requested data; the search head then formates the returned data for presentation to the user.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index=_internal | stats count by source, sourcetype</span><br></pre></td></tr></table></figure>
<p>an example of executing a simple search in Splunk Web. The SPL specifies searching in the <code>_internal</code> index, which is where Splunk saves data about its internal operations, and provides a count of the number of events in each log for Today. The SPL command specified an <code>index</code>, and then pipes the returned results to the <code>stats</code> command to return a <code>count</code> of all the events by their <code>source</code> and `sourcetype<br><img src="https://i.imgur.com/exMXaN5.jpg" alt="Simple search in Splunk Web"></p>
<p>A <strong>deployment server</strong> is a Splunk Enterprise instance that acts as a centralized configuration manager ofr a number of Splunk components, but which in practice is used to manage UFs.</p>
<p>A <strong>deployer</strong> is a Splunk Enterprise instance that is ued to distribute Splunk apps and certain other configuration updates to search head cluster memebers.</p>
<p>A <strong>cluster master</strong> is a Splunk Enterprise instance that coordinates the activities of an indexing cluster.</p>
<p>A <strong>license master</strong> is a single Splunk Enterprise instance that provides a licensing service for the multiple instances of Splunk that have been deployed in a distributed environment.</p>
<p>A <strong>heavy forwarder</strong> is an instance of Splunk Enterprise that can receive data from other forwarders or data sources and parse, index, and/or send data to another Splunk instance for indexing. </p>
<p>Splunk Enterprise also has a monitoring tool function called the <strong>monitoring console</strong>, which lets you view detailed topology and performance information about your entire distributed deployment from one interface. </p>
<p><img src="https://i.imgur.com/ElU7rTv.png" alt="Splunk data pipeline"></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/splunk/">splunk</a><a href="/tags/monitoring/">monitoring</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/13/terraform/" title="terraform" itemprop="url">terraform</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-13T03:29:54.000Z" itemprop="datePublished"> Published 2019-07-13</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><a href="https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS">Supplemental content</a></p>
<h1 id="Install-Terraform-and-Tools-on-linux"><a href="#Install-Terraform-and-Tools-on-linux" class="headerlink" title="Install Terraform and Tools on linux"></a>Install Terraform and Tools on linux</h1><h2 id="Terraform-development-environment"><a href="#Terraform-development-environment" class="headerlink" title="Terraform development environment"></a>Terraform development environment</h2><ul>
<li>Terraform</li>
<li>aws account</li>
<li>aws cli with credentials configured</li>
<li>git</li>
<li>shell (bash, pwoershell, cmd, git-bash)</li>
<li>Text editor (visual studio code with Extensions terraform)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://releases.hashicorp.com/terraform/0.12.4/terraform_0.12.4_linux_amd64.zip</span><br><span class="line">unzip terraform_0.12.4_linux_amd64.zip</span><br><span class="line">sudo mv terraform /usr/local/bin</span><br><span class="line">terraform version</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="First-deployment-with-Terraform"><a href="#First-deployment-with-Terraform" class="headerlink" title="First deployment with Terraform"></a>First deployment with Terraform</h1><h2 id="Configuration-language-basics"><a href="#Configuration-language-basics" class="headerlink" title="Configuration language basics"></a>Configuration language basics</h2><p>Terraform uses HCL (Hashicorp configuration language)</p>
<ul>
<li>human friendliness</li>
<li>JSON is quite verbose and doesn’t support comments, is machine readable</li>
<li>YAML is quite easy to mess up indentation and it’s not always clear whether you should use a colon or hyphen(specially when you using nested maps and lists)- machine-friendly, which is designed to be written and modified by humans</li>
<li>can sue JSON as input to Terraform</li>
</ul>
<p><strong>main features of HCL</strong></p>
<ul>
<li>can have single-line comments, start with a double slash or a number sign</li>
<li>multi-line comments are wrapped in /*</li>
<li>Values assign syntax key = vaule</li>
<li>Strings are double bolded</li>
<li>Numbers, booleans, arrays, lists, objects, named maps or dictonaries</li>
<li>Interpolations, conditionals, and various build-in functions</li>
</ul>
<h2 id="Set-up-aws-provider"><a href="#Set-up-aws-provider" class="headerlink" title="Set up aws provider"></a>Set up aws provider</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir s3_backbone &amp;&amp; cd s3_backbone</span><br><span class="line">git init</span><br><span class="line">terraform init</span><br></pre></td></tr></table></figure>
<p>Provide: Terraform object that is responsible for managing the lifecycle of a resouce:</p>
<ul>
<li>Create, REad, Update, and Delete operations (CRUD)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat providers.tf</span><br><span class="line">provider &quot;aws&quot;&#123;</span><br><span class="line">  region = &quot;ap-southeast-2&quot;</span><br><span class="line">&#125;</span><br><span class="line">git add -A</span><br><span class="line">git commit -m &quot;Add aws provider&quot;</span><br><span class="line">terraform init</span><br><span class="line">git status</span><br><span class="line">echo &quot;.terraform&quot; &gt;&gt; .gitignore</span><br><span class="line">git status</span><br><span class="line">git add .gitignore&amp;&amp; git commit -m &quot;Add .gitignore&quot;</span><br><span class="line">terraform plan # creates an execution plan</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Deploy-an-s3-bucket-into-aws"><a href="#Deploy-an-s3-bucket-into-aws" class="headerlink" title="Deploy an s3 bucket into aws"></a>Deploy an s3 bucket into aws</h2><p>google terraform s3 bucket<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat s3.tf</span><br><span class="line">resource &quot;aws_s3_bucket&quot; &quot;main&quot; &#123;</span><br><span class="line">  bucket = &quot;packt-terraform-section2-bucket-stan&quot;</span><br><span class="line">  acl    = &quot;private&quot;</span><br><span class="line">&#125;</span><br><span class="line">git add . &amp;&amp; git commit -m &quot;Add S3 bucket&quot;</span><br><span class="line">terraform plan</span><br><span class="line"># The output of this command is similar to what we get when we run the diff command on Linux: resources with a plus sign are going to be created, resources with the minus sign are going to be deleted, and resources with a tilde sign are going to be modified</span><br><span class="line">terraform apply</span><br><span class="line">git status</span><br><span class="line"># notice that Terraform also created a new file, terraform.tfstate</span><br><span class="line"># it&apos;s a JSON file, which contains some information about the bucket we just created. Terraform uses the state file to map real-world resources to your configuration, and keep track of metadata</span><br></pre></td></tr></table></figure></p>
<p><strong>What is state?</strong></p>
<ul>
<li>Desired state</li>
<li>Actual state</li>
<li>Known state<br>When we write our configuration files, we describe the desired state. This is how we want our infrastructure to be. Then there’s the actual state: this is how our infrastructure looks like, right now. You can get this actual state by exploring your infrastructure in the web console, or running some describe commands against the API. And to bridge these two states, there is the known state, which is stored in the state file. Terraform uses it to keep track of all resources it already created for this set of templates. In general, this known state should be the same as the actual state. When we run the plan command, Terraform performs a refresh, and then determines what actions are necessary to achieve the desired state specified in the configuration files. When you run the apply command, Terraform executes the planned actions, and then stores the updated actual state in the state file.</li>
</ul>
<p>for example, you went to the web console and manually changed something - Terraform will detect such changes, and unless they also exist in the desired state, it will revert them. So, if we are going to treat our <strong>infrastructure as code</strong>, we should get into the mindset of not changing our sources manually.</p>
<p>Make sure the state file is ignored by Git<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> cat .gitignore</span><br><span class="line">.terraform</span><br><span class="line"></span><br><span class="line">*.tfstate*</span><br><span class="line">git add -A &amp;&amp; git commit -m &quot;Ignore TF state&quot;</span><br></pre></td></tr></table></figure></p>
<h2 id="Structuring-the-project"><a href="#Structuring-the-project" class="headerlink" title="Structuring the project"></a>Structuring the project</h2><p>Typical project structure<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">|-main.tf</span><br><span class="line">|-outputs.tf</span><br><span class="line">|-variables.tf</span><br></pre></td></tr></table></figure></p>
<p>group related resources together, and keep the configuration files to a manageable size - ideally, not longer than 200 lines of code.</p>
<h1 id="Modifying-resoureces"><a href="#Modifying-resoureces" class="headerlink" title="Modifying resoureces"></a>Modifying resoureces</h1><h2 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h2><p>Keep the code DRY- Don’t Repeat Yourself-SOFTWARE ENGINEERING PRICIPLE aimed at reducing interpretation of the same data</p>
<p>Terraform performs automatic conversion from string values to numeric and boolean values, based on context.</p>
<p>Maps are useful for selecting a value based on some other provided value.</p>
<p>A list value is an ordered sequence of strings, indexed by integers starting with 0.</p>
<p>Several ways to set variables:</p>
<ol>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">cat variables.tf</span><br><span class="line">variable &quot;s3_bucket_name&quot; &#123;</span><br><span class="line">        #default = &quot;packt-terraform-section2-bucket-stan&quot;</span><br><span class="line">        description = &quot;Name of the S3 bucket&quot;</span><br><span class="line">        type = &quot;string&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">variable &quot;s3_tags&quot; &#123;</span><br><span class="line">        type = &quot;map&quot;</span><br><span class="line"></span><br><span class="line">        default = &#123;</span><br><span class="line">                created_by = &quot;terraform&quot;</span><br><span class="line">                environment = &quot;test&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">variable &quot;s3_regions&quot; &#123;</span><br><span class="line">        type = &quot;list&quot;</span><br><span class="line">        default = [&quot;ap-southeast-2&quot;, &quot;us-west-2&quot;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">terraform plan</span><br><span class="line">var.s3_bucket_name</span><br><span class="line">  Name of the S3 bucket</span><br><span class="line"></span><br><span class="line">  Enter a value: packt-terraform-section2-bucket-stan</span><br><span class="line"></span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">terraform plan -var &apos;s3_bucket_name=&quot;packt-terraform-section2-bucket-stan&quot;&apos;</span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>3.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TF_VAR_s3_bucket_name=&quot;packt-terraform-section2-bucket-stan&quot; terraform plan</span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure></p>
<p><strong>Variable definition files</strong></p>
<ul>
<li>We can also have multiple tfvars files, and pass them explicitly to Terraform using the var file flag. If we pass several files, Terraform will merge their values - and if a particular variable is defined in more than one variable file, the last value that is filed wins. </li>
<li>Terraform automatically loads all files which match terraform.tfvars or *.auto.tfvars from the current directory</li>
<li>Other files can be passed explicitly using -var-file flag<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat terraform.tfvars</span><br><span class="line">s3_bucket_name = &quot;packt-terraform-section2-bucket-stan&quot;</span><br><span class="line">terraform plan</span><br><span class="line">Refreshing Terraform state in-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to local or remote state storage.</span><br><span class="line"></span><br><span class="line">aws_s3_bucket.main: Refreshing state... [id=packt-terraform-section2-bucket-stan]</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>String Interpolation</strong></p>
<ul>
<li>The process of evaluating a string expression and replacing all paceholders with their values<br><code>&quot;${var.s3_bucket_name}&quot;</code><br><strong>First-Class Expressions</strong><br><code>var.s3_bucket_name</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> cat s3.tf</span><br><span class="line">resource &quot;aws_s3_bucket&quot; &quot;main&quot; &#123;</span><br><span class="line">  bucket = &quot;$&#123;var.s3_bucket_name&#125;&quot;</span><br><span class="line">  acl    = &quot;private&quot;</span><br><span class="line"></span><br><span class="line">  tags   = &#123;</span><br><span class="line">    env = &quot;$&#123;lookup(var.s3_tags, &quot;environment&quot;)&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  region =&quot;$&#123;var.s3_regions[0]&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line">#Terraform console is a useful tool for automation scripts, as it allows you to access arbitrary attributes from a Terraform configuration.</span><br><span class="line">terraform console</span><br><span class="line">&gt; var.s3_tags</span><br><span class="line">&#123;</span><br><span class="line">  &quot;created_by&quot; = &quot;terraform&quot;</span><br><span class="line">  &quot;environment&quot; = &quot;test&quot;</span><br><span class="line">&#125;</span><br><span class="line">&gt; var.s3_tags[&quot;environment&quot;]</span><br><span class="line">test</span><br><span class="line">&gt; exit</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Local-development-workflow"><a href="#Local-development-workflow" class="headerlink" title="Local development workflow"></a>Local development workflow</h2><p><strong>Using git to store state is a bad idea</strong></p>
<ul>
<li>maintenance overhead</li>
<li>secrets in plain text</li>
</ul>
<p><strong>State</strong></p>
<ul>
<li>Local state</li>
<li>Version Control</li>
<li>Remote state</li>
<li>Backends<ul>
<li>Terraform enterprise</li>
<li>S3</li>
<li>Consul: a service networking solution to connect and secure services across any runtime platform and public or private cloud.</li>
<li>Etcd</li>
<li>HTTP</li>
</ul>
</li>
</ul>
<p>Recommend using S3<br><strong>Local Values</strong></p>
<ul>
<li><strong>Input variables</strong> are similar to arguments of a function</li>
<li><strong>Local values</strong> are analogous to local variables within the function’s scope</li>
</ul>
<p>edit variables.tf file:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">locals &#123;</span><br><span class="line">        s3_tags= &#123;</span><br><span class="line">                created_by = &quot;terraform&quot;</span><br><span class="line">                environment = &quot;$&#123;var.environment&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>we can skip refreshing it again to save a couple of seconds, here. I will pass a flag, -refresh=false.<br>The state filei(terraform.tfstate) is also used to store some metadata, such as resource dependencies, or a pointer to the provider configuration in situations where multiple AWS providers are present. Another use is to store a cache of the attribute values for all the resources in the state. When we run terraform plan, Terraform must know the current state of resources, and by default it will query the providers and sync the latest attributes from all our resources. For large infrastructure, this can be too slow, and we may get throttled at the API level - so, as a performance improvement, there is an option to disable this behavior by passing refresh=false flag.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">terraform plan -refresh=false</span><br><span class="line"></span><br><span class="line">An execution plan has been generated and is shown below.</span><br><span class="line">Resource actions are indicated with the following symbols:</span><br><span class="line">-/+ destroy and then create replacement</span><br><span class="line"></span><br><span class="line">Terraform will perform the following actions:</span><br><span class="line"></span><br><span class="line">terraform apply -auto-approve  ##skip answer yes</span><br><span class="line"></span><br><span class="line">export TF_CLI_ARGS_apply=&quot;-auto-approve&quot;</span><br></pre></td></tr></table></figure></p>
<p><strong>Common Workflow</strong></p>
<ul>
<li>validate</li>
<li>plan</li>
<li>apply</li>
<li>fmt<br><a href="https://github.com/antonbabenko/pre-commit-terraform">Pre-Commit Hooks</a><h2 id="Deleting-Resources"><a href="#Deleting-Resources" class="headerlink" title="Deleting Resources"></a>Deleting Resources</h2>1.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">terraform plan -destroy</span><br><span class="line">terraform destroy</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ol start="2">
<li>remove a resource from configuration and then run terraform plan &amp;&amp; terraform apply</li>
</ol>
<p>the 2nd one is more suted to CI/CD systems. You will most likely have some pipeline for provisioning your resources, but you may not necessarily have any automated way of destroying them, because this doesn’t happen that often. Another point is that, this way, you can destroy specific resources without having to pass special flags, which would require changes to automation scripts.</p>
<p><strong>Protect a resoure from deletion</strong><br>Use the life cycle meta-parameter.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lifecycle &#123;</span><br><span class="line">  prevent_destory = &quot;true&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Only protects against terraform destory.</p>
<h2 id="Managing-state"><a href="#Managing-state" class="headerlink" title="Managing state **"></a>Managing state <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em>**</em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h2><p><a href="https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS/tree/master/Section_3">code</a></p>
<p><strong>set up the remote state backend</strong></p>
<ol>
<li>Create the Terraform configuration section</li>
</ol>
<p>This block is special, as it configures the behavior of Terraform itself, such as setting up a backend or requiring a minimum Terraform version to execute a configuration.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  required_version = &quot;&gt; 0.11.7&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>if we have some configuration which we can’t migrate to the latest version, for some reason, we can pin it to an older version in this block. Let’s set the current version.</p>
<p><strong>Manage terraform versions for each project by Terraform switcher</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># MacOS with brew</span><br><span class="line">brew install warrensbox/tap/tfswitch</span><br><span class="line"># Linux</span><br><span class="line">curl -L https://raw.githubusercontent.com/warrensbox/terraform-switcher/release/install.sh | bash</span><br><span class="line">tfswitch</span><br></pre></td></tr></table></figure></p>
<ol start="2">
<li><p>Add a backend</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">backend &quot;s3&quot; &#123;</span><br><span class="line">    bucket = &quot;packt-terraform-bucket-stan-test-ap-southeast-2&quot;</span><br><span class="line">    key = &quot;test/backbone&quot;</span><br><span class="line">    region = &quot;ap-southeast-2&quot;</span><br><span class="line">    encrypt = &quot;true&quot;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Apply</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m &quot;Configure remote state&quot;</span><br><span class="line">git clean -fdx #clean the repository of all unchecked files</span><br><span class="line">Removing .terraform/</span><br><span class="line">Removing terraform.tfstate</span><br><span class="line">Removing terraform.tfstate.backup</span><br><span class="line">terraform init</span><br><span class="line">terraform plan #there is no more local state file anymore</span><br></pre></td></tr></table></figure>
</li>
<li><p>configuration todo</p>
</li>
</ol>
<ul>
<li><p>enforce encryption by default (here use the default one, you can use KMS instead)<br>by edit s3.tf:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server_side_encryption_configuration &#123;</span><br><span class="line">  rule &#123;</span><br><span class="line">    apply_server_side_encryption_by_default &#123;</span><br><span class="line">       sse_algorithm = &quot;AES256&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>versioning: alwasy have a way back</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">versioning &#123;</span><br><span class="line">   enabled = true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>lifecycle policy: Versioning will store all previous versions of the file, which will eventually bloat the bucket size. To reverse this, we can set a lifecycle policy. Remove all the version after 90 days. In your particular case, you might want to use a different value, or maybe move them to <strong>glacier storage</strong> instead of deleting the old files.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">lifecycle_rule &#123;</span><br><span class="line">   id      = &quot;state&quot;</span><br><span class="line">   prefix  = &quot;state/&quot;</span><br><span class="line">   enabled = true</span><br><span class="line"></span><br><span class="line">   noncurrent_version_expiration &#123;</span><br><span class="line">      days = 90</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Best Practices</strong></p>
<ul>
<li>Do not store state locally</li>
<li>Do not commit state to version control</li>
<li>If using S3:<ul>
<li>Enable versioning</li>
<li>Enforce encryption</li>
<li>Store state close to the infrastructure</li>
<li>Limit access to the bucket, consider enabling log in</li>
</ul>
</li>
</ul>
<h1 id="Building-a-multi-tier-environment"><a href="#Building-a-multi-tier-environment" class="headerlink" title="Building a multi-tier environment"></a>Building a multi-tier environment</h1><p><strong>What we will build?</strong></p>
<ul>
<li>Network layer-Virtual Private Cloud (VPC), internet gateway, public and private subnets, NAT gateway, and a bastion host)</li>
<li>Relational Database Service (RDS) instance running PostgreSQL</li>
<li>Elastic Container Service (ECS) cluster to host a dockerised app<br><strong>Provider Caching</strong></li>
<li><strong>terraform init</strong> downloads providers separately for each project</li>
<li>We can cache them by setting an environment variable<br>  export TF_PLUGIN_VACHE_DIR=”$HOME/.terraform.d/plugin-cache”<br><a href="https://github.com/PacktPublishing/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS/tree/master/Section_4/vpc">code</a><br><img src="https://i.imgur.com/Rzhlc11.png" alt="AWS VPC"><br><strong>Count Meta-Parameter</strong></li>
<li>Available to all resources</li>
<li>Allows creating multiple copies of a resouce without repeating its configuration</li>
<li>Helps keep your infrastructure code <strong>DRY</strong><br><strong>Splat Expression</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;aws_nat_gateway&quot; &quot;main&quot; &#123;</span><br><span class="line">  count         = &quot;$&#123;length(var.availability_zones)&#125;&quot;</span><br><span class="line">  subnet_id     = &quot;$&#123;element(aws_subnet.public.*.id, count.index)&#125;&quot;</span><br><span class="line">  allocation_id = &quot;$&#123;element(aws_eip.nat.*.id, count.index)&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>The challenge, here, is that the gateways need to reference the subnets and the IPS that we created, but because we used count, we don’t have a direct reference to each resource. We can resolve this by using a splat expression, which you can see in action where we reference the subnet ID and the allocation ID. A splat expression allows to obtain a list of attribute values from a set of resources created using the count argument. Notice this asterisk, which represents all values in the generated list.</p>
<h2 id="Organizing-data-with-output-variables"><a href="#Organizing-data-with-output-variables" class="headerlink" title="Organizing data with output variables"></a>Organizing data with output variables</h2><p><strong>Resources and data sources</strong></p>
<ul>
<li>Resources provide <strong>Create, Read, Update</strong>,and <strong>Delete</strong> functionality (CRUD)</li>
<li>Data srouces support <strong>read</strong> operations only<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data &quot;aws_ami&quot; &quot;amazon_linux&quot; &#123;</span><br><span class="line">  most_recent = true</span><br><span class="line">  filter &#123;</span><br><span class="line">    name   = &quot;name&quot;</span><br><span class="line">    values = [&quot;amzn-ami-*-x86_64-gp2&quot;]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Output Variables</strong></p>
<ul>
<li>Expose important resource attributes and make tme easier to query</li>
<li>Outputs are exposed to the user and stored in the state file during terraform apply</li>
<li>A single output block configures a single variable<br><strong>Example Output</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output &quot;vpc_id&quot; &#123;</span><br><span class="line">   value = &quot;$&#123;aws_vpc.main.id&#125;&quot;</span><br><span class="line">   description = &quot;VPC id&quot;</span><br><span class="line">   sensitive = false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>After we run the apply once, the outputs are stored in the state file - so, the next time we need to get them, we can use <code>terraform output</code>.<br>or<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">terraform output public_subnets</span><br></pre></td></tr></table></figure></p>
<p><strong>provider version</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> terraform providers</span><br><span class="line">.</span><br><span class="line">├── provider.aws 1.31</span><br><span class="line">└── provider.template</span><br><span class="line">ls -l ~/.terraform.d/plugin-cache/linux_amd64</span><br></pre></td></tr></table></figure></p>
<h2 id="Integrating-components-in-a-complex-environment"><a href="#Integrating-components-in-a-complex-environment" class="headerlink" title="Integrating components in a complex environment"></a>Integrating components in a complex environment</h2><p><img src="https://i.imgur.com/LcsUUkG.png" alt="Adding a database server"><br><strong>Steps to add a DB server</strong></p>
<ol>
<li>Create a VPC (done)</li>
<li>Add Subnets to the VPC (done)</li>
<li>Create a DB Subnet Group</li>
<li>Create a VPC Secruity Group</li>
<li>Create a DB Instance in the VPC</li>
</ol>
<p>Integrate separate Terraform configurations while keeping them in different projects</p>
<p>Remote state serves as a centralized source of truth:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> cat data_sources.tf</span><br><span class="line"># Remote state</span><br><span class="line">data &quot;terraform_remote_state&quot; &quot;vpc&quot; &#123;</span><br><span class="line">  backend = &quot;s3&quot;</span><br><span class="line"></span><br><span class="line">  config &#123;</span><br><span class="line">    bucket = &quot;packt-terraform-bucket-stan-test-$&#123;var.region&#125;&quot;</span><br><span class="line">    key    = &quot;test/vpc&quot;</span><br><span class="line">    region = &quot;$&#123;var.region&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Remote state allows us to share information between current projects, and to build our infrastructures in small atomic configurations focused on one thing.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db_subnet_group.tf</span><br><span class="line">subnet_ids = [&quot;$&#123;data.terraform_remote_state.vpc.private_subnets&#125;&quot;]</span><br></pre></td></tr></table></figure></p>
<p>Notice the interpolation syntax that we use.first, specify that it’s a data source - then its type, terraform remote state. Then comes the name of particular remote state, VPC, and lastly the attribute that we are interested in. </p>
<h2 id="Using-templates"><a href="#Using-templates" class="headerlink" title="Using templates"></a>Using templates</h2><p><img src="https://i.imgur.com/IjCKZfO.png" alt="Application tier"><br>deploy a small but realistic web application into our VPC. Our app runs in Docker, so we will provision an LST container service cluster - <strong>ECS</strong> - to host it in our private subnets. We will use <strong>Fargate</strong>, which is a managed compute and orchestration engine, so we won’t need to maintain EC2 instances that run our containers. </p>
<p><strong>Use Terraform templates to compose complex string inputs</strong><br>App: a REST API for a todo applicaton, written in Go. It uses Postgres scale database as its backend.</p>
<p><a href="https://hub.docker.com/r/endofcake/go-todo-rest-api-example/">public image on Docker hub</a></p>
<ol>
<li>provision an ECS cluster<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat ecs_cluster.tf</span><br><span class="line">resource &quot;aws_ecs_cluster&quot; &quot;main&quot; &#123;</span><br><span class="line">  name = &quot;$&#123;var.ecs_cluster_name&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>Partitioning Infrastructure</strong></p>
<ul>
<li>If the resources are likely to be created and destryoed together, they belong together</li>
<li>If some resource can be used by multiple other resources, it’s better to keep it sparate (VPC,RDS, and ECS cluster)</li>
</ul>
<p>template eg.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">bastion.tf</span><br><span class="line"># User data</span><br><span class="line">data &quot;template_file&quot; &quot;user_data&quot; &#123;</span><br><span class="line">  template = &quot;$&#123;file(&quot;$&#123;path.module&#125;/templates/user_data.sh&quot;)&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/tmplates/user_data.sh</span><br><span class="line">#!/bin/env bash</span><br><span class="line"></span><br><span class="line">set -euo pipefail</span><br><span class="line">exec &gt; &gt;(tee /var/log/user-data.log|logger -t user-data -s 2&gt;/dev/console) 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line">echo &quot;Starting user data...&quot;</span><br><span class="line">yum update -y</span><br><span class="line">yum install -y postgresql96.x86_64</span><br><span class="line">touch /home/ec2-user/success</span><br><span class="line">echo &quot;All done&quot;</span><br></pre></td></tr></table></figure></p>
<p>Next, I create template_cloudinit_config data source, and pull in the rendered template file. cloudinit_config allows us to compose multi-part user data scripts.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data &quot;template_cloudinit_config&quot; &quot;user_data&quot; &#123;</span><br><span class="line">  gzip          = true</span><br><span class="line">  base64_encode = true</span><br><span class="line"></span><br><span class="line">  part &#123;</span><br><span class="line">    content_type = &quot;text/x-shellscript&quot;</span><br><span class="line">    content      = &quot;$&#123;data.template_file.user_data.rendered&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>If we run terraform apply with this configuration on Windows, it most likely wouldn’t work - the problem is that Windows use a different line break tag, which is not valid on Linux. Windows use both carriage return and line feed, while Linux only uses line feed. The easiest way to check the line break tag is to look at the bottom right corner of the editor. Anyway, long story short, we want to make sure that this script is valid, even if we deploy our configuration from a Windows machine. This is probably the only case where there is any difference between running Terraform on Linux and on Windows. There are two changes that you should make to resolve this.</p>
<ol>
<li><p>add a gitattributes file</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat .gitattributes</span><br><span class="line"># Always LF</span><br><span class="line">*.sh text eol=lf</span><br></pre></td></tr></table></figure>
</li>
<li><p>use EditorConfig plugin to define how our text editor displays and saves our code<br><img src="https://i.imgur.com/55JD2B3.png" alt="editorconfig plugin"> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat .editorconfig</span><br><span class="line">[*.sh]</span><br><span class="line">end_of_line = lf</span><br><span class="line">indent_size = 2</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><a href="https://github.com/stanosaka/Hands-on-Infrastructure-Automation-with-Terraform-on-AWS/tree/master/Section_4/ecs_app_todo">ecs app todo code</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">~/terraform/ecs_app_todo|</span><br><span class="line">⇒  tree</span><br><span class="line">.</span><br><span class="line">├── cloudwatch.tf</span><br><span class="line">├── data_sources.tf</span><br><span class="line">├── ecs_task.tf</span><br><span class="line">├── graph.png</span><br><span class="line">├── iam.tf</span><br><span class="line">├── lb.tf</span><br><span class="line">├── outputs.tf</span><br><span class="line">├── providers.tf</span><br><span class="line">├── templates</span><br><span class="line">│   └── ecs_task.tpl</span><br><span class="line">├── terraform.tfvars</span><br><span class="line">└── variables.tf</span><br></pre></td></tr></table></figure></p>
<p>templates/ecs_task.tpl file: ECS task definition. It describes which Docker images to use, the required resources, and other configurations necessary to launch the containers. As you can see, it’s a JSON block, which I’ve extracted into a template. It requires a few parameters, mostly to set up the connection to the database. </p>
<p>ecs_task.tf file: This is the Terraform configuration of our ECS task. I’m using the familiar template file data source, and I’m passing the required variables using the vars parameter, which accepts a map of variables. Some of the variables come from the tfvars file, but many are imported from the remote state. </p>
<p>data_sources.tf file: If we check out our data sources, we see that we’re pulling in remote state from all three projects that we created earlier. </p>
<p>lb.tf file: another important resource that we are creating is the load balancer, which distributes income and application traffic across multiple targets, for high availability. It will also allow us to connect to our service from the public internet, and here is the security group which allows public access</p>
<p><strong>confirm it’s working</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">curl -d &apos;&#123;&quot;title&quot;:&quot;sample project&quot;&#125;&apos; -H &quot;Content-Type: application/json&quot; -X POST todoapp-alb-91218331.ap-southeast-2.elb.amazonaws.com/projects</span><br><span class="line">&#123;&quot;ID&quot;:1,&quot;CreatedAt&quot;:&quot;2019-07-21T12:20:38.881103057Z&quot;,&quot;UpdatedAt&quot;:&quot;2019-07-21T12:20:38.881103057Z&quot;,&quot;DeletedAt&quot;:null,&quot;title&quot;:&quot;sample project&quot;,&quot;archived&quot;:false,&quot;tasks&quot;:null&#125;</span><br><span class="line"></span><br><span class="line">curl todoapp-alb-91218331.ap-southeast-2.elb.amazonaws.com/projects</span><br><span class="line">[&#123;&quot;ID&quot;:1,&quot;CreatedAt&quot;:&quot;2019-07-21T12:20:38.881103Z&quot;,&quot;UpdatedAt&quot;:&quot;2019-07-21T12:20:38.881103Z&quot;,&quot;DeletedAt&quot;:null,&quot;title&quot;:&quot;sample project&quot;,&quot;archived&quot;:false,&quot;tasks&quot;:null&#125;]</span><br><span class="line"></span><br><span class="line">ssh bastion</span><br><span class="line">export PGPASSWORD=foobar</span><br><span class="line">export PGHOST=todoapp.foobar.ap-southeast-2.rds.amazonaws.com</span><br><span class="line">psql -U terraform -d todoapp</span><br><span class="line">todoapp=&gt; \d+</span><br><span class="line">                             List of relations</span><br><span class="line"> Schema |      Name       |   Type   |   Owner   |    Size    | Description</span><br><span class="line">--------+-----------------+----------+-----------+------------+-------------</span><br><span class="line"> public | projects        | table    | terraform | 16 kB      |</span><br><span class="line"> public | projects_id_seq | sequence | terraform | 8192 bytes |</span><br><span class="line"> public | tasks           | table    | terraform | 8192 bytes |</span><br><span class="line"> public | tasks_id_seq    | sequence | terraform | 8192 bytes |</span><br><span class="line">(4 rows)</span><br><span class="line">todoapp=&gt; select * from projects;</span><br><span class="line"> id |          created_at           |          updated_at           | deleted_at |     title      | archived</span><br><span class="line">----+-------------------------------+-------------------------------+------------+----------------+----------</span><br><span class="line">  1 | 2019-07-21 12:20:38.881103+00 | 2019-07-21 12:20:38.881103+00 |            | sample project | f</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure></p>
<h2 id="Working-with-dependency-graph"><a href="#Working-with-dependency-graph" class="headerlink" title="Working with dependency graph"></a>Working with dependency graph</h2><p><strong>Dependency graph</strong></p>
<ul>
<li>All resources in the configuration are organized into a graph</li>
<li>The graph is used to determine the order in which the resources are created<br><img src="https://i.imgur.com/9swFk8u.png" alt="Directed acyclic graph"><br>Terraform organizes all resources in a configuration in a directed acyclic graph. What this means in plain English is that the dependencies between the resources go in one direction, and there can be no cycles. So, no circular dependencies. When we run the plan command, Terraform builds this graph, checks whether there are any cycles, and then determines which operations can be run in parallel. By default, up to ten nodes in the graph can be processed concurrently. We can control this setting using the parallelism flag on the plan, apply, and destroy commands, but in most cases this is not required.<br><strong>Parallelism</strong></li>
<li>Up to 10 nodes can be processed concurrently by default</li>
<li>Conifgurable with <strong>-parallemism</strong> flag for plan, apply, and destroy commands (advanced setting)<br><strong>Dependencies</strong></li>
<li><p>Implicit-one resource references another resource using the interpolation syntax</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">resource &quot;aws_lb&quot; &quot;todo_app&quot; &#123;</span><br><span class="line">    security_groups = [&quot;$&#123;aws_security_group.lb.id&#125;&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Explicit-using depends_on metaparameter<br> <code>depends_on = [&quot;aws_security_group.lb&quot;]</code></p>
</li>
</ul>
<p>Use explicit dependencies to resolve race conditions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Have to set an explicit dependency here to avoid</span><br><span class="line">  # race condition with LB creation</span><br><span class="line">depends_on = [&quot;aws_lb_listener.todo_app&quot;]</span><br></pre></td></tr></table></figure></p>
<p><strong>tools</strong></p>
<ol>
<li><p><a href="http://graphviz.gitlab.io/download/">Graphviz</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">terraform graph|dot -Tpng &gt; graph.png</span><br><span class="line">terraform plan</span><br><span class="line">terraform graph -draw-cycles|dot -Tpng &gt; graph.png</span><br></pre></td></tr></table></figure>
</li>
<li><p><a href="https://github.com/28mm/blast-radius">blast radius</a></p>
</li>
</ol>
<h2 id="Main-takeaways"><a href="#Main-takeaways" class="headerlink" title="Main takeaways"></a>Main takeaways</h2><ul>
<li>Use outputs and remote state data source to integrate stacks of resources in a complex environment</li>
<li>Keep your code DRY by using <em>count</em> parameter and splat expressions</li>
<li>Use <strong>templates</strong> to generate complex string inputs, such as user data scripts or ECS task definitions</li>
</ul>
<h1 id="Creating-reusable-components-with-moduels"><a href="#Creating-reusable-components-with-moduels" class="headerlink" title="Creating reusable components with moduels"></a>Creating reusable components with moduels</h1><h2 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h2><ul>
<li>Self-contained packages of Terraform configurations that are managed as a group<br>When we want to avoid writing duplicate code in a general-purpose programming language, we usually write a library. In, Terraform, we can put our code in a <strong>module</strong>.</li>
<li>Improve code resue</li>
<li>Provide an abstration layer<br>for example, you may need to add a vault cluster to your environment, and the vault is another great Hashicorp tool which is used for managing secrets, which requires dozens of components - but instead of thinking about individual security groups or EC2 instances, you can treat all these resources as a single group which requires some parameters, and gives you a ready-to-use vault cluster. </li>
<li>Can be teated as blackbox</li>
<li>Share best practices within an organization</li>
<li>Versioned artifacts</li>
</ul>
<h2 id="Creating-the-first-module"><a href="#Creating-the-first-module" class="headerlink" title="Creating the first module"></a>Creating the first module</h2><ul>
<li>Root module:<ul>
<li>The current working dirctory holding Terraform files</li>
</ul>
</li>
<li>Child modules:<ul>
<li>All modules sourced by the root (parent) module<br><strong>Delaring Modules</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">module &quot;child&quot; &#123;</span><br><span class="line">source = &quot;./child&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ol>
<li>rename ecs app project to module.ecs_app_web<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat main.tf</span><br><span class="line">module &quot;child&quot; &#123;</span><br><span class="line">    source = &quot;../module.ecs_app_web&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>terraform get</strong></p>
<ul>
<li>terraform get: Download modules referenced in the root module</li>
<li>terraform get -update: Check the downloaded modules for updates and download the new versions. if present<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> terraform get -update</span><br><span class="line">- module.child</span><br><span class="line">  Updating source &quot;../module.ecs_app_web&quot;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>When you run terraform get, the local modules will be simlinked into .terraform directory, so you can inspect what’s there if you notice some unexpected behavior.</p>
<ol start="2">
<li>copy terraform.tfvars and variables.tf, modify main.tf file, add<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">region = &quot;$&#123;var.region&#125;&quot; </span><br><span class="line">app_image_version = &quot;$&#123;var.app_image_version&#125;&quot; </span><br><span class="line">app_image_repository = &quot;$&#123;var.app_image_repository&#125;&quot; </span><br><span class="line">app_name = &quot;$&#123;var.app_name&#125;&quot; </span><br><span class="line">container_port = &quot;$&#123;var.container_port&#125;&quot; </span><br><span class="line">desired_count = &quot;$&#123;var.desired_count&#125;&quot; </span><br><span class="line">pgsslmode = &quot;$&#123;var.pgsslmode&#125;&quot; </span><br><span class="line">network_mode = &quot;$&#123;var.network_mode&#125;&quot; </span><br><span class="line">requires_compatibilities = &quot;$&#123;var.requires_compatibilities&#125;&quot; </span><br><span class="line">launch_type = &quot;$&#123;var.launch_type&#125;&quot; </span><br><span class="line">health_check_path = &quot;$&#123;var.health_check_path&#125;&quot;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>terraform providers</strong></p>
<ul>
<li>terraform providers:<ul>
<li>Print information about the providers used in the currrent configuration</li>
</ul>
</li>
<li>terraform providers [config-path]:<ul>
<li>Pass an explicit path to the configuration instead of using the current working directory by default<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> terraform providers</span><br><span class="line">.</span><br><span class="line">└── module.child</span><br><span class="line">    ├── provider.aws 1.31</span><br><span class="line">    ├── provider.template 1.0.0</span><br><span class="line">    └── provider.terraform</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>There is only one module, and it uses two providers - AWS and Template, plus a special provider called Terraform, which is responsible for working with the remote state backend.</p>
<p><strong>best practices</strong>: Keep explicit provider configurations only in the root module, and pass them down to descendant modules.</p>
<p><strong>Two wasy pass providers</strong></p>
<ul>
<li>the most common approach: let the descendant modules inherit the providers implicitly - that is, automatically</li>
<li>have several providers of the same type, and then pass them explicitly by alias; this can be useful if we need to create resources in different AWS regions, for example</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">root@stan-OptiPlex-380:~stan/Doc/Terraform/ecs_app_todo|master⚡</span><br><span class="line">⇒  mv ../module.ecs_app_web/providers.tf ./</span><br><span class="line">root@stan-OptiPlex-380:~stan/Doc/Terraform/ecs_app_todo|master⚡</span><br><span class="line">⇒  terraform init</span><br><span class="line">Initializing modules...</span><br><span class="line">- module.child</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line"></span><br><span class="line">Successfully configured the backend &quot;s3&quot;! Terraform will automatically</span><br><span class="line">use this backend unless the backend configuration changes.</span><br><span class="line"></span><br><span class="line">Initializing provider plugins...</span><br><span class="line">- Checking for available provider plugins on https://releases.hashicorp.com...</span><br><span class="line">- Downloading plugin for provider &quot;aws&quot; (1.31.0)...</span><br><span class="line">- Downloading plugin for provider &quot;template&quot; (1.0.0)...</span><br><span class="line"></span><br><span class="line">Terraform has been successfully initialized!</span><br><span class="line"></span><br><span class="line">You may now begin working with Terraform. Try running &quot;terraform plan&quot; to see</span><br><span class="line">any changes that are required for your infrastructure. All Terraform commands</span><br><span class="line">should now work.</span><br><span class="line"></span><br><span class="line">If you ever set or change modules or backend configuration for Terraform,</span><br><span class="line">rerun this command to reinitialize your working directory. If you forget, other</span><br><span class="line">commands will detect it and remind you to do so if necessary.</span><br><span class="line">root@stan-OptiPlex-380:~stan/Doc/Terraform/ecs_app_todo|master⚡</span><br><span class="line">⇒  terraform providers</span><br><span class="line">.</span><br><span class="line">├── provider.aws 1.31</span><br><span class="line">├── provider.template 1.0.0</span><br><span class="line">├── provider.terraform (from state)</span><br><span class="line">└── module.child</span><br><span class="line">    ├── provider.aws (inherited)</span><br><span class="line">    ├── provider.template (inherited)</span><br><span class="line">    └── provider.terraform</span><br></pre></td></tr></table></figure>
<p><strong>Use module-relative path for embedded files (${path.module})</strong></p>
<p><strong>Encapsulation</strong></p>
<ul>
<li>A language mechanism for restricting direct access to some of the object’s components</li>
</ul>
<p>we can choose to make the module as transparent as possible - and in this case, it would inject all dependencies from the root module, and keep no data sources in the child module</p>
<h1 id="Error-and-debug"><a href="#Error-and-debug" class="headerlink" title="Error and debug"></a>Error and debug</h1><ol>
<li>Error 1:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">terraform init</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line">Backend configuration changed!</span><br><span class="line"></span><br><span class="line">Terraform has detected that the configuration specified for the backend</span><br><span class="line">has changed. Terraform will now check for existing state in the backends.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Error inspecting states in the &quot;s3&quot; backend:</span><br><span class="line">    NoSuchBucket: The specified bucket does not exist</span><br><span class="line">        status code: 404, request id: E51C641611FF2763, host id: 9AN52en4R7RaZueavAicV5/N01SahL+Y1TZBT8TGnYBYYD5ywWxPKgkiiqDx8+FsgkwNNyadfSU=</span><br><span class="line"></span><br><span class="line">Prior to changing backends, Terraform inspects the source and destination</span><br><span class="line">states to determine what kind of migration steps need to be taken, if any.</span><br><span class="line">Terraform failed to load the states. The data in both the source and the</span><br><span class="line">destination remain unmodified. Please resolve the above error and try again.</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>Debug mode:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> TF_LOG=trace terraform init</span><br><span class="line">2019/07/21 11:50:39 [INFO] Terraform version: 0.11.7  41e50bd32a8825a84535e353c3674af8ce799161</span><br><span class="line">2019/07/21 11:50:39 [INFO] Go runtime version: go1.10.1</span><br><span class="line">2019/07/21 11:50:39 [INFO] CLI args: []string&#123;&quot;/root/.terraform.versions/terraform_0.11.7&quot;, &quot;init&quot;&#125;</span><br><span class="line">2019/07/21 11:50:39 [DEBUG] Attempting to open CLI config file: /root/.terraformrc</span><br><span class="line">2019/07/21 11:50:39 [DEBUG] File doesn&apos;t exist, but doesn&apos;t need to. Ignoring.</span><br><span class="line">2019/07/21 11:50:39 [INFO] CLI command args: []string&#123;&quot;init&quot;&#125;</span><br><span class="line">2019/07/21 11:50:39 [DEBUG] command: loading backend config file: /root/terraform/vpc</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line">2019/07/21 11:50:39 [TRACE] Preserving existing state linea</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<ol start="2">
<li>Error2:<br><img src="https://i.imgur.com/NvWneaV.png" alt="error2"><br>if ecs try to connect to localhost as rds, and couldnot connect sucessfully</li>
</ol>
<p>Debug:<br>ecs_task.tpl pg environment vars are all missing</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/aws/">aws</a><a href="/tags/terraform/">terraform</a><a href="/tags/automation/">automation</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/05/agile/" title="agile" itemprop="url">agile</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-05T01:10:42.858Z" itemprop="datePublished"> Published 2019-07-05</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="Agile-is-a-movement"><a href="#Agile-is-a-movement" class="headerlink" title="Agile is a movement."></a>Agile is a movement.</h1><p>Movement: a group of people working together to advance their shared political, social, or artistic ideas.</p>
<h2 id="Early-agile-methodologies"><a href="#Early-agile-methodologies" class="headerlink" title="Early agile methodologies"></a>Early agile methodologies</h2><ul>
<li>1995: Scrum<ul>
<li>Iterative cycles of work</li>
<li>Emphasis on cross-functional collaboration</li>
</ul>
</li>
<li>Mid-90s: Crystal<ul>
<li>Emphasis on adaptability and “stretch-to-fit” process</li>
</ul>
</li>
<li>1990: XP<ul>
<li>Short, iterative cycles of work</li>
<li>Emphasis on collaboration between developers</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/MjJqXdR.jpg" alt="agile manifesto"><br><strong>Agile Values</strong></p>
<ul>
<li>Increase cross-functional collaboration</li>
<li>Minimize works in progress (sepecs, etc)</li>
<li>Work in iterative cycles to incorporate change and get frequent feedback</li>
<li>Make time to reflect on how you work</li>
</ul>
<hr>
<h1 id="Agile-Development"><a href="#Agile-Development" class="headerlink" title="Agile Development"></a>Agile Development</h1><p><strong>born-on-the-cloud model</strong>: cloud as the primary platform for both consumed and delivered services<br>Agility to get projects up and running quickly<br>streamlined process by reducing transitions from Development to Operations</p>
<p>Java EE application with a Minimum Viable Product (MVP)<br>setup the cloud infrastructure and Toolchain using the Born-on-the-cloud approach</p>
<p>Hypothesis-driven development</p>
<p>ranked backlog, user stories, story points<br>tracking and delivering in Timeboxed iterations</p>
<p><strong>backlog</strong> is a prioritized list of features (User Stores) waiting to be scheduled and implemented</p>
<p>Note that among other things one of the most important responsibilities of the product owner role in Agile development methodology is to keep the backlog ranked by priority, and he or she can set the priorities by simply dragging the issues and ordering them, regardless of when they were added to the backlog</p>
<p>User stories: who, what, why<br>story points and planning poker</p>
<p><strong>user story</strong> is an informal, natural language description of a chunk of functionality that is of value from an end-user perspective<br>As a <who>, I want <what> so that <why></p>
<p><strong>Story Points</strong> are estimates of effort as influenced by the amount of work, complexity, risk, and uncertainty.</p>
<ul>
<li>(Adapted) Fibonacci sequence: 0,1,2,3,5,8,13,20,40,100</li>
</ul>
<p><strong>Planning Poker</strong> is a consensus-based, gamified technique for estimating<br>Timeboxing refers to the act of putting strict time boundaries around an action for activity</p>
<p>time boxed interrogations along with story points are important to measure the team velocity over time. For example you should track the total amount of story points that team delivers each iteration, and this way you’ll be able to determine on average the team velocity metric, or in other words how many story points on average the team is able to deliver. </p>
<p>Architecture breakdown</p>
<ul>
<li>User interface (html/css/javascript)</li>
<li>CRUD Service(REST APIs with JAX-RS)</li>
<li>Database(NoSQL)</li>
</ul>
<p><strong>Test-Driven Development (TDD)</strong> is a technique for building software by writing automate test cases before writing any code<br>why: focus on the outcome; helps to manage risk; enables fast iterations and continous integration; keeps the code clear, simple and testable;<br>grater confidence to make applicaton changes; documentation of how the system works</p>
<p>How:add a test-&gt;run all tests and see if the new one fails-&gt; write the code-&gt;run tests-&gt; refactor the code-&gt;repeat</p>
<p>A <strong>delivery pipeline</strong> is a sequence of automated stages that retrieve input and run jobs, such as builds, tests, and deployments.<br>It automates the continuous deployment of a project, with miniumum or no-human intervention.</p>
<ul>
<li>A Stage retrieves input and run jobs, such as builds,tests, and deployments.</li>
<li>Jobs run in discrete working directories in containers that are created for each pipeline run</li>
<li>By default, stages run sequentially after changes are delivered to source control</li>
</ul>
<p><strong>showcase the applicaton</strong>: At the end of the iteration before the retrospective meeting that is a showcase meaning, also know as demo meeting, where the work done is demonstrated to the stakeholders and feedback is obtaining. The showcase meeting starts by reviewing what we have committed in the form of user stories. And finally we demonstrate what we have accomplished in the form of working software, so we can acquire feedback on the product we are building.</p>
<p><strong>retrospective meeting</strong>: how to conduct<br>1st way:<br>What went well?<br>what could be improved?</p>
<p>2nd way:<br>Start doing</p>
<ul>
<li>continuous delivery<br>stop doing</li>
<li>time-bxed iterations<br>continue doing</li>
<li>ranked backlog</li>
</ul>
<h2 id="Common-Problems"><a href="#Common-Problems" class="headerlink" title="Common Problems"></a>Common Problems</h2><h2 id="Value-Focus"><a href="#Value-Focus" class="headerlink" title="Value/Focus"></a>Value/Focus</h2><table>
<thead>
<tr>
<th>Problems</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Not understanding the market</td>
<td>Hypothesis-driven development</td>
</tr>
<tr>
<td>Putting wrong products into the market</td>
<td>Minimum Viable Product (MVP)</td>
</tr>
<tr>
<td>Lack of focus on value</td>
<td>Timboxing/Iterations</td>
</tr>
</tbody>
</table>
<h2 id="Productivity-Speed-Cost"><a href="#Productivity-Speed-Cost" class="headerlink" title="Productivity/Speed/Cost"></a>Productivity/Speed/Cost</h2><table>
<thead>
<tr>
<th>Problems</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Too long to get projects up and running</td>
<td>Born on the Cloud</td>
</tr>
<tr>
<td>Slow to put products into market</td>
<td>MVP/Delivery pipeline/Continuous delivery</td>
</tr>
<tr>
<td>Too costly projects</td>
<td>Automation/Toolchain/Delivery pipeline</td>
</tr>
</tbody>
</table>
<h2 id="Communication-Visibility"><a href="#Communication-Visibility" class="headerlink" title="Communication/Visibility"></a>Communication/Visibility</h2><table>
<thead>
<tr>
<th>Problems</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Priorities aren’t clear</td>
<td>Ranked backlog</td>
</tr>
<tr>
<td>Requirements not reflecting the user’s needs</td>
<td>User stories</td>
</tr>
<tr>
<td>Poor team communication</td>
<td>Daily standup</td>
</tr>
<tr>
<td>Lack of visibility into the progress</td>
<td>Iteration wall/Showcase meeting</td>
</tr>
</tbody>
</table>
<h2 id="Quality-Control"><a href="#Quality-Control" class="headerlink" title="Quality/Control"></a>Quality/Control</h2><table>
<thead>
<tr>
<th>Problems</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Low quality products</td>
<td>Test driven development/Delivery pipeline</td>
</tr>
<tr>
<td>Lack of prcess improvement</td>
<td>Retrospective meeting/Continous improvement</td>
</tr>
<tr>
<td>Bad Requirements estimations</td>
<td>Story points/Planning poker</td>
</tr>
<tr>
<td>Not honouring past our commitments</td>
<td>Track team’s velocity</td>
</tr>
</tbody>
</table>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/agile/">agile</a><a href="/tags/software-development/">software development</a><a href="/tags/agile-development/">agile development</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/07/04/devops-as-a-service/" title="Devops As A Service" itemprop="url">Devops As A Service</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stan Zhou" target="_blank" itemprop="author">Stan Zhou</a>
		
  <p class="article-time">
    <time datetime="2019-07-03T23:54:43.000Z" itemprop="datePublished"> Published 2019-07-04</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><img src="https://i.imgur.com/5ci7g2C.png" alt="Imgur"><br>Business Requirements</p>
<ul>
<li>Start with business requirements</li>
<li>DevOps is about doing the work right</li>
<li>What about doing the right work? See<ul>
<li>(Agile) Portfolio Management- making sure the work you are doing is funded and delivering business value, and</li>
<li>Lean Control - making sure you get early engagement with control functions in your organisation (Audit, Compliance, Security, Architecture,<br>Accessibility, Marketing, etc.)</li>
</ul>
</li>
<li>Work/Requirements are comprised of<ul>
<li>features of business value (2-3 months), divided into …</li>
<li>sprints (2-3 weeks) and the sprints are made up of …</li>
<li>tasks (2-3 days of work)</li>
</ul>
</li>
</ul>
<p>Tasks</p>
<ul>
<li>2-3 days of work</li>
<li>Developers pull tasks off of a sprint queue</li>
<li>Sprint goals to demo working software at the end of each sprint</li>
</ul>
<p>Code</p>
<ul>
<li>Integrated continuously, Build continuously</li>
<li>All code is reviewed by another team member before committing</li>
<li>Feature branching or trunk-based development?</li>
<li>No long lived code branches</li>
</ul>
<p>Continuous Integration</p>
<ul>
<li>Code built continuously (multiple times per day)</li>
<li>Fast feedback -continous builds are very fast (&lt; 5mins)</li>
<li>Best practice build patterns/chains<ul>
<li>Compile, unit test, integration test, deploy artefacts</li>
</ul>
</li>
</ul>
<p>Metrics</p>
<ul>
<li>Code quality is vital</li>
<li>Code coverage measures test automation</li>
<li>Gold/silver/bronze accreditation</li>
</ul>
<p>Artifacts</p>
<ul>
<li>Green builds produce shippable artefacts (.jar, .dll, .exe, docker image)</li>
<li>Single store for all internal and external artefacts and libraries</li>
<li>Security policies around 3rd party libraries and external access</li>
</ul>
<p>Infrastructure as Code</p>
<ul>
<li>Operations roles change</li>
<li>Infrastructure provisioning and configuration is automated</li>
<li>Orchestration tools to provision infrastructure (Terraform, Cloud Formation for AWS)</li>
<li>Configuration management tools to install and manage software on provisioned infrastructure (Chef, Puppet, Ansible)</li>
<li>IaC is stored, tested and versioned in source code control</li>
<li>Organisational Change, move to Site Reliability Engineering (SRE)</li>
</ul>
<p>Service Mangement</p>
<ul>
<li>Approvals and change are automated</li>
<li>Products with higher levels of accreditation have lower change management overheads (more automation)</li>
</ul>
<p>Continous Deployment</p>
<ul>
<li>Infrastructure provisioned automatically</li>
<li>Configuration automated</li>
<li>Change approvals automated</li>
<li>Push button deployment to production</li>
</ul>
<p>Monitoring</p>
<ul>
<li>Observability driven design</li>
<li>Monitoring, logging, dash boarding early in the life-cycle</li>
<li>Issues and observations feed back to developers</li>
</ul>
<p>Security</p>
<ul>
<li>“Shift Left” security</li>
<li>“average total cost of a breach ranges from $2.2 million to $6.9 million”</li>
<li>Code vulnerability scanning in the build pipeline</li>
<li>Build fail if major/critical issues</li>
<li>Tools- CheckMarx, Fortify</li>
<li>Artefact scanning for security vulnerabilities</li>
<li>Firewalls to protect against 3rd party vulnerabilities</li>
<li>Tools - Nexus Lifecycle/Fiewall, BackDuck</li>
<li>Image scanning dof Docker images</li>
<li>Tools- AquaSec, Twistlock, Tennable, OpenSCAP</li>
</ul>
<p>Evolving DevOps @ Scale</p>
<p>Shadow DevOps -&gt; Enterprise DevOps -&gt; DevOps as a Service</p>
<p>10 years age -&gt; 5 years ago  -&gt; the future</p>
<p><img src="https://i.imgur.com/6Ei88Zz.jpg" alt="Enterprise Devops"><br><img src="https://i.imgur.com/jRJvY69.jpg" alt="Devops as a Service"><br><img src="https://i.imgur.com/kQNGOfS.jpg" alt="GitOps"><br><img src="https://i.imgur.com/Vvmeafo.jpg" alt="AWS DevOps"><br><img src="https://i.imgur.com/lwpUXVf.jpg" alt="Azure DevOps"></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Devops/">Devops</a><a href="/tags/aws/">aws</a><a href="/tags/git/">git</a><a href="/tags/Azure/">Azure</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>







  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  
<div class="github-card">
<p class="asidetitle">Github Card</p>
<div class="github-card" data-github="stanosaka" data-width="220" data-height="119" data-theme="medium">
<script type="text/javascript" src="//cdn.jsdelivr.net/github-cards/latest/widget.js" ></script>
</div>
  </div>



  

  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Devops/" title="Devops">Devops<sup>7</sup></a></li>
			
		
			
				<li><a href="/tags/aws/" title="aws">aws<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/centos/" title="centos">centos<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/Jenkins/" title="Jenkins">Jenkins<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/CD-CI/" title="CD/CI">CD/CI<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/docker/" title="docker">docker<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/git/" title="git">git<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/tomcat/" title="tomcat">tomcat<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/saltstack/" title="saltstack">saltstack<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/zabbix/" title="zabbix">zabbix<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/ec2/" title="ec2">ec2<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/backup/" title="backup">backup<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/github/" title="github">github<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/nginx/" title="nginx">nginx<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Pipeline/" title="Pipeline">Pipeline<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Blue-Ocean/" title="Blue Ocean">Blue Ocean<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Linux/" title="Linux">Linux<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/SRE/" title="SRE">SRE<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/agile/" title="agile">agile<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://kupczynski.info/2018/04/18/spacemacs.html" target="_blank" title="Learning Spacemacs">Learning Spacemacs</a>
            
          </li>
        
          <li>
            
            	<a href="https://cloud.ibm.com/docs/tutorials?topic=solution-tutorials-tutorials" target="_blank" title="IBM cloud solution tutorial">IBM cloud solution tutorial</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/aws-samples" target="_blank" title="AWS Samples">AWS Samples</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/bikrambora/devlab-launchpad" target="_blank" title="Welcome to Dev Labs">Dev Labs</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/ansible/ansible-examples" target="_blank" title="Ansible GitHub repo">Ansible GitHub repo</a>
            
          </li>
        
          <li>
            
            	<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html" target="_blank" title="Ansible Best Practices">Ansible Best Practices</a>
            
          </li>
        
          <li>
            
            	<a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/" target="_blank" title="kubectl cheat sheet">kubectl cheat sheet</a>
            
          </li>
        
          <li>
            
            	<a href="http://rogerdudler.github.io/git-guide" target="_blank" title="Git commands">Git commands</a>
            
          </li>
        
          <li>
            
            	<a href="https://docs.docker.com/engine/reference/builder/" target="_blank" title="Dockerfile reference">Dockerfile reference</a>
            
          </li>
        
          <li>
            
            	<a href="http://bit.ly/2mTQr8l" target="_blank" title="Linux Command line cheat sheet">Linux Command line cheat sheet</a>
            
          </li>
        
          <li>
            
            	<a href="http://bit.ly/2EPHxze" target="_blank" title="PowerShell Basic Cheat Sheet">PowerShell Basic Cheat Sheet</a>
            
          </li>
        
          <li>
            
            	<a href="http://sed.sourceforge.net/sed1line_zh-CN.html" target="_blank" title="sed cheatsheet">sed cheatsheet</a>
            
          </li>
        
          <li>
            
            	<a href="http://obsavus1p.bkt.clouddn.com/vim_cheat_sheet_for_programmers_print.png" target="_blank" title="vim cheatsheet">vim cheatsheet</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.gitbook.com/book/yeasy/docker_practice/details" target="_blank" title="Learn Docker">Learn Docker</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.unixhot.com/page/ops" target="_blank" title="运维知识体系">运维知识体系</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.tecmint.com/" target="_blank" title="tecmint">tecmint</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.lib.uts.edu.au" target="_blank" title="shoujin.wang@student.uts.edu.au">UTS Library</a>
            
          </li>
        
          <li>
            
            	<a href="https://7esl.com" target="_blank" title="ESL">ESL</a>
            
          </li>
        
          <li>
            
            	<a href="https://stanchou.wordpress.com" target="_blank" title="Stan&#39;s wordpress">Stan&#39;s wordpress</a>
            
          </li>
        
          <li>
            
            	<a href="https://docs.00root.com" target="_blank" title="Stan&#39;s gitbook">Stan&#39;s gitbook</a>
            
          </li>
        
          <li>
            
            	<a href="https://api.ipify.org" target="_blank" title="Your IP address">Your IP address</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/stanosaka/oreilly_sql_fundamentals_for_data/blob/master/notes_and_slides/sql_fundamentals_notes.md" target="_blank" title="sql fundamentials">sql fundamentials</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.nerdfonts.com" target="_blank" title="Nred Fonts">Nred Fonts</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Stan living in Sydney. <br/>
			I am a lifelong technology learner.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		<a href="https://github.com/stanosaka" target="_blank" class="icon-github" title="github"></a>
		
		
		<a href="http://stackoverflow.com/users/6724938" target="_blank" class="icon-stack-overflow" title="stackoverflow"></a>
		
		
		<a href="https://twitter.com/stanosaka" target="_blank" class="icon-twitter" title="twitter"></a>
		
		
		<a href="https://www.facebook.com/stan.osaka" target="_blank" class="icon-facebook" title="facebook"></a>
		
		
		<a href="https://www.linkedin.com/in/00root" target="_blank" class="icon-linkedin" title="linkedin"></a>
		
		
		<a href="https://www.douban.com/people/btw01v" target="_blank" class="icon-douban" title="豆瓣"></a>
		
		
		<a href="http://www.zhihu.com/people/stan-22-82" target="_blank" class="icon-zhihu" title="知乎"></a>
		
		
		
		<a href="mailto:devops@cwzhou.win" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2020 
		
		<a href="/about" target="_blank" title="Stan Zhou">Stan Zhou</a>
		
		
		</p>
</div>
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>


        
  	    <script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script>
            <script>
               if (window.mermaid) {
                  mermaid.initialize({theme: 'forest'});
               }
            </script>
        












<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
